\section{Introduction, simplices}\label{905}
Topics to be covered:
\begin{enumerate}
    \item Singular homology
    \item CW-complexes
    \item Basics of category theory
    \item Homological algebra
    \item The K\"{u}nneth theorem
    \item UCT, cohomology
    \item Cup and cap products, and
    \item Poincar\'{e} duality.
\end{enumerate}
Examples to keep in mind: $\mathbf{R}^n$. Inside, $S^{n-1}$ being the $(n-1)$-sphere. This is topologized as a subspace of Euclidean space. Taking the quotient by the equivalence relation $x\simeq -x$ gives $\mathbf{RP}^{n-1}$, i.e. the space of lines through the origin in $\mathbf{R}^{n+1}$.

Also, we can look at $V_k(\mathbf{R}^n)$, which is the space of orthonormal $k$-frames (ordered collection of $k$ orthonormal vectors) in $\mathbf{R}^n$, called the Stiefel manifold, topologized as a subspace of $(S^{n-1})^k$. The Grassmannian, $\mathrm{Gr}_k(\mathbf{R}^n)$, the space of $k$-dimensional linear subspaces of $\mathbf{R}^n$. It's a quotient space of $V_k(\mathbf{R}^n)$, since a $k$-frame spans a $k$-dimensional subspace. For example, $\mathbf{Gr}_1(\mathbf{R}^n) = \mathbf{RP}^{n-1}$. These are all \emph{manifolds}.
\begin{definition}
A manifold is a Hausdorff space, locally homeomorphic to $\mathbf{R}^n$.
\end{definition}
All these manifolds are compact except for $\mathbf{R}^n$. Manifolds exhibit a hidden symmetry, captured by Poincar\'{e} duality.

We'll probe general topological spaces through simplices.
\begin{definition}
The standard $n$-simplex $\Delta^n$ is the convex hull of $\{e_0,\cdots,e_n\}$ in $\mathbf{R}^{n+1}$. More explicitly,
$$\Delta^n = \{\sum t_i e_i = 1 : \sum t_i = 1, t_i\geq 0\}\subseteq\mathbf{R}^{n+1}$$
The $t_i$s are called barycentric coordinates.
\end{definition}
Usually we just drop the $e_i$s and just write ``$i$''. There are maps between them, namely inclusions of faces. The map $d^2:\Delta^1\to\Delta^2$ that misses the vertex $i$ (where $0\leq i\leq 2$) is denoted $d^i$\todo{Insert an image here}. They're called ``face inclusions'', and are maps $d^i:\Delta^{n-1}\to\Delta^n$ where $0\leq i\leq n$; they miss the vertex $i$.
\begin{definition}
Let $X$ be any topological space. A singular $n$-simplex in $X$ is a continuous map $\Delta^n\to X$. Denote by $\mathrm{Sin}_n(X)$ as the collection of all $n$-simplices of $X$.
    
    This seems like a ``fairly insane'' thing to do.
\end{definition}
See drawing for a torus\todo{Image me}. The direction of the simplex is like an orientation given by ordering of the indices of $\Delta^n$. The standard notation is $\sigma:\Delta^n\to X$\todo{Depict this whole thing as an image, and remove the sentence when done}.

If $\sigma:\Delta^n\to X$. Find $(n-1)$-simplices by looking faces of simplex; get a map $d_i:\Sin_n(X)\to\Sin_{n-1}(X)$ for $0\leq i\leq n$ by taking $\sigma\mapsto\sigma\circ d^i=: d_i\sigma$, which is the $i$th face of $\sigma$. This carries a lot of information about the space.

Some simplices are particularly interesting. The issue of when boundaries match up is a key aspect of simplices. If $\sigma$ is a simplex that goes around the hole in a torus, then $d_1\sigma = d_0\sigma$, and this means that the ``boundary'' is zero. So we want to understand things like $d_0\sigma - d_1\sigma$, but this isn't even a simplex anymore; we need to take formal sums and differences. We'll therefore consider the abelian group generated by simplices.
\begin{definition}
The abelian group of singular $n$-chains in $X$ is the free abelian group generated by $n$-simplices
$$S_n(X) = \mathbf{Z}\Sin_n(X)$$
    Its elements are finite linear combinations, i.e. formal sums of the form $\sum_{i\in\text{finite set}}a_i\sigma_i$\todo{idk what was meant by ``display'' in the comments} where $a_i\in\mathbf{Z}$. It's a pretty big group. If $n<0$, say that $S_n(X)=0$. Now, define a map $\partial:\Sin_n(X)\to S_{n-1}(X)$ via:
$$\partial\sigma = \sum_{i=0}^n(-1)^i d_i\sigma$$
We'll extend this to $S_n(X) \to S_{n-1}(X)$ by additivity.
\end{definition}
Cycles are chains whose boundary is zero. These are the interesting chains. A more precise definition is the following:
\begin{definition}
An $n$-cycle in $X$ is an $n$-chain $c$ with $\partial c = 0$. Denote $Z_n(X) = \ker(S_n(X)\xrightarrow{\partial}S_{n-1}(X))$.
\end{definition}
For example, with the $\sigma$ on the torus described before, $\partial c = d_0\sigma - d_1\sigma$ and this is zero.
\begin{theorem}
Any boundary is a cycle, i.e., $B_n(X) := \mathrm{Im}(\partial:S_{n+1}(X)\to S_n(X))\subseteq Z_n(X)$.
\end{theorem}
\begin{proof}
    Homework!
\end{proof}
\begin{definition}
The $n$th singular homology group of $X$ is:
    $$ H_n(X) = Z_n(X)/B_n(X) = \frac{\ker(\partial:S_n(X)\to S_{n-1}(X))}{\mathrm{Im}(\partial:S_{n+1}(X)\to S_n(X))}$$
The kernel is a free abelian group, and so is the image because they're both subgroups of free abelian groups; but the quotient isn't necessarily free abelian. The quotient is finitely generated for all the spaces we are talking about although the kernel and image are uncountably generated.
\end{definition}
%\newpage
\section{Simplices, more about homology}
Recall the standard $n$-simplex $\Delta^n\subseteq\mathbf{R}^{n+1}$. A singular simplex is a map $\sigma:\Delta^n\to X$; they are elements of the set $\Sin_n(X)$. For example, $\Sin_0(X)$ consists of points of $X$. You have a huge collection of maps $d^i:\Sin_n(X)\to\Sin_{n-1}(X)$ and $s^i:\Sin_n(X)\to\Sin_{n+1}(X)$, and the collection $\{\Sin_n(X),d^i,s^i\}$ forms a simplicial set. You therefore get a functor $\mathbf{Top}\to\{\text{simplicial sets}\}$. Simplicial sets are really cool, because they're combinatorial models for topological spaces.

Now, you get induced maps on free abelian groups. This produces for each space a semi-simplicial abelian group. Using the $d^i$s and $s^i$s, you get a boundary map $\partial$, and therefore a chain complex because $\partial^2=0$ (see homework). We capture this process in a diagram:
\begin{equation*}
\xymatrix{\mathbf{Top}\ar[d]\ar[r] & \{\text{semi-simplicial sets}\}\ar[r] & \{\text{semi-simplicial abelian groups}\}\ar[d]\\
    \{\text{simplicial sets}\}\ar[ur] & & \{\text{chain complexes}\}\ar[d]^{\text{take homology}}\\
 & &\{\text{graded abelian group}\}}
\end{equation*}
If you have a chain complex $\partial:A_n\to A_{n-1}$, then you have its homology $H_n(A,\partial)=\ker\partial_n/\img\partial_n$.

Let's practice with simplices. Suppose we have $\sigma:\Delta^1\to X$. Construct a map $\phi:\Delta^1\to\Delta^1$ via $(t,1-t)\mapsto (1-t,t)$. This reverses the orientation of $\sigma$. Composing $\sigma$ with $\phi$ gives another singular simplex $\overline{\sigma}$. It is \textit{not} true that $\overline{\sigma}=-\sigma$ in $S_1(X)$.

Claim: $\overline{\sigma}\equiv -\sigma\bmod B_1(X)=\img(\partial)$, i.e., they are homologous. That is, if $d_0\sigma=d_1\sigma$, so $\sigma\in Z_1(X)$, then $[\overline{\sigma}]=-[\sigma]$ in $ H_1(X)$. In other words, $\overline{\sigma}+\sigma$ is a boundary. We have to come up with a $2$-simplex in $X$ whose boundary is $\overline{\sigma}+\sigma$.

Let $\pi$ denote the projection map from $[0,1,2]$ to $[0,1]$\todo{MUST UPLOAD PICTURE HERE}. Then, $\partial(\sigma\circ\pi)=\sigma\pi d^0-\sigma\pi d^1 +\sigma\pi d^2=\overline{\sigma}-c^1_{\sigma(0)}+\sigma$ where $c^1_{\sigma(0)}$ is the constant $1$-simplex at $\sigma(0)$ (similarly for $c^n_{\sigma(0)}$). The $c^1_{\sigma(0)}$ is an error term. How do we correct this? Consider the constant $2$-simplex $c^2_{\sigma(0)}$ at $\sigma(0)$; then the boundary is $c^1_{\sigma(0)}-c^1_{\sigma(0)}+c^1_{\sigma(0)}$, which is $c^1_{\sigma(0)}$. So, $\overline{\sigma}+\sigma=\partial(\sigma\circ\pi + c^2_{\sigma(0)})$.

Let's compute the homologies of $\emptyset$ and $\ast$. Well, $\Sin_n(\emptyset)=\emptyset$, so $S_\ast(\emptyset)=0$. So, $\cdots\to S_2\to S_1\to S_0$ is the zero chain complex. This means that $Z_\ast(\emptyset)=0$ and similarly for boundaries. The homology in all dimensions is therefore $0$.

Now for $\ast$. Clearly $\Sin_n(\ast)=\ast$, and this generates $S_n(\ast)$, which is thus $\mathbf{Z}$. The chain complex is $S_0(\ast)\leftarrow S_1(\ast)\leftarrow S_2(\ast)\leftarrow\cdots$. What are the boundary maps? Well, $\partial(c^1_\ast)=d^0c^1_\ast - d^1c^1_\ast = c^0_\ast - c^0_\ast = 0$, $\partial(c^2_\ast)=d^0c_2^\ast - d^1 c^2_\ast + d^2 c^2_\ast = c^1_\ast - c^1_\ast + c^1_\ast = c^1_\ast$, and $\partial (c^3_\ast)=d^0 c^3_\ast - d^1 c^3_\ast + d^2 c^3_\ast - d^3 c^3_\ast = 0$. This means that our chain complex is:
$$\cdots\to\mathbf{Z}\xrightarrow{0}\mathbf{Z}\xrightarrow{1}\mathbf{Z}\xrightarrow{0}\mathbf{Z}$$
The cycles therefore alternate between $0$s and $\mathbf{Z}$s, namely as $\mathbf{Z},\mathbf{Z},0,\mathbf{Z},0,\cdots$. The boundaries are the same as the cycles except for dimension zero, namely as $0,\mathbf{Z},0,\mathbf{Z},0,\cdots$. This means that $ H_0(\ast)=\mathbf{Z}$ but $ H_i(\ast)=0$ for $i>0$.

What do these constructions do? Suppose you have $f:X\to Y$. You have a map $f_\ast:\Sin_n(X)\to\Sin_n(Y)$ induced by composition, namely $\sigma\mapsto f\circ \sigma=:f_\ast\sigma$. What about face maps; does the following diagram commute?
\begin{eqnarray*}
\xymatrix{\Sin_n(X)\ar[r]^{f_\ast}\ar[d]^{d_i} & \Sin_n(Y)\ar[d]^{d_i}\\
\Sin_{n-1}(X)\ar[r]^{f_\ast} & \Sin_{n-1}(Y)}
\end{eqnarray*}
We see that $d_if_\ast\sigma=(f_\ast\sigma)\circ d^i=f\circ\sigma\circ d^i$, and $f_\ast(d_i\sigma)=f_\ast(\sigma\circ d^i)=f\circ\sigma\circ d^i$. So the answer is yes! This also holds for the free abelian groups. You therefore get a map of chain complexes.

A chain map $f:C_\ast\to D_\ast$ is a map $f_n:C_n\to D_n$ such that the following diagram commutes for every $n$:
\begin{equation*}
    \xymatrix{
	C_n\ar[r]^{f_n}\ar[d]^{partial_C} & D_n\ar[d]^{\partial_D}\\
	C_{n-1}\ar[r]^{f_{n-1}} & D_{n-1}
    }
\end{equation*}
Does a chain map induce a map in homology $f_\ast: H_n(C)\to H_n(D)$? As a preliminary question, do we get a map $Z_n(C)\to Z_n(D)$? Let $c\in Z_n(C)$, so that $\partial_C c = 0$. Then $\partial_D f_n(c) = f_{n-1}\partial_C c = f_{n-1}(0) = 0$, because $f$ is a chain map. This means that $f_n(c)$ is also an $n$-cycle, i.e., $f$ gives a map $Z_n(C)\to Z_n(D)$.

Do we also get a map $B_n(C)\to B_n(D)$? Let $c\in B_n(C)$, so that there exists $c^\prime \in C_{n+1}$ such that $\partial_C c^\prime = c$. Then $f_n(c) = f_n\partial_C c^\prime = \partial_D f_{n+1}(c^\prime)$. Thus $f_n(c)$ is the boundary of $f_{n+1}(c^\prime)$, and $f$ gives a map $B_n(C)\to B_n(D)$.

The two maps $Z_n(C)\to Z_n(D)$ and $B_n(C)\to B_n(D)$ give a map on homology. This means that we get a map $f_\ast: H_n(X)\to H_n(Y)$, as desired!
%\newpage
\section{Categories, functors, natural transformations}
Office hours. Hood Chatham's are Mondays, 1:30 - 3:30, in 2-390A. Miller's is Tuesdays, 3:00-5:00 in 2-478.

The collection of all topological spaces forms a category. Similarly with simplicial sets, denoted $\set_\Deltab$ or $s\set$. You can take $X\mapsto \Sin_\bullet(X)$, and if $X\to Y$ is a map of spaces, this induces $\Sin_\bullet(X)\to\Sin_\bullet(Y)$. This is a functor $\mathbf{Top}\to s\set$.
\begin{definition}
A category $\cc$ is a class $\mathrm{ob}(\cc)$ of objects, such that for every two objects, $\cc(X,Y)$ is a set (thought of as a set of maps from $X$ to $Y$); these are called morphisms. These satisfy the properties that for all $X\in\mathrm{ob}(\cc)$, there exists an element $1_X\in\cc(X,X)$ that acts as the identity, and for all $X,Y,X\in\mathrm{ob}(\cc)$, there is a composition $\cc(X,Y)\times\cc(Y,Z)\to\cc(X,Z)$. These in turn satisfy the following properties:
\begin{itemize}
\item $1_Y\circ f=f$, and $f\circ 1_X=f$.
\item Composition is associative.
\end{itemize}
\end{definition}
\begin{example}
The category of sets and functions between sets forms a category. The category of abelian groups and homomorphisms forms a category. Of course, topological spaces and continuous maps. A monoid, which is a category with one object. The simplex category (note that $|[n]|=n+1$). A poset forms a category; but note that if $x\leq y$ and $y\leq x$, then $x\cong y$, not $x=y$. The latter property holds if the only isomorphisms are identities.
\end{example}
A small category is one such that $\mathrm{ob}(\cc)$ is a set, not necessarily a class.
\begin{definition}
Let $\cc,\cd$ be categories. A functor $F:\cc\to\cd$ is a function $\mathrm{ob}(\cc)\to\mathrm{ob}(\cd)$, such that for all $x,y\in\mathrm{ob}(\cc)$, there is a map $\cc(x,y)\to\cc(F(x),F(y))$ that respects composition and the identity.

Let $F,G:\cc\to\cd$. A natural transformation $\theta:F\to G$ is a map $\theta(X):F(X)\to G(X)$ for all $X\in\mathrm{ob}(\cc)$, and a commuting diagram for all $f:X\to Y$:
\begin{equation*}
\xymatrix{F(X)\ar[d]^{F(f)}\ar[r]^{\theta(X)} & G(X)\ar[d]^{G(f)}\\
F(Y)\ar[r]^{\theta(Y)} & G(Y)}
\end{equation*}
\end{definition}
\begin{example}
The boundary map $\partial:S_n\to S_{n-1}$ is a natural transformation. Let $G$ be a group viewed as a one-point category. Any element $F\in\mathrm{Fun}(G,\mathbf{Ab})$ is simply a group action of $G$ on $F(\ast)=A$, i.e., a representation of $G$ in abelian groups. A natural transformation from $F\to F^\prime$ is just a $G$-equivariant map.
\end{example}
%\newpage
\section{More about categories, and computing the homology of a star-shaped region}
Let $\mathrm{Vect}_{\mathbf{C}}$ be the category of vector spaces and linear transformations. Given a $\mathbf{C}$-vector space $V$, you can consider the dual $V^\ast=\Hom(V,\cc)$. Is this a functor? If you have a linear transformation $F:V\to W$, you get a map $F^\ast:W^\ast\to V^\ast$, so this is like a functor, but isn't strictly functor. This preserves composition and identities. Taking the dual therefore gives a functor $\mathrm{Vect}_\cc^{op}\to\mathrm{Vect}_\cc$, which is a \textit{contravariant} functor.
\begin{definition}
Given $\cc,\cd$. A contravariant functor is a functor from $\cc^{op}\to\cd$ where $\cc^{op}$ has the same objects as the category $\cc$ but with all morphisms reversed. There's a contravariant functor $\cc\to\cc^{op}$ that is the identity on objects and on morphisms.
\end{definition}
Let $\cc$ be a category, and let $Y\in\mathrm{ob}(\cc)$. We get a map $\cc^{op}\to\set$ that takes $X\mapsto \cc(X,Y)$, and takes a map $X\to W$ to the map defined by composition $\cc(W,Y)\to \cc(X,Y)$. This is called the functor that is represented by $Y$. It is very important to note that $\cc(-,Y)$ is contravariant, but $\cc(Y,-)$ is covariant.

Recall that $\Deltab$ has objects $[0],[1],[2],\cdots$ and a functor $\Deltab\to\mathbf{Top}$ that sends $[n]\mapsto\Delta^n$. We get a map $\mathbf{Top}^{op}\to\set$ given by sending $X\mapsto\mathbf{Top}(\Delta^n,X)=:\Sin_n(X)$. The composition gives you a contravariant functor $\Delta^{op}\to\set$, which sends $[n]\mapsto\mathbf{Top}(\Delta^n,X)$. This, along with the description of what happens to the face and degeneracy maps (see psets!) is precisely the singular simplicial set of $X$. In other words:
\begin{prop}[Really a definition...]
Simplicial sets are precisely functors $\Deltab^{op}\to\set$, i.e., $s\set=\mathbf{Fun}(\Deltab^{op},\set)$. More generally, simplicial objects in a category $\cc$ are functors $\Deltab^{op}\to\cc$, i.e., $s\cc=\mathbf{Fun}(\Deltab^{op},\cc)$.
\end{prop}
(Note that $\mathbf{Fun}(\cc,\cd)$ is the category whose objects are functors and whose morphisms are natural transformations.) Semi-simplicial sets (only face maps, not necessarily degeneracy maps) in a category $\cc$ are simply $ss\cc=\mathbf{Fun}(\Deltab^{op}_{inj},\cc)$ where $\Deltab_{inj}$ consists of the objects of $\Deltab$ where the morphisms only consist of the injective maps.
\begin{definition}
Let $f:X\to Y$ be a morphism in a category $\cc$. Say that $f$ is a \textit{split epimorphism} if there exists $g:Y\to X$ (often called a section or a splitting) such that $Y\xrightarrow{g}X\xrightarrow{f}Y$ is the identity.
\end{definition}
\begin{example}
Let $\cc=\set$. If $f:X\to Y$ is a map of sets, then this says that for every element of $Y$, there exists some element of $X$ whose image in $Y$ is the original element. This means that $f$ is surjective. Is every surjective map a split epimorphism? This reduces to the axiom of choice because proving that if $y\in Y$, the map $g:Y\to X$ can be constructed by choosing some $x\in f^{-1}(y)$.
\end{example}
\begin{definition}
Say that $g:Y\to X$ is a split monomorphism if there is $f:X\to Y$ such that $f\circ g=1_Y$.
\end{definition}
\begin{example}
Let $\cc=\set$. Claim: it's an injection. If $y,y^\prime\in Y$, and $g(y)=g(y^\prime)$, we want to show that $y=y^\prime$. Apply $f$, to get $f(g(y))=y=f(g(y^\prime))=y^\prime$. If $Y\neq \emptyset$, then every injection $g:Y\to X$ is a split mono.
\end{example}
\begin{example}
An isomorphism is a split epi + split mono.
\end{example}
\begin{lemma}
If $f:X\to Y$ is a split epi or mono in $\cc$, and you have a functor $F:\cc\to \cd$, then so is $F(f)$ in $\cd$.
\end{lemma}
\begin{proof}
Trivial.
\end{proof}
\begin{example}
Suppose $\cc=\mathbf{Ab}$, and you have a split epi $f:A\to B$. We have a map $g:B\to A$ so that $fg=1$. Clearly $f$ must be surjective. Consider the kernel of $f$, so we have a composition $\ker f\to A\to B$. We also have a map $B\to A$, so we can add, and get $\ker f\oplus B\xrightarrow{[i,g]} A$ where $i$ is the inclusion $\ker f\to A$. Left for reader: $[i,g]$ is an isomorphism.

If $g:B\to A$ is a split mono, so there is $f:A\to B$ so that $fg=1$. Clearly $g$ is injective, and we get a map $B\to A\xrightarrow{p}\mathrm{coker}(g)$. We therefore get a map $A\xrightarrow{\begin{pmatrix}
p \\ f
\end{pmatrix}}\mathrm{coker}(g)\oplus B$. Left to reader again: this is an isomorphism.
\end{example}
We have to get into some topology, since it's on our agenda. Suppose I have a space $X$. There's always a unique map $X\to\ast$, which means categorically that $\ast$ is trivial. We have an induced map $ H_n(X)\to H_n(\ast)=\begin{cases}\mathbf{Z} & n=0\\
0 & \text{else}\end{cases}$. Consider the equivalence class (also called the \textit{homology class} of the cycle $\sum a_ix_i$) $\left[\sum a_ix_i\right]\in H_0(X)$, where $x_i$ is a point in $X$. Under the induced map, this goes as: $\left[\sum a_ix_i\right]\mapsto \left[\sum a_i\ast\right]=\left(\sum a_i\right)\left[\ast\right]$. This is called the augmentation map. This map is a split epi, because we can always choose a point of $X$ and pull an element of $\mathbf{Z}$ back. This motivates the following definition.
\begin{definition}
A pointed space is a pair $(X,\ast)$, with $\ast\in X$ called the \textit{basepoint}.
\end{definition}
We have an inclusion $\ast\to X\to\ast$, so we get an induced map $\mathbf{Z}\xrightarrow{\eta} H_\ast(X)\xrightarrow{\epsilon}\mathbf{Z}$, and the composition is the identity. The map $\epsilon$ is the augmentation map we described above. This means, by our above analysis, we see that $ H_\ast(X)\cong \mathbf{Z}\oplus\mathrm{coker}\eta \cong\mathbf{Z}\oplus\ker\epsilon$. The homology $ H_\ast(X,\ast)=\mathrm{coker}\eta$, and this is called the reduced homology of $(X,\ast)$. It's isomorphic to $ H_\ast(X)$ in dimensions greater than $0$, but differs by a factor of $\mathbf{Z}$ in dimension $0$.

We spent up a lot of time on categories, and didn't get to star-shaped regions. We'll pick this up on Friday, but we'll begin a little here.
\begin{definition}
A star-shaped region is a subspace $X$ of $\mathbf{R}^n$ for some $n$ such that $0\in X$, such that for all $x\in X$, and for all $t\in[0,1]$, $tx\in X$. 
\end{definition}
\begin{example}
Any convex region containing the origin is star shaped.
\end{example}
\begin{theorem}
The augmentation map $\epsilon: H_\ast(X)\to \mathbf{Z}$ is an isomorphism, i.e., $ H_0(X)\cong\mathbf{Z}$ and $ H_i(X)\cong 0$ for $i>0$.
\end{theorem}
The strategy of proof is that $\epsilon$ is induced by sending $X\to \ast$. We'll look at the chain map $S_\ast(x)\to\mathbf{Z}\to S_\ast(X)$. We'll show that this composite induces the same map in homology as the identity map, which means that the identity map factors through $\mathbf{Z}$, so we're done.
%\newpage
\section{Homotopy, star-shaped regions}
The idea of homotopy is the central concept of all of algebraic topology, to put it bluntly. We have a functor $ H_\ast:\mathbf{Top}\to\mathbf{Ab}$, but it's too crude to distinguish between topological spaces. The virtue of this definition is that it's computable, although it can't completely distinguish between two spaces.
\begin{definition}
Let $f_0,f_1:X\to Y$ be two maps. A homotopy from $f_0$ to $f_1$ is a map $h:X\times I\to Y$ such that $h(x,0)=f_0(x)$ and $f(x,1)=f_1(x)$. We say that $f_0$ and $f_1$ are homotopic, and this is written $f_0\sim f_1$ because this is an equivalence relation on maps (transitivity follows from the gluing lemma).
\end{definition}
We denote by $[X,Y]$ the set $\mathbf{Top}(X,Y)/\sim$. On Monday, we'll prove the following result.
\begin{theorem}
If $f_0\sim f_1$, then $ H_\ast(f_0)= H_\ast(f_1)$. In other words, homology cannot distinguish between homotopic things.
\end{theorem}
Suppose I have two maps $f_0,f_1:X\to Y$ and a map $g:Y\to Z$, with a homotopy $h:f_0\sim f_1$. Composing $h$ with $g$ gives a homotopy between $g\circ f_0$ and $g\circ f_1$. Precomposing also works. Namely, if $g:W\to X$ is a map and $f_0,f_1:X\to Y$ are homotopic, then $f_0g\sim f_1g$. Does this let us compose homotopy classes? That is, can we complete:
\begin{equation*}
\xymatrix{\mathbf{Top}(Y,Z)\times\mathbf{Top}(X,Y)\ar[d]\ar[r] & \mathbf{Top}(X,Z)\ar[d]\\
[Y,Z]\times[X,Y]\ar@{-->}[r] & [X,Z]}
\end{equation*}
The answer is yes. If $g_0\sim g_1:Y\to Z$ and $f_0\sim f_1: X\to Y$, then $g_0f_0\sim g_0f_1$, but this is just homotopic to $g_1f_1$. This therefore gives us a new category, called the homotopy category.
\begin{definition}
The homotopy category of topological spaces is $\mathrm{Ho}(\mathbf{Top})$ whose objects are topological spaces and $\mathrm{Ho}(\mathbf{Top})(X,Y)=[X,Y]=\mathbf{Top}(X,Y)/\sim$.
\end{definition}
This is an interesting category because it has \textit{terrible} categorical properties. The theorem that we'll prove on Monday says that the homology functor $ H_\ast:\mathbf{Top}\to\mathbf{Ab}$ factors as $\mathbf{Top}\to\mathrm{Ho}(\mathbf{Top})\to\mathbf{Ab}$.
\begin{definition}
A map $f:X\to Y$ is a homotopy equivalence if $[f]\in[X,Y]$ is an isomorphism in $\htop$. In other words, there is $g:Y\to X$ such that $fg\sim 1_Y$ and $gf\sim 1_X$.
\end{definition}
\begin{example}
Homotopy equivalence doesn't preserve compactness. For example, the inclusion $S^{n-1}\subseteq \mathbf{R}^n-\{0\}$. The homotopy inverse $p:\mathbf{R}^n-\{0\}\to S^{n-1}$ can be obtained by dividing a (always nonzero!) vector by its length. Clearly $p\circ i=1_{S^{n-1}}$. We have to find a homotopy $i\circ p\sim 1_{\mathbf{R}^n-\{0\}}$. Namely, we want a map $(\mathbf{R}^n-\{0\})\times I\to \mathbf{R}^n-\{0\}$; but this is straightforward, namely, take $(v,t)\mapsto tv+(1-t)\frac{v}{||v||}$.
\end{example}
Let's set up the stuff about star-shaped region. The first thing to realize is that the inclusion $\{0\}\to X$, where $X$ is a star-shaped region, is a homotopy equivalence, precisely like the above example!
\begin{definition}
A space $X$ is contractible if the map $X\to\ast$ is a homotopy equivalence.
\end{definition}
In other words, the star-shaped region is contractible. The claim is the following.
\begin{prop}
$ H_\ast(X)\cong\mathbf{Z}$ where $X$ is a star-shaped region.
\end{prop}
We want to set up a homotopy in the category of chain complexes.
	\begin{definition}
	Let $C_\bullet,D_\bullet$ be chain complexes, and $f_0,f_1:C_\bullet\to D_\bullet$ be chain maps. A chain homotopy $h:f_0\sim f_1$ is a collection of homomorphisms $h:C_n\to D_{n+1}$ such that $\partial h+h\partial=f_1-f_0$.
	\end{definition}
It's a really weird relation, but we'll understand why this is a good thing.
			\begin{equation*}
			\xymatrix{C_{n+2}\ar[r]^{f_1-f_0}\ar[d]^\partial & D_{n+2}\ar[d]^\partial\\
			C_{n+1}\ar@{-->}[ur]^h\ar[r]^{f_1-f_0}\ar[d]^\partial & D_{n+2}\ar[d]^\partial\\
			C_n\ar@{-->}[ur]^h\ar[r]_{f_1-f_0} & D_n}
			\end{equation*}
	\begin{lemma}
	If $f_0,f_1:C_\bullet\to D_\bullet$ are chain homotopic, then $f_{0,\ast}=f_{1,\ast}: H(C)\to H(D)$.
	\end{lemma}
		\begin{proof}
		This is the same thing as saying that $(f_1-f_0)_\ast=0$. Let $c\in Z_n(C_\bullet)(C)$, so that $\partial c=0$. Well, $(f_1-f_0)_\ast c=(\partial h+h\partial)c=\partial hc+h\partial c=\partial hc$, so it's a boundary. Therefore, $f_{1,\ast}$ and $f_{0,\ast}$ have the same homology class (because when you take homology classes, you work modulo boundaries), which means we're done.
		\end{proof}
		\begin{proof}
		We have the map $S_\ast(X)\xrightarrow{\epsilon}\mathbf{Z}\xrightarrow{\eta}S_\ast(X)$ where the latter map sends $1$ to the constant map at the origin. The claim is that $\eta\epsilon\sim 1:S_\ast(X)\to S_\ast(X)$. Let's just mention that $\eta\epsilon(\sum a_ix_i)=(\sum a_i)c_0$ where $c_0$ is the zero-simplex that is constant at the origin. We want a homotopy $h:S_q(X)\to S_{q+1}(X)$, but it suffices to construct $\Sin_q(X)\to \Sin_{q+1}(X)$. For $\sigma\in\Sin_q(X)$, define $h:\Sin_q(X)\to\Sin_{q+1}(X)$ as follows:
		$$h\sigma(t_0,\cdots,t_{q+1})=(1-t_0)\sigma\left(\frac{(t_0,\cdots,t_{q+1})}{1-t_0}\right)$$
		I give up livetexing the proof; just read Hatcher.
		\end{proof}
% Continue indenting like this.
%\newpage
\section{Homotopy invariance of homology}
As a side product, we'll construct something called the cross product. Here's the theorem.
	\begin{theorem}
	If $f_0,f_1:X\to Y$ and $f_0\sim f_1$, then $f_{0,\ast}\sim f_{1,\ast}:S_\ast(X)\to S_\ast(Y)$.
	\end{theorem}
	\begin{corollary}
	With the same hypotheses, then $f_{0,\ast}=f_{1,\ast}: H_\ast(X)\to H_\ast(Y)$, because chain homotopic maps induce the same map on homology.
	\end{corollary}
The proof uses naturality (a lot). We'll produce a chain homotopy from the two inclusions $i_0,i_1:X\to X\times I$, and then homotope $f_0,f_1$ through a map $X\times I\to Y$. Namely, we'll construct a chain homotopy $h_X:S_n(X)\to S_{n+1}(X\times I)$ which gives a homotopy $i_{0,\ast}\sim i_{1,\ast}$, and this'll be natural in $X$.

This gives the result we want. We can get a homotopy $h:=g\circ h_\ast:S_n(X)\to S_{n+1}(X\times I)\to S_{n+1}(Y)$. Well:
		\begin{multline*}
		\partial h + h\partial = \partial(g_\ast h_\ast) + g_\ast h_\ast\partial=g_\ast\partial h_\ast + g_\ast h_\ast \partial = g_\ast(\partial h_\ast + h_\ast\partial)\\
		 = g_\ast(i_{1,\ast} - i_{0,\ast}) = g_\ast i_{1,\ast} - g_\ast i_{0,\ast} = (g\circ i_1)_\ast - (g\circ i_0)_{\ast} = f_{1,\ast} - f_{0,\ast}
		\end{multline*}
(The last equality is because $h_\ast$ is a chain homotopy between $i_{1,\ast}$ and $i_{0,\ast}$.) So $h=g_\ast\circ h_\ast$ is a chain homotopy. But how do we define $h_\ast:S_n(X)\to S_{n+1}(X\times I)$? You want to take $\sigma\mapsto``\sigma\times I''$. More generally, we'll set up a cross product $\times:S_p(X)\times S_q(Y)\to S_{p+q}(X\times Y)$ that is natural, bilinear, satisfy the Leibniz rule, and are normalized.

Naturality is exactly what you'd expect it to be. If $A,B,C$ are abelian groups, then $A\times B\to C$ is a bilinear map if $f(a+a^\prime,b)=f(a,b)+f(a^\prime,b)$ and similarly in the other variable (just substitute the $S_n(X)$ etc here). The Leibniz formula says:
		\begin{equation*}
		\partial(a\times b) = (\partial a)\times b + (-1)^{|a|}a\times\partial b,\quad\text{where }|a|=p\text{ means that }a\in S_p(X).
		\end{equation*}
The word normalized means that the following construction is correct. Suppose $q=0$; then this is a map $S_p(X)\to S_0(Y)\to S_p(X\times Y)$, which (it suffices to define a map $\Sin_p(X)\times \Sin_0(Y)\to S_p(X\times Y)$ because $\left(\sum_i a_i\sigma_i,\sum_j b_j\tau_j\right)\mapsto \sum_{i,j}a_ib_i(\sigma_i\times\tau_j)$ by bilinearity) sending:
		\begin{equation*}
		(\sigma, c^0_y)\mapsto \left(\begin{pmatrix}\sigma \\ c^p_y\end{pmatrix}:\Delta^p\to X\times Y\right)
		\end{equation*}
This latter map is just the composition $\Delta^p\xrightarrow{\sigma} X\xrightarrow{\text{inclusion at }y\in Y}X\times Y$. When $p=0$, we can send:
		\begin{equation*}
		(c^0_x,\tau)\mapsto \left(\begin{pmatrix}c^p_0 \\ \tau\end{pmatrix}:\Delta^p\to X\times Y\right)
		\end{equation*}
This latter map is just the composition $\Delta^p\xrightarrow{\tau} Y\xrightarrow{\text{inclusion at }x\in X}X\times Y$. We have to check that this behaves correctly for the boundary map, namely, that Leibniz holds. We have:
		\begin{equation*}
		\partial(\sigma\times c^0_y) = \partial\sigma\times c^0_y
		\end{equation*}
and similarly. We're going to use induction to define this for $p+q$; we've only done this for $p+q=0,1$. Let's assume it's done for $p+q-1$. First note that there's a universal example of a $p$-simplex, namely the map $\iota_p:\Delta^p\to \Delta^p$, because given any $p$-simplex $\sigma:\Delta^p\to X$, you get $\sigma=\sigma_\ast(\iota_p)$ where $\sigma_\ast:\Sin_p(\Delta^p)\to \Sin_p(X)$. It suffices to define $\iota_p\times\iota_q\in S_{p+q}(\Delta^p\times\Delta^q)$; you're supposed to think of the product of two simplices as a prism, which isn't a simplex itself - but you can triangulate it and look at it as the formal sum of two simplices. Then $\sigma\times \tau = (\sigma\times\tau)_\ast(\iota_p\times\iota_q)$ where $(\sigma\times\tau)_\ast:S_{p+q}(\Delta^p\times\Delta^q)\to S_{p+q}(X\times Y)$. We need this to satisfy the Leibniz rule, so that:
		\begin{equation*}
		S_{p+q-1}(\Delta^p\times\Delta^q)\ni \partial(\iota_p\times\iota_q) = (\partial\iota_p)\times\iota_q + (-1)^p\iota_p\times\partial\iota_q
		\end{equation*}
A necessary condition for $\iota_p\times\iota_q$ to exist is that $\partial((\partial\iota_p)\times\iota_q + (-1)^p\iota_p\times\partial\iota_q) =0$. Let's compute what this is.
		\begin{equation*}
		\partial((\partial\iota_p)\times\iota_q + (-1)^p\iota_p\times\partial\iota_q) = \partial^2(\iota_p)\times\iota_q + (-1)^{p-1}(\partial \iota_p)\times(\partial \iota_q) + (-1)^p(\partial\iota_p)\times(\partial\iota_q) + (-1)^q\iota_p\times\partial^2\iota_q = 0
		\end{equation*}
because $\partial^2=0$. 

The subspace $\Delta^p\times\Delta^q\subseteq\mathbf{R}^{p+1}\times\mathbf{R}^{q+1}$ is convex, so by translation, it's homeomorphic to a star-shaped region. But we know that $ H_{p+q-1}(\Delta^p\times\Delta^q)=0$ because $p+q>1$, which means that every cycle is a boundary. In other words, what we checked above is also sufficient! So, choose any element $\iota_p\times\iota_q$ with the right boundary. This means we're done if we check that this choice satisfies naturality, bilinearity, and the Leibniz rule (left to reader). We'll now define $h_X:S_n(X)\to S_{n+1}(X\times I)$ via $h_Xc = c\times\iota$ where $\iota:\Delta^1\to I$ is the obvious map. The cross product is in $S_{p+1}(X\times I)$. Let's compute:
		\begin{equation*}
		\partial h_X = \partial(c\times \iota) = \partial c\times\iota + (-1)^{|c|}c\times\partial\iota
		\end{equation*}
But now, $\partial\iota = c_1^0 - c_0^0\in S_0(I)$, which means that this becomes $\partial c\times\iota + (-1)^{|c|}(\iota_{1,\ast} - \iota_{0,\ast})$. We'll do a little more next time.
%\newpage
\section{Basically a recap of what we did last time}
PSet 1 due today. Last time, we showed:
\begin{theorem}
There exists a map $S_p(X)\times S_q(Y)\to S_{p+q}(X\times Y)$ that is:
	\begin{itemize}
	\item Natural, in the sense that if $f:X\to X^\prime$ and $g:Y\to Y^\prime$, and $a\in S_p(X)$ and $b\in S_p(Y)$ so that $a\times b\in S_{p+q}(X\times Y)$, then $f_\ast(a)\times g_\ast(b)=(f\times g)_\ast(a\times b)$.
	\item Bilinear, in the sense that $(a+a^\prime)\times b=(a\times b)+(a^\prime\times b)$, and $a\times (b+b^\prime)=a\times b+a\times b^\prime$.
	\item The Leibniz rule is satisfied, i.e., $\partial(a\times b)=(\partial a)\times b + (-1)^{|a|}a\times \partial b$.
	\item Normalized, in the following sense. Let $x\in X$ and $y\in Y$. Write $i_x:Y\to X\times Y$ sending $y\mapsto (x,y)$, and write $i_y:X\to X\times Y$ sending $x\mapsto (x,y)$. If $b\in S_q(Y)$, then $c^0_x\times b=(i_x)_\ast b\in S_q(X\times Y)$, and if $a\in S_p(X)$, then $a\times c^0_y=(i_y)_\ast a\in S_p(X\times Y)$.
	\end{itemize}
\end{theorem}
We were a little hasty in the end, so we're going to recall some things.
\begin{proof}[Proof sketch]
There were two steps.
\begin{enumerate}
\item It's enough to define $\iota_p\times \iota_q\in S_{p+q}(\Delta^p\times \Delta^q)$ where $\iota_n:\Delta^n\to\Delta^n$ is the identity, because every other simplex is $\iota_n$ pushed forward, and the cross product is supposed to be natural.
\item Induction on $p+q$. The first thing we use is the Leibniz rule, namely $\partial(\iota_p\times\iota_q) = (\partial\iota_p)\times\iota_q + (-1)^p\iota_p\times\partial\iota_q$. Is this a boundary? A necessary thing for anything to be a boundary is that it's a cycle. But because $\Delta^p\times\Delta^q$ is homeomorphic to a star-shaped region, it's contractible - therefore $ H_{p+q-1}(\Delta^p\times\Delta^q)=0$, a \emph{sufficient} condition for something to be a boundary is that it's a cycle! We showed that $\partial(\iota_p\times\iota_q)$ is a cycle, and therefore a boundary. We just need to choose \emph{some} class $[a]$ in $S_{p+q}(\Delta^p\times\Delta^q)$ such that $\partial([a])=(\partial\iota_p)\times\iota_q + (-1)^p\iota_p\times\partial\iota_q$, and this works.
\begin{enumerate}
\item Naturality is left to the reader.
\item Let's check the Leibniz rule. Let $\sigma:\Delta^p\to X$ and $\tau:\Delta^q\to Y$. What's $\partial(\sigma\times\tau)$? We start by asking how we define $\sigma\times \tau$. Well, this is just $\sigma_\ast\iota_p\times\tau_\ast\iota_q$. Because of naturality, this is just $(\sigma\times\tau)_\ast(\iota_p\times\iota_q)$. This means that $\partial(\sigma\times\tau)=\partial((\sigma\times\tau)_\ast(\iota_p\times\iota_q))$. Now, we can use the naturality of the boundary map to see that this is just $(\sigma\times\tau)_\ast\partial(\iota_p\times\iota_q)$, which we can expand as:
\begin{align*}
(\sigma\times\tau)_\ast\partial(\iota_p\times\iota_q)& =(\sigma\times\tau)_\ast((\partial\iota_p)\times\iota_q + (-1)^p\iota_p\times\partial\iota_q) \\
& = \sigma_\ast(\partial\iota_p)\times\tau_\ast\iota_q + (-1)^{p}(\sigma_\ast\iota_p\times\tau_\ast(\partial\iota_q))\\
& = \partial(\sigma_\ast\iota_p)\times\tau_\ast\iota_q + (-1)^{p}(\sigma_\ast\iota_p\times\partial(\tau_\ast\iota_q))\\
& = \partial\sigma\times\tau + (-1)^{p}\sigma\times\partial\tau
\end{align*}
\end{enumerate}
\end{enumerate}
\end{proof}
A key fact in this whole thing is that $ H_{p+q-1}(\Delta^p\times\Delta^q)=0$. This method of proof, namely of reducing to things that have zero homology (aka acyclic spaces) is called the \emph{method of acyclic models}.

What happens on the level of homology? Let's abstract a little bit. Suppose we have three chain complexes $A_\bullet$, $B_\bullet$, and $C_\bullet$, to be thought of as $S_\ast(X)$, $S_\ast(Y)$, and $S_\ast(X\times Y)$. Suppose we have maps $\times: A_p\times B_q\to C_{p+q}$ that satisfies bilinearity and the Leibniz formula. What does this induce in homology?
\begin{lemma}
This determines a bilinear map $ H_p(A)\times H_q(B)\xrightarrow{\times} H_{p+q}(C)$.
\end{lemma}
\begin{proof}
Let $[a]\in H_p(A)$ where $a\in Z_p(A)$ such that $\partial a=0$ (i.e., $a$ is a cycle). Let $[b]\in H_q(B)$ where $b\in Z_q(A)$ such that $\partial b=0$. We want to define $[a]\times [b]\in H_{p+q}(C)$. We hope that $[a]\times [b]=[a\times b]$. We need to check that $a\times b$ is a cycle; let's check. By Leibniz, $\partial(a\times b)=\partial a\times b+(-1)^pa\times\partial b$. Because $a,b$ are boundaries, this is zero. We still need to check that this thing is well-defined. Let's pick another $[a^\prime]=[a]$ and $[b^\prime]=[b]$. We want $[a\times b]=[a^\prime\times b^\prime]$. In other words, we need that $a\times b$ differs from $a^\prime\times b^\prime$ by a boundary. We can write $a^\prime=a+\partial\overline{a}$ and $b^\prime=b+\partial\overline{b}$. What's $a^\prime\times b^\prime$? It's:
	\begin{equation*}
	a^\prime\times b^\prime=(a+\partial\overline{a})+(b+\partial\overline{b})
	= a\times b+\left(a\times\partial\overline{b} + (\partial\overline{a})\times b+(\partial\overline{a})\times(\partial\overline{b})\right)
	\end{equation*}
But, well, $\partial(a\times\overline{b})=\partial a\times\overline{b}+(-1)^pa\times\partial\overline{b}=(-1)^pa\times\partial\overline{b}$, and $\partial(\overline{a}\times b)=\partial\overline{a}\times b$, and $\partial(\overline{a}\times\partial\overline{b})=\partial\overline{a}\times\partial\overline{b}$. This means that $a^\prime\times b^\prime=a\times b+\partial((-1)^{-p}(a\times \overline{b}) + \overline{a}\times b + \overline{a}\times\partial\overline{b})$. They differ by a boundary, so it's well-defined.

The last step is to check bilinearity, which is left to the reader.
\end{proof}
This gives the following result.
\begin{theorem}
There is a map $ H_p(X)\times H_q(Y)\to H_{p+q}(X\times Y)$ that's natural, bilinear, and normalized. This map is also \emph{unique} (unlike the map $S_p(X)\times S_q(Y)\to S_{p+q}(X\times Y)$, which isn't unique because we there are uncountably many choices of $\iota_p\times\iota_q$, all differing by a boundary), because the map $\times:S_p(X)\times S_q(Y)\to S_{p+q}(X\times Y)$ is unique up to chain homotopy!
\end{theorem}
Let's go back to homotopy invariance. Recall that if $f_0\sim f_q:X\to Y$, then $f_{0,\ast}=f_{1,\ast}:S_\ast(X)\to S_\ast(Y)$. We proved this by showing that this reduces to showing that the two inclusions $i_0,i_1:X\to X\times I$ induce the same map on $S_\ast(X)\to S_\ast(X\times I)$. The chain homotopy $h_X:i_{0,\ast}\sim i_{1,\ast}$ is defined as follows. Let $c\in S_p(X)$. We need to give an element of $S_{p+1}(X\times I)$, so if $\iota:\Delta^1\to I$ is the obvious map, we just define $h_X(c)=(-1)^p c\times\iota$. Let's check that.

Let's compute $\partial h_Xc$. This is $\partial((-1)^p c\times \iota)=(-1)^p\partial(c\times\iota)$, which, expanded out, is:
	\begin{equation*}
	\partial((-1)^p c\times \iota)=(-1)^p\partial(c\times\iota)=(-1)^p(\partial c)\times\iota+(-1)^{2p}c\times\partial\iota
	\end{equation*}
Well, $\partial\iota=c_1^0-c_0^0\in S_0(I)$, so this is equal to $(-1)^p(\partial c)\times\iota+c\times c^0_1 - c\times c_0^0$. But $c\times c^0_1=(i_1)_\ast c-(i_0)_\ast c$. Therefore, this is $(-1)^p(\partial c)\times\iota + (i_1)_\ast c-(i_0)_\ast c$. On the other hand, what's $h_X\partial c=(-1)^{p-1}(\partial c)\times\iota$. Let's add them together:
	\begin{equation*}
	\partial h_Xc+h_X\partial c=(-1)^p(\partial c)\times\iota + (i_1)_\ast c-(i_0)_\ast c+(-1)^{p-1}(\partial c)\times\iota=(i_1)_\ast c - (i_0)_\ast c
	\end{equation*}
So this is, by definition, a chain homotopy!

I just want to mention that there's an explicit choice of $\iota_p\times\iota_q$. This is called the Eilenberg-Zilber chain. You're highly encouraged to think about this yourself. We're going to consider $\Delta^{p+q}\to\Delta^p\times\Delta^q$. They're all affine maps, sending vertices to pairs of vertices. We're going to think of an ordered map $\omega:[p+q]\to[p]\times[q]$. We can complete the diagram to get:
	\begin{equation*}
	\xymatrix{ & [p]\\
	[p+q]\ar[ur]^{pr_2\omega}\ar[dr]_{pr_1\omega}\ar[r]^\omega & [p]\times[q]\ar[u]^{pr_2}\ar[d]^{pr_1}\\
	 & [q]}
	\end{equation*}
We also want $\omega$ to be injective (which requires that it takes $(0,0)$ to $(p,q)$). We can draw out a ``staircase'' in the $p\times q$ grid, and the area under the staircase defined by $\omega$ is denote $A(\omega)$. Define $\iota_p\times\iota_q=\sum(-1)^{A(\omega)}\overline{\omega}$ where $\overline{\omega}$ is the corresponding affine map $\Delta{p+q}\to\Delta^p\times\Delta^q$. It's combinatorially annoying to check that this satisfies the conditions of the theorem, but it's a good exercise to check it out. It's in a paper by Eilenberg-Moore.
%\newpage
\section{Relative Homology}
First, let's recall a little about homology. We showed that homology factors as a functor $\mathbf{Top}\to\mathrm{h}\mathbf{Top}\to\mathbf{GrAb}$. As a corollary:
\begin{corollary}
If $f:X\to Y$ is a homotopy equivalence (i.e., an isomorphism in the homotopy category), the induced map on homology $ H_\ast(f): H_\ast(X)\to H_\ast(Y)$ is an isomorphism. This is the same thing as saying that if $f:X\to Y$ does not induce an isomorphism on homology, then $f$ can't be a homotopy equivalence. Homology's therefore often used to distinguish spaces.
\end{corollary}
\begin{example}
If $X\times\mathbf{R}^n\to X$ is the projection map, this is a homotopy equivalence because $\mathbf{R}^n$ is contractible. Therefore, $ H_\ast(X\times\mathbf{R}^n)\cong H_\ast(X)$.
\end{example}
\subsection{Towards computing homology}
Fix a space $W$, and consider the functor $X\mapsto [W,X]$. This is basically uncomputable - if you could, you'll win a Fields medal! But there's something more that homology has going for it is that it's ``local''. What do we mean by this? Homology is a bit like a measure:
	\begin{enumerate}
	\item If $A\subseteq X$ is a subspace, then $ H_\ast(X)$ is related to $ H_\ast(A)+ H_\ast(X-A)$. Called the lexseq of a pair.
	\item The homology $ H_\ast(A\cup B)$ is like $ H_\ast(A)+ H_\ast(B)- H_\ast(A\cap B)$. Called the Mayer-Vietoris sequence.
	\end{enumerate}
The thing we use is the notion of exact sequences. Let me tell you about exact sequences.
\subsection{Exact sequences}
This is a story about abelian groups.
\begin{definition}
Let $A\xrightarrow{i} B\xrightarrow{p} C$ be a sequence of abelian groups and homomorphisms. We say that the sequence is exact (at $B$) if $\ker p=\img i$, i.e., $p\circ i=0$ with no room for error.
\end{definition}
\begin{example}
If you have a chain complex $\cdots\to C_{n+1}\to C_n\to C_{n-1}\to\cdots$, it's exact at $C_n$ if the homology $ H_n(C)$ in dimension $n$ is zero. So homology is the obstruction to exactness. 
\end{example}
\begin{example}
$0\to A\xrightarrow{i}B$ is exact iff $i$ is injective, and $B\xrightarrow{p}C\to 0$ is exact iff $p$ is surjective.
\end{example}
There's a beautiful book by Eilenberg and Steenrod, published in 1952, which was the founding of algebraic topology.
\begin{example}
If you have a sequence that's exact at every point, it's called a long exact sequence (henceforth called lexseq in these notes). If you have a sequence like $0\to A\xrightarrow{i} B\xrightarrow{p} C\to 0$ that's exact, then this is called a short exact sequence (henceforth called sexseq in these notes). This means that $p\circ i=0$, $i$ is injective, $p$ is surjective. Also, this sequence factors like:
	\begin{equation*}
	\xymatrix{\ker(p) \ar[dr] & & \\
	A\ar[u]\ar[r]^i & B\ar[r]^p\ar[dr] & C\\
	 & & \mathrm{coker}(i)\ar[u]}
	\end{equation*}
So $A\cong \ker p$ and $B\cong \mathrm{coker}(i)$. These things are equivalence to short exactness. 
\end{example}
Let's see how this appears in algebraic topology.
\begin{definition}
A pair of spaces is a space $X$ together with subspaces $A\subseteq X$, denoted $(X,A)$. We have a new category, called $\mathbf{Top}_2$ where morphisms $(X,A)\to (Y,B)$ are maps $f:X\to Y$ that take $A\to B$. There are two functors $\mathbf{Top}\to \mathbf{Top}_2$, sending $X\mapsto (X,\emptyset)$ and $X\mapsto (X,X)$. There are also two functors back to $\mathbf{Top}$, sending $(X,A)\mapsto A$ or $(X,A)\mapsto X$.
\end{definition}
How does this behave on the level of chain complexes? If I have a pair $(X,A)$, I get a map $\Sin_n(A)\to \Sin_n(X)$ that's clearly injective. Is this a split monomorphism? Yes, unless $A=\empty$, because you can choose a point in $A$ and send everything not in $A$ to that point. Let's now apply the free abelian group functor to get $S_n(A)\to S_n(X)$. Is this a monomorphism? Yes, because monomorphisms are preserved by this functor. This is also split because being a split mono is a categorical property. This is split even when $A=\empty$ because then $S_n(\empty)=0$.
\begin{definition}
The relative $n$-chains is defined as $S_n(X,A):= S_n(X)/S_n(A)$. So we have a sexseq (ses) $0\to S_n(A)\to S_n(X)\to S_n(X,A)\to 0$. Is $S_n(X,A)$ free abelian if $S_n(X)$ and $S_n(A)$ are? If you have a ses $0\to A\to B\to C\to 0$ such that $A\to B$ is split, then it's homework to show that $B\cong A\oplus C$. So $C$ must also be free abelian if $B$ and $A$ are; i.e., $S_n(X,A)$ is free abelian.
\end{definition}
\begin{example}
Consider $\Delta^n$, which contains its boundary $\partial\Delta^n:=\bigcup \img d_i\simeq S^{n-1}$. We have the identity map $\iota_n:\Delta^n\to \Delta^n$, the universal $n$-simplex, which is in $\Sin_n(\Delta^n)\subseteq S_n(\Delta^n)$. Its boundary $\partial\iota_n\in S_{n-1}(\Delta^n)$, but it actually lands in $S_{n-1}(\partial\Delta^n)$. So $\partial\iota_n$ is \emph{not} a boundary in $\partial\Delta^n$, as we'll see, but it certainly is a cycle. So it determines a homology class, $[\partial\iota_n]$, which, it turns out, generates $ H_{n-1}(\partial\Delta^n)\simeq H_{n-1}(S^{n-1})\cong\mathbf{Z}$.

I can think of $\iota_n\in S_n(\Delta^n,\partial\Delta^n)$, or rather the class of it mod $S_n(\partial\Delta^n)$. It's a relative chain. Is it a cycle? Let's branch off a bit.
\end{example}
Consider the ses $0\to S_n(A)\to S_n(X)\to S_n(X,A)\to 0$. A $c\in S_n(X)$ determines a relative cycle if $\partial c\in S_{n-1}(A)$. I'm sorry, I've messed this up a little bit. There's so much to say here. I'm getting ahead of myself a little bit here. What I meant to say is, let's think of what $\partial$ does. We have a map of ses:
\begin{equation*}
\xymatrix{0\ar[d]\ar[r] & S_n(A)\ar[d]\ar[r] & S_n(X)\ar[d]\ar[r] & S_n(X,A)\ar@{-->}[d]\ar[r] & 0\ar[d]\\
0\ar[r] & S_{n-1}(A)\ar[r] & S_{n-1}(X)\ar[r] & S_{n-1}(X,A)\ar[r] & 0}
\end{equation*}
Does the dotted map exist? We can pull $\overline{c}\in S_n(X,A)$ to some $c\in S_n(X)$, and then define $\partial\overline{c}$ to be the pushforward of $\partial c$. Is this well-defined? If $c,c^\prime$ both map to $\overline{c}$, then $c-c^\prime=0$, so there's some $a$ in $S_n(A)$ that is sent to $c-c^\prime$, and $\partial$ pushes this forward to say that $\partial a$ maps to $\partial(c-c^\prime)=\partial c-\partial c^\prime$. Since we're quotienting out by $S_{n-1}(A)$, this means that the pushforwards of $\partial c$ and $\partial c^\prime$ are the same. I'll leave it to you (although Professor Miller explained this in detail) to show that $\partial^2=0$. 

Now let's continue. A class $c\in S_n(X)$ gives a relative cycle if and only if $\partial c\in S_{n-1}(A)$ because we want $\partial c$ in $S_n(X,A)$ to be zero. So $\iota_n\in S_n(\Delta^n,\partial\Delta^n)$ is indeed a relative cycle since $\partial\iota_n\in S_{n-1}(\partial\Delta^n)$. Similarly, a class $c\in S_n(X)$ is a relative boundary if and only if there is a $b\in S_{n+1}(X)$ such that $\partial b=c\bmod S_n(A)$, i.e., $\partial b-c\in S_n(A)$. So $\iota_n\in S_n(\Delta^n,\partial\Delta^n)$ isn't a relative boundary. Therefore $ H_n(\Delta^n,\partial\Delta^n)\cong\mathbf{Z}=\langle[\iota_n]\rangle$ where $ H_n(X,A)$ denotes the relative homology. This stuff takes a little bit of time to get used to.
%\newpage
\section{Long exact homology sequence, Excision, and Genealogy}
WARNING: I've probably messed up typing some indices. Hopefully not.
\subsection{5-lemma}
Suppose you have two exact sequences of abelian groups.
\begin{equation*}
\xymatrix{A_4\ar[r]^d\ar[d]^{f_4} & A_3\ar[r]^d\ar[d]^{f_3} & A_2\ar[r]^d\ar[d]^{f_2} & A_1\ar[r]^r\ar[d]^{f_1} & A_0\ar[d]^{f_0}\\
B_4\ar[r]^d & B_3\ar[r]^d & B_2\ar[r]^d & B_1\ar[r]^r & B_0}
\end{equation*}
When can we guarantee that $f_2$ is an isomorphism? We're going to diagram chase :-(. Just follow your nose.

Let $b_2\in B_2$. We want to show that there is something in $A_2$ that can be pushed forward to $b_2$, i.e., prove surjectivity of $f_2$. We can consider $db_2\in B_1$. Let's assume that $f_1$ is surjective. Then there's $a_1\in A_1$ such that $f_1(a_1)=db_2$. What is $da_1$? Well, $f_0(da_1)=d(f_1(a_1))=d(db)=0$. So we want $f_0$ to be injective. Then $da_1$ is zero, so by exactness of the top sequence, there is some $a_2\in A_2$ such that $da_2=a_1$. What is $f_2(a_2)$? What is $d(f_2(a_2))$? By commutativity, $d(f_2(a_2))=f_1(d(a_2))=f_1(a_1)=db_2$. Let's consider $b_2-f_2(a_2)$. This maps to zero under $d$. So by exactness, there is $b_3\in B_3$ such that $d(b_3)=b_2-f_2(a_2)$. If we assume that $f_3$ is surjective, then there is $a_3\in A_3$ such that $f_3(a_3)=b_3$. But now, $d(a_3)\in A_2$, and $f_2(d(a_3))=d(f_3(a_3))=b_2-f_2(a_2)$. But this means that $b_2=f(a_2+d(a_3))$, which guarantees surjectivity of $f_2$. This means that if $f_1$ is surjective, $f_0$ is injective, and $f_3$ is surjective, then $f_2$ is surjective.

A similar dual process says that $f_2$ is injective if $f_1$ is injective, $f_3$ is injective, and $f_4$ is surjective. If all of these conditions are satisfied, then $f_2$ is an isomorphism. This is the content of the five-lemma.
\subsection{Relative homology}
I guess I didn't really define this. Suppose you have a pair of spaces $(X,A)$. Then you have an sexseq of chain complexes $0\to S_\ast(A)\to S_\ast(X)\to S_\ast(X,A)\to 0$. 
\begin{definition}
The relative homology of the pair $ H_\ast(X,A):= H(S_\ast(X,A))$.
\end{definition}
\begin{example}
$ H_\ast(X,\emptyset)= H_\ast(X)$ because $S_\ast(\emptyset)=0$. Another case is $ H_\ast(X,X)=0$ because $S_\ast(X,X)=S_\ast(X)/S_\ast(X)=0$.
\end{example}
\subsection{General study of homologies of sexseqs of chain complexes}
Suppose I have three chain complexes $A_\bullet\to B_\bullet\to C_\bullet$. By the way, this is an important announcement. Henceforth, differentials in chain complexes will be denoted $d$, no longer $\partial$. For some reason. (It's so much easier for typing as well.) Assume that this is an exact sequence of chain complexes.

Is $ H_\ast(A)\to H_\ast(B)\to H_\ast(C)$ exact? Let's push this a little further. Suppose I have a sexseq $0\to A_\bullet\to B_\bullet\to C_\bullet\to 0$. We can ask the same question as before. Let's write this out more explicitly.
\begin{equation*}
\xymatrix{0\ar[r] & A_{n+1}\ar[r]^f\ar[d]^d & B_{n+1}\ar[r]^g\ar[d]^d & C_{n+1}\ar[r]\ar[d]^d & 0\\
0\ar[r] & A_n\ar[r]^f\ar[d]^d & B_n\ar[r]^g\ar[d]^d & C_n\ar[r]\ar[d]^d & 0\\
0\ar[r] & A_{n-1}\ar[r]^f & B_{n-1}\ar[r]^g & C_{n-1}\ar[r] & 0}
\end{equation*}
Let $[b]\in H_n(B)$ such that $g([b])=0$. It's determined by some $b\in B_n$ such that $d(b)=0$. If $g([b])=0$, then there is some $\overline{c}\in C_{n+1}$ such that $d\overline{c}=gb$. Now, $g$ is surjective, so there is some $\overline{b}\in B_{n+1}$ such that $g(\overline{b})=\overline{c}$. Then we can consider $d\overline{b}\in B_n$, and $g(d(\overline{b}))=d(\overline{c})\in C_n$. What is $b-d\overline{b}$? This maps to zero in $C_n$, so by exactness there is some $a\in A_n$ such that $f(a)=b-d\overline{b}$. Is $a$ a cycle? Well, $f(da)=d(fa)=d(b-d\overline{b})=db-d^2\overline{b}=db$, but we assumed that $db=0$, so $f(da)=0$. This means that $da$ is zero because $f$ is an injection by exactness. Therefore $a$ is a cycle. What is $[a]\in H_n(A)$? Well, $f([a])=[b-d\overline{b}]=[b]$ because $d\overline{b}$ is a cycle. Is the composite $ H_n(A)\to H_n(B)\to H_n(C)$ zero? Yes, because the composite factors through zero. This proves exactness of $ H_n(A)\to H_n(B)\to H_n(C)$.

\begin{theorem}[lexseq in homology]
Let $0\to A_\bullet\to B_\bullet\to C_\bullet\to 0$ be a sexseq of chain complexes. Then there is a natural homomorphism $\partial: H_n(C)\to H_{n-1}(A)$ such that there's lexseq:
\begin{equation*}
\xymatrix{ & & \ar[dll]^\partial\\
 H_n(A)\ar[r] & H_n(B)\ar[r] & H_n(C)\ar[dll]^\partial\\
 H_{n-1}(A)\ar[r] & H_{n-1}(B)\ar[r] & H_{n-1}(C)\ar[dll]^\partial\\
 & & &}
\end{equation*}
\end{theorem}
\begin{proof}
We'll construct $\partial$, and leave the rest as an exercise. We have our sexseq:
\begin{equation*}
\xymatrix{0\ar[r] & A_{n+1}\ar[r]^f\ar[d]^d & B_{n+1}\ar[r]^g\ar[d]^d & C_{n+1}\ar[r]\ar[d]^d & 0\\
0\ar[r] & A_n\ar[r]^f\ar[d]^d & B_n\ar[r]^g\ar[d]^d & C_n\ar[r]\ar[d]^d & 0\\
0\ar[r] & A_{n-1}\ar[r]^f & B_{n-1}\ar[r]^g & C_{n-1}\ar[r] & 0}
\end{equation*}
Let $c\in C_n$ such that $dc=0$. The map $g$ is surjective, so pick a $b\in B_n$ such that $g(b)=c$. Then consider $db\in B_{n-1}$. But $g(d(b))=0=d(g(b))=dc$. So by exactness, there is some $a\in A_{n-1}$ such that $f(a)=db$. How many choices are there of picking $a$? One, because $a$ is injective. We need to check that $a$ is a cycle. What is $d(a)$? Well, $d^2b=0$, so $da$ maps to $0$ under $f$. But because $f$ is injective, $da=0$, i.e., $a$ is a cycle. This means we can define $\partial[c]=[a]$.

To make sure that this is well-defined, let's make sure that this choice of homology class $a$ didn't depend on the $b$ that we chose. Pick some other $b^\prime$ such that $g(b^\prime)=c$. Then there is $a^\prime\in A_{n-1}$ such that $f(a^\prime)=db^\prime$. We want $a-a^\prime$ to be a boundary, so that $[a]=[a^\prime]$. We want $\overline{a}\in A_n$ such that $d\overline{a}=a-a^\prime$. Well, $g(b-b^\prime)=0$, so by exactness, there is $\overline{a}\in A_n$ such that $f(\overline{a})=b-b^\prime$. What is $d\overline{a}$? Well, $d\overline{a}=d(b-b^\prime)=db-db^\prime$. But $f(a-a^\prime)=b-b^\prime$, so because $f$ is injective, $d\overline{a}=a-a^\prime$, i.e., $[a]=[a^\prime]$. What else do I have to check? It's an exercise to check that $\partial$ as defined here is a homomorphism. Also, left as an exercise to check that this doesn't depend on $c\in[c]$, and that $\partial$ actually makes the exact sequence above exact.
\end{proof}
\subsection{Mathematical Genealogy}
I'm not typing in anything here. It's a rather big tree:
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{math-family}
\caption{Mathematical genealogy, growing from Lefschetz, who was initially a chemist. The asterisks are meant to indicate that someone's at MIT.}
\end{figure}
%\newpage
\section{Excision, and the Eilenberg-Steenrod axioms}
We have homotopy invariance and the lexseq of a pair. We claimed that $ H_\ast(X,A)$ ``depends only on $X-A$''. You have to be careful about this. 
\begin{definition}
A triple $(X,A,U)$ where $U\subseteq A\subseteq X$ is \emph{excisive} if $\overline{U}\subseteq\mathrm{Int}(A)$. This is a point-set definition. From an excisive triple you can get a pair $(X-U,A-U)\subseteq (X,A)$, and this is called an exision.
\end{definition}
\begin{theorem}
An excision induces an isomorphism in homology, i.e., $ H_\ast(X-U,A-U)\cong H_\ast(X,A)$. We might prove this on Wednesday.
\end{theorem}
What are some consequences? We'll compute $ H_\ast(S^n)$ and $ H^\ast(D^n,S^{n-1})$. Here's the result. We'll use the homeomorphisms $D^n\simeq \Delta^n$ and $S^{n-1}\simeq\partial\Delta^n$. Let's write $S^0=\{0,1\}$, and $\iota_n:\Delta^n\to\Delta^n$.
\begin{theorem}
	\begin{enumerate}
	\item \begin{equation*}
	 H_q(S^n)=\begin{cases}\Z = \langle[c^0_\ast]\rangle & q=0,n>0\\ \Z\oplus\Z = \langle[c^0_1],[\partial\iota_1]\rangle & q=n=0 \\ \Z = \langle[\partial\iota_{n+1}]\rangle & q=n>0 \\ 0 & \text{else} \end{cases}
	\end{equation*}

	\item \begin{equation*}
	 H_q(D^n,S^{n-1}) = \begin{cases}
	\Z=\langle [\iota_n]\rangle & q=n\\
	0 & \text{else}
	\end{cases}
	\end{equation*}
	\end{enumerate}
\end{theorem}
If $n=0$, then we say that $S^{-1}=\emptyset$. What are the generators of these groups?
\begin{proof}
We'll use the lexseq, homotopy invariance, and excision. We have the lexseq:
\begin{equation*}
\xymatrix{ & & \ar[dll]^\partial\\
 H_q(S^{n-1})\ar[r] & H_q(D^n)\ar[r] & H_q(D^n,S^{n-1})\ar[dll]^\partial\\
 H_{1-1}(S^{n-1})\ar[r] & H_{q-1}(D^n)\ar[r] & H_{q-1}(D^n,S^{n-1})\ar[dll]^\partial\\
 & & &}
\end{equation*}
But we know that $D^n$ is contractible, so $ H_q(D^n)=\begin{cases}\Z & q=n\\ 0 & \text{else}\end{cases}$. This means that $\partial: H_q(D^n,S^{n-1})\cong H_{q-1}(S^{n-1})$ for $q>1$, but when $q=1$, we get $0\to H_1(D^n,S^{n-1})\xrightarrow{\partial} H_0(S^{n-1})\to H_0(D^n) \to H_0(D^n,S^{n-1})\to 0$.

Let's think about the case $n>1$. Then $ H_0(S^{n-1})=\mathbf{Z}=\langle[c^0_\ast]\rangle$, and $ H_0(D^n)=\Z=\langle[c^0_\ast]\rangle$, so you have an isomorphism, which means that $ H_0(D^n,S^{n-1})=0$ and $ H_1(D^n,S^{n-1})=0$. Now, let's go to the case $n=1$. Then $ H_0(S^0)=\Z\oplus\Z=\langle [c^0_\ast],[\partial\iota_1]\rangle$ and $ H_0(D^0)=\Z$. But $[\partial\iota_1]$ goes to zero, and $[c^0_\ast]$ goes to the generator of $\Z= H_0(D^0)$. This means that $ H_1(D^1,S^0)$ is generated by $\langle[\iota_1]\rangle\cong\Z$ because the map $ H_1(D^n,S^{n-1})\to H_0(S^{n-1})$ is the boundary map, so $[\iota_1]\mapsto [\partial\iota_1]$.

Excision will come into play through the following statement.
\begin{prop}
If $n>1,q>1$, then $ H_q(D^n,S^{n-1})\to H_q(D^n/S^{n-1},\ast)\cong H_q(S^n,\ast)\cong H_q(S^n)$, because $D^n/S^{n-1}\simeq S^n$. The claim is that this collapse map is an isomorphism.
\end{prop}
This provides the inductive step. Let's assume we've proved the proposition. Then $ H_q(D^n,S^{n-1})\cong H_{q-1}(S^{n-1})$. The proposition says that $ H_q(S^n)\cong H_{q-1}(S^{n-1})$. But we also have the boundary map $\partial: H_{q+1}(D^n,S^{n-1})\cong H_q(S^n)$, i.e., $ H_{q+1}(D^n,S^{n-1})\cong H_q(D^n,S^{n-1})$.

Now I want to prove the proposition. 
\begin{proof}[Proof of proposition]
We want to compare $ H_q(D^n,S^{n-1})$ and $ H_q(D^n/S^{n-1},\ast)$. We'll use excision to do this. We have $D^n=\{ x\in\mathbf{R}^{n+1} | |x|\leq 1 \}$. Let $A=\{ x|1/3\leq |x|\leq 1 \}$ and $U=\{ x|2/3<|x|\leq 1 \}$, and $\{ x||x|=1 \} =S^{n-1}\subseteq U$. We need a preliminary step. $ H_q(D^n,S^{n-1})\to H_q(D^n,A)$. We claim that this an isomorphism, but this is true because of the lexseq and the 5-lemma. By excision, $ H_q(D^n,A)\cong H_q(D^n-U,A-U)$. We can collapse the $(n-1)$-sphere, and $(D^n/S^{n-1}-U/S^{n-1},A/S^{n-1}-U/S^{n-1})=(D^n-U,A-U)$ because you're collapsing something from something that's already been collapsed! Now, we claim that $ H_q(D^n/S^{n-1}-U/S^{n-1},A/S^{n-1}-U/S^{n-1})\cong H_q(D^n/S^{n-1},A/S^{n-1})$, which is true by excision. THE FOLLOWING PART IS MOST DEFINITELY NOT RIGHT\footnote{My own comment: this proof can be finished by noticing that $A\simeq S^{n-1}$ via $\mathbf{v}\mapsto\frac{\mathbf{v}}{||\mathbf{v}||}$, and that $D^n/S^{n-1}\simeq S^n$.}. But also, $ H_q(D^n/S^{n-1},\text{disk})= H_q(D^n/S^{n-1},A/S^{n-1})$. Because the disk is contractible, using the lexseq and the 5-lemma completes the proof of the proposition.
\end{proof}
\end{proof}
``This really turns me on, because I love homology.'' Why should you care about homology?
\begin{corollary}
If $m\neq n$, then $S^m\not\simeq S^n$ because they have different homology groups. 
\end{corollary}
\begin{corollary}
If $m\neq n$, then $\mathbf{R}^m\not\cong \mathbf{R}^n$, because they're not homeomorphic.
\end{corollary}
\begin{proof}
Let $m,n>0$. Assume we have a homeomorphism $f:\mathbf{R}^m\to \mathbf{R}^n$. This restricts to $\mathbf{R}^m-\{0\}\to \mathbf{R}^n-\{0\}$, but each of these are homotopy equivalent to spheres, but we can't get a homotopy equivalence between two spheres of different dimension by the above corollary.
\end{proof}
\subsection{Eilenberg-Steenrod axioms}
\begin{definition}
A homology theory (on $\mathbf{Top}$) is:
\begin{itemize}
\item a functor $h_n:\mathbf{Top}_2\to\mathbf{Ab}$ for all $n$. We'll write $h_n(X)=h_n(X,\emptyset)$
\item natural transformations $\partial:h_n(X,A)\to h_{n-1}(A)$.
\end{itemize}
such that:
\begin{itemize}
\item if $f_0,f_1:(X,A)\to (Y,B)$ are homotopic, then $f{0,\ast}\simeq f_{1,\ast}:h_n(X,A)\to h_n(Y,B)$.
\item an excision induces isomorphisms.
\item a lexseq:
\begin{equation*}
\cdots\to h_{q+1}(X,A)\xrightarrow{\partial}h_q(A)\to h_q(X)\to h_q(X,A)\xrightarrow{\partial}\cdots
\end{equation*}
\item (the dimension axiom): $h_n(\ast)$ is nonzero only in dimension zero. This is like the parallel postulate.
\end{itemize}
\end{definition}
\begin{example}
Ordinary singular homology satisfies these. 
\end{example}
\begin{theorem}[Brouwer fixed-point theorem]
If $f:D^n\to D^n$, then there is some point $x\in D^n$ such that $f(x)=x$.
\end{theorem}
\begin{proof}
Suppose not. Then you can draw a ray from $x$ to $f(x)$ to the boundary $S^{n-1}$, intersecting at a point $g(x)$. Left to you to check that $g$ is continuous. If $x$ was on the boundary, then $x=g(x)$. This is inconsistent by our computation because otherwise the identity on $ H_{n-1}(S^{n-1})$ would be zero, contradiction!
\end{proof}
%\newpage
\section{Application of our previous calculation of $ H_\ast(S^n)$ and the ``locality principle''}
\begin{theorem}
Let $n\geq 1$. There is a surjective monoid homomorphism $[S^n,S^n]\to \Z_\times$, where $\Z_\times$ is the multiplicative monoid of $\Z$. $[S^n,S^n]$ is a monoid under composition. (This is basically the degree...)
\end{theorem}
\begin{proof}
Given $f:S^n\to S^n$, take the homology, which is just a homomorphism $\Z\to \Z$, all of which are simply multiplication by an integer. The integer by which you're multiplying to get this homomorphism is the integer associated to $f$.

Construction. If $n=1$, this is just the winding number. Suppose I've constructed this in dimension $n-1$. We have:
	\begin{equation*}
	\xymatrix{ H_{n-1}(S^{n-1})\ar[d]^n & \ar[l] H_n(D^n,S^{n-1})\ar[r]\ar[d] & H_n(S^n)\ar[d]\\
	 H_{n-1}(S^{n-1}) & \ar[l] H_n(D^n,S^{n-1})\ar[r] & H_n(S^n)}
	\end{equation*}
So we're basically suspending $f:S^{n-1}\to S^{n-1}$. More explicitly, if you have $f:S^{n-1}\to S^{n-1}$. We can extend to $\overline{f}:D^n\to D^n$ by sending $tx\mapsto tf(x)$ where $tx$ denotes the ray connecting $x\in S^{n-1}$ to the origin, and we can then quotient out by $S^{n-1}$ to get the map $S^n\to S^n$ as required.
\end{proof}
\subsection{Addendum to the ES axioms}
There's a further axiom, which isn't due to ES, but rather due to Milnor. It's this.
\begin{itemize}
\item Suppose $I$ a set. For each $\alpha\in I$ there's have a space $X_\alpha\in\mathbf{Top}$. I can consider $\coprod_\alpha X_\alpha$. There are inclusion maps $X_\alpha\to\coprod_\alpha X_\alpha$. Then $\bigoplus_\alpha h_n(X_\alpha)\cong h_n\left(\coprod_\alpha X_\alpha\right)$.
\end{itemize}
This is known for ordinary singular homology.
\subsection{Homological algebra}
\begin{enumerate}
\item Suppose $A,B\subseteq C$ are abelian groups. Then $A+C\subseteq C$. You have a sexseq $0\to A\cap B\to A\oplus B\to A+C\to 0$ where the map $c\mapsto (c,-c)$ is how the map $A\cap B\to A\oplus B$ is defined.
\item ``Fundamental isomorphism for abelian groups'' says the following. We have two sexseqs.
	\begin{equation*}
	\xymatrix{0\ar[r] & A\cap B\ar[r]\ar[d] & B\ar[r]\ar[d] & B/A\cap B\ar[r]\ar@{-->}[d]^\cong & 0\\
	0\ar[r] & A\ar[r] & A+B\ar[r] & (A+B)/A\ar[r] & 0}
	\end{equation*}
	I'm not going to write out the diagram chase that we did.
\item ``Snake lemma''. Suppose I have\footnote{``It's my Turn'', Jill Clayburgh}:
	\begin{equation*}
	\xymatrix{ & \ker f^\prime\ar[r]\ar[d] & \ker f\ar[r]\ar[d] & \ker f^{\prime\prime}\ar[d]\\
	0\ar[r] & A^\prime\ar[r]\ar[d]^{f^\prime} & A\ar[r]\ar[d]^f & A^{\prime\prime}\ar[r]\ar[d]^{f^{\prime\prime}} & 0\\
	0\ar[r] & B^\prime\ar[r]\ar[d] & B\ar[r]\ar[d] & B^{\prime\prime}\ar[r]\ar[d] & 0\\
	 & \coker f^\prime\ar[r] & \coker f\ar[r] & \coker f^{\prime\prime}}
	\end{equation*}
	Claim is that there's a map $\ker f^{\prime\prime}\to\coker f$ so that $0\to \ker f^\prime\to \ker f\to \ker f^{\prime\prime}\to\coker f^\prime\to\coker f\to \coker f^{\prime\prime}\to 0$. This is basically the lexseq in homology associated to the sexseqs of the following three chain complexes: $0\to A^\prime\to B^\prime\to 0$, $0\to A\to B\to 0$, and $0\to A^{\prime\prime}\to B^{\prime\prime}\to 0$. Work this out yourself.
\end{enumerate}
\subsection{Locality}
\begin{definition}
The (not necessarily open) cover of a topological space. Won't write this.
\end{definition}
\begin{definition}
Let ${\mathscr{A}}$ be a cover of $X$. An $n$-simplex $\sigma$ is ${\mathscr{A}}$-small if there is $A\in \mathscr{A}$ such that the image of $\sigma$ is entirely in $A$.
\end{definition}
Notice that if $\sigma:\Delta^n\to X$ is ${\mathscr{A}}$-small, then so is $d^i\sigma$. Let's denote by $\Sin^{\mathscr{A}}_n(X)$ the set of ${\mathscr{A}}$-small $n$-simplices. This means that we get a map $\Sin^{\mathscr{A}}_n(X)\to \Sin^{\mathscr{A}}_{n-1}(X)$. Let $S^{\mathscr{A}}_n(X)=\Z[\Sin^{\mathscr{A}}_n(X)]$. Then there's a subchain complex $S^{\mathscr{A}}_\ast(X)$.
\begin{theorem}
The inclusion $S^\mathscr{A}_\ast(X)\subseteq S_\ast(X)$ is a chain homotopy equivalence.
\end{theorem}
\begin{corollary}
If $ H^\mathscr{A}_\ast(X):= H(S^\mathscr{A}_\ast(X))$, then $ H^\mathscr{A}_\ast(X)\cong H_\ast(X)$.
\end{corollary}
We'll do this on Monday.
\begin{example}
If $\mathscr{A}=\{A,B\}$, then $\overline{X-B}=X-\mathrm{Int}(B)\subseteq\mathrm{Int}(A)$. Let $X-B=U$. Then $U\subseteq \overline{U}\subseteq \mathrm{Int}(A)\subseteq A\subseteq X$. This is an excision! So $U\subseteq A\subseteq X$ is an excision. But now, $(X-U,A-U)\to (X,A)$ is an excision, but $(X-U,A-U)=(B,A\cap B)$, so we have $(B,A\cap B)\to (X,A)$ is an excision. Now, also, $S^\mathscr{A}_\ast(X)=S_\ast(A)+S_\ast(B)$. Says he got off track, let me just write things out and explain in a moment.
\begin{equation*}
	\xymatrix{0\ar[r] & S_n(A)\cap S_n(B)=S_n(A\cap B)\ar[r]\ar[d] & S_n(B)\ar[r]\ar[d] & S_n(B,A\cap B)\ar[r]\ar@{-->}[d]^\cong & 0\\
	0\ar[r] & S_n(A)\ar[r] & S_n(A)+S_n(B)=S^\mathscr{A}_n(X)\ar[r] & S^\mathscr{A}_n(X)/S_n(A)\ar[r] & 0}
	\end{equation*}
But we can consider $S_\ast(X)/S_\ast(A)=S_\ast(X,A)$. By the lexseq + 5 lemma, this thing is isomorphic to $S^\mathscr{A}_n(X)/S_n(A)$, so $S_\ast(B,A\cap B)\cong S_\ast(X,A)$ in homology. This is precisely the excision theorem. QED.
\end{example}
%\newpage
\section{Mayer-Vietoris and Subdivision}
(Is it Meyer-Vietoris or Mayer-Vietoris?) Today is the lecture with a lot of formulae.
\begin{theorem}
Let $\sca$ be a cover of $X$, so that $X=\bigcup_{A\in \sca}\mathrm{Int}(A)$. Then the theorem we're going to prove is this. If $S^\sca_\ast(X)=\sum_{A\in\sca}S_\ast(A)\to S_\ast(X)$ induces an isomorphism in $ H_\ast$. (This is a ``quasi-isomorphism'' of chain complexes.)
\end{theorem}
Because this lecture's full of formulas, I'm going to stand around with a piece of paper in my hand.
\begin{example}
Let $\sca=\{A,B\}$ of X, so that:
\begin{equation*}
\xymatrix{A\cap B\ar[r]^{j_1}\ar[d]^{j_2} & A\ar[d]^{i_1}\\
B\ar[r]_{i_2} & X}
\end{equation*}
Then consider the following diagram:
\begin{equation*}
\xymatrix{0\ar[r] & S_\ast(A\cap B)\ar[r]^{\begin{pmatrix}j_{1\ast} \\ -j_{2\ast}\end{pmatrix}}\ar@{=}[d] & S_\ast(A)\oplus S_\ast(B)\ar[r]\ar[d] & S^\sca_\ast(X)\ar[r]\ar@{=}[d] & 0\\
0\ar[r] & S_\ast(A)\cap S_\ast(B)\ar[r] & S_\ast(A)\oplus S_\ast(B)\ar[dr]\ar[r]^{(i_{1\ast},\ i_{2\ast})} & S_\ast(A)+S_\ast(B)\ar[r]\ar@{^(->}[d] & 0\\
 & & & S_\ast(X) &}
\end{equation*}
The map $S_\ast(A)+S_\ast(B)\hookrightarrow S_\ast(X)$ is a quasi-isomorphism, this is what locality says. Take the homology of this to get a lexseq:
\begin{equation*}
\xymatrix{ \cdots\ar[rr] & & H_{n+1}(X)\ar[dll]_{\begin{pmatrix}j_{1\ast} \\ -j_{2\ast}\end{pmatrix}}\\
 H_n(A\cap B)\ar[r] & H_n(A)\oplus H_n(B)\ar[r]^{(i_{1\ast},\ i_{2\ast})} & H_n(X)\ar[dll]\\
 H_{n-1}(A\cap B)\ar[r] & H_{n-1}(A)\oplus H_{n-1}(B)\ar[r] & \cdots}
\end{equation*}
Voila, you have Mayer-Vietoris. (I have a different proof of this that I submitted in homework.)
\end{example}
\subsection{The cone construction}
Let $X\subseteq \mathbf{R}^N$ be a star-shaped region, and let $b\in\mathbf{R}^N$. Then we showed that the augmentation $S_\ast(X)\xrightarrow{\epsilon}\Z$ is a chain homotopy equivalence. There's another map going backwards $\Z\xrightarrow{\eta_b} S_\ast(X)$ sending $1\mapsto c^0_b$. Clearly the composition $\epsilon\circ\eta_b$ is the identity. We want to show that $\eta_b$ ad $\epsilon$ are chain homotopy inverses to each other. One direction is easy. The other map $S_\ast(X)\xrightarrow{\eta_b\epsilon}S_\ast(X)$ being homotopic to $1_{S_\ast(X)}$ is a little harder. This means that we want to construct a map $b\ast:S_n(X)\to S_{n+1}(X)$ such that $db\ast+b\ast d=1-\eta_b\epsilon$.

Consider some $\sigma:\Delta^1\to X$. Then because $X$ is star shaped, you can send $\sigma$ to $b$. This gives a $2$-simplex $b\ast \sigma$, called the \emph{join}. We'll define this $2$-simplex and label it so that the zero vertex is $b$ itself, the $1$ vertex is $d_1\sigma$, and the $2$ vertex is $d_0\sigma$. Define $b\ast\sigma$ as follows (where $(t_0,\cdots,t_{n+1})\in \Delta^{n+1}$):
\begin{equation*}
b\ast\sigma(t_0,\cdots,t_n,t_{n+1})=t_0b + (1-t_0)\sigma\left(\frac{t_1,\cdots,t_{n+1}}{1-t_0}\right)
\end{equation*}
When $t_0=0$, then you recover exactly $\sigma(t_1,\cdots,t_{n+1})$ and when $t_0=1$, this is exactly $b$. (Why can you divide by $1-t_0=0$?) This is a map $b\ast:\Sin_n(X)\to\Sin_{n+1}(X)$, so we can extend linearly to get $S_n(X)\to S_{n+1}(X)$, also denoted $b\ast$. What is $d_i(b\ast\sigma)$? This is exactly:
\begin{equation*}
d_i(b\ast\sigma)=\begin{cases}\sigma & i=0 \\ 
c^0_b & i=1,n=0\\
b\ast d_{i-1}\sigma & i>0,n>0\end{cases}
\end{equation*}
The latter thing seems true because in the case when $n=1$, $d_2(b\ast\sigma)$ is the cone on $d_1\sigma$. The middle thing is true because when $n=0$ you can't use the bottom thing (what is the boundary in that case?), and if you draw this out, noting our convention that when $t_0=1$ you have $d_1\sigma$ and when $t_0=1$ you have $b$, this automatically yields $d_1(b\ast\sigma)=b$ if $\sigma:\Delta^0\to X$. We can rewrite this as follows. Here $c\in S_n(X)$.
\begin{equation*}
d_i(b\ast c)=\begin{cases}
c & i=0\\
b\ast d_0c + \eta_b\epsilon c & i=1\\
b\ast d_{i-1}\sigma & i>1
\end{cases}
\end{equation*}
Because $d_0$ of a $0$-simplex is defined to be zero. This may seem confusing, but it's just a translation of what we wrote down above. We want to compute that this thing is actually a chain homotopy. Let's compute.
\begin{align*}
d(b\ast c)& = d_0(b\ast c) - d_1(b\ast c) + \sum_{i>1}(-1)^i d_i(b\ast c)\\
& = c-(b\ast d_0c + \eta_b\epsilon c) + \sum_{i=2}^n (-1)^ib\ast d_{i-1}c\\
& = c-\eta_b\epsilon c - \sum_{j=0}^{n-1}(-1)^jb\ast d_jc\\
& = c-\eta_b\epsilon c - b\ast dc
\end{align*}
Here $j=i-1$. The equality $\sum_{j=0}^{n-1}(-1)^jb\ast d_jc=b_\ast dc$ holds because $b\ast$ is linear (by definition on $S_n(X)$). This means that $b\ast$ is a chain homotopy, QED. This completes what we've claimed about the star shaped region. We want to use this cone construction to talk about subdivision.
\subsection{Subdivide the standard simplex}
Let's focus on the standard simplex. This is a nice thing about singular homology. For the $1$-simplex, you just cut in half. For the $2$-simplex, just look at the subdivision of each face, and look at the barycenter\footnote{The barycenter of the $n$-simplex is $b_n:=\frac{(1,\cdots,1)}{n+1}$.}, and join the barycenter to the $1$-simplex between each ``half'' $1$-simplex. We want to formalize this process. Define a natural transformation $\$:S_n(X)\to S_n(X)$ by defining on standard $n$-simplex, namely by specifying what $\$(\iota_n)$ is where $\iota_n:\Delta^n\xrightarrow{\mathrm{id}}\Delta^n$, and then extending by naturality (namely $\$(\sigma)=\sigma_\ast\$(\iota_n)$). Here's the definition. When $n=0$, define $\$=\mathrm{id}$, i.e., $\$(\iota_0)=\iota_0$. For $n>0$, define $\$\iota_n:=b_n\ast\$ d\iota_n$ where $b_n$ is the barycenter of $\Delta^n$. This makes a \emph{lot} of sense if you draw out a picture, and it's a very clever definition that captures the geometry we described. Let me tell you what we'll prove about this, most likely on Wednesday.
\begin{prop}
$\$$ is a chain map $S_\ast(X)\to S_\ast(X)$, i.e., $\$d=d\$$. Also, $\$\simeq 1$.
\end{prop}
Also, class is cancelled on Friday.
%\newpage
\section{Locality (almost done!)}
\begin{theorem}
We discovered that $S^\sca_\ast(X)\hookrightarrow S_\ast(X)$ is a subcomplex, and this induced an isomorphism in homology.
\end{theorem}
We talked about subdivision and the cone construction, the latter of which dealt with a star-shaped region, relative to some point (which we can safely assume is the origin) $b$. If $\sigma:\Delta^n\to X$ is a map, then $b\ast \sigma:S_n(X)\to S_{n+1}(X)$ where $\ast$ is the join. We did all of this before. The property that this had is that it's a homotopy between $1$ and $\eta_b\epsilon$, i.e., $db\ast + b\ast d = 1-\eta_b\epsilon$. This is called equation $(\ast)$. Look above for the definition of $\eta_b$ and $\epsilon$. Hopefully you remember this story.

The subdivision operator $\$:S_\ast(X)\to S_\ast(X)$ for any space $X$ is natural, so it's enough to say what $\$\iota_n$ and $\$\iota_0$ is. Define $\$\iota_0=\iota_0$, and define $\$\iota_n=b_n\ast\$(d\iota_{n-1})$ where $b_n$ is the barycenter of the $n$-simplex. The standard simplex is star-shaped relative to its barycenter, so by naturality, it suffices to do this for $\iota_n$. The two key properties are the following.
\begin{theorem}
\begin{enumerate}
\item $\$$ is a chain map.
\item There is a chain homotopy $T:\$\sim 1$.
\end{enumerate}
\end{theorem}
\begin{proof}
Let's try to prove that it's a chain map. We'll use induction on $n$. It's enough to show that $d\$\iota_n=\$ d\iota_n$, because:$$d\$\sigma=d\$\sigma_\ast\iota_n=\sigma_\ast d\$\iota_n=\sigma_\ast \$d\iota_n=\$ d\sigma_\ast\iota_n=\$ d\sigma$$
We declared $d\$\iota_0=d\iota_0=0$. But also $\$d\iota_0=\$0=0$, so this works.

For $n\geq 1$, we want to compute $d\$\iota_n$. This is:
\begin{align*}
d\$\iota_n & =d(b_n\ast \$ d\iota_n) & \\
 & = (1-\eta_b\epsilon-b_n\ast d)(\$ d\iota_n) & \text{by $(\ast)$}
\end{align*}
What happens when $n=1$? Well:
$$\eta_b\epsilon\$d\iota_1 = \eta_b\epsilon \$(c^0_1 - c^0_0)=\eta_b\epsilon(c^0_1 - c^0-0)=0$$
Because $\epsilon$ takes sums of coefficients, which is $1+(-1)=0$. Let's continue.
\begin{align*}
d\$\iota_n & = ... & \\
 & = \$d\iota_n - b_n\ast d\$ d\iota_n & \\
 & = \$d\iota_n - b_n\$d^2\iota_n &\\
 & = \$d\iota_n & \text{because $d^2=0$}
\end{align*}
So we're done.

To define the chain homotopy $T$, we'll just write down a formula and not justify it. We just need to define $T\iota_n$ by naturality. So define:
\begin{equation*}
T\iota_n = \begin{cases}
0 & n=0\\
b_{n}\ast(\$\iota_n - \iota_n- Td\iota_n)\in S_{n+1}(\Delta^n) & n>0
\end{cases}
\end{equation*}
This is because $T:S_n(X)\to S_{n+1}(X)$ such that $dT+Td=\$-1$. I'm confused about this, so help me out. Hmm. The term $\$\iota_n - \iota_n-Td\iota_n$ is an $n$-chain. We're going to do this by induction. Again, we need to check only on the universal case.

When $n=0$, $dT\iota_0 + Td\iota_0 = 0+0 = 0 = \$\iota_0 - \iota_0$ because $\$\iota_0=\iota_0$. Now let's induct. For $n\geq 1$, let's start by computing $dT\iota_n$. This is:
\begin{align*}
dT\iota_n & = d_n(b_n\ast(\$\iota_n - \iota_n - Td\iota_n)) & \\
& = (1-b_n\ast d)(\$\iota_n - \iota_n - Td\iota_n) & \text{by $(\ast)$}\\
 & = \$\iota_n-\iota_n-Td\iota_n-b_n\ast (d\$\iota_n - d\iota_n - dTd\iota_n)
\end{align*}
We can ignore the $\eta_b\epsilon$ part because we're in dimension $\geq 1$. All we want now is that $b_n\ast(d\$\iota_n - d\iota_n - dTd\iota_n)=0$. We can do this via induction, because $T(d\iota_n)$ is in dimension $n$ (or is it $n-1$?):
\begin{align*}
dTd\iota_n & = -Td(d\iota_b)+\$ d\iota_n - d\iota_n\\
& = \$d\iota_n - d\iota_n\\
& = d\$\iota_n - d\iota_n
\end{align*}
This means that $d\$\iota_n-d\iota_n - dTd\iota_n=0$, so we're done.
\end{proof}
\begin{corollary}
$\$^k\sim 1:S_\ast(X)\to S_\ast(X)$. I.e., we're iterating subdivision. We want $T_k$ such that $dT_k+T_kd=\$^k-1$
\end{corollary}
\begin{proof}
$dT+Td=\$-1$. Let's apply $\$$ to this. We get $\$dT+\$Td=\$^2-\$$. Sum up these two things, so we get $dT+Td+\$dT+\$Td = \$^2-1$. But now, $\$d=d\$$, so the left hand side is $dT+d\$T + Td+\$Td = d(\$+1)T + (\$+1)Td$, i.e., $d(\$+1)T+(\$+1)Td=\$^2-1$. So define $T_2=(\$+1)T$, and continuing, you see that $T_k=(\$^{k-1}+\$^{k-2}+\cdots+1)T=\left(\sum^{k-1}_{i=0}\$^i\right)T$.
\end{proof}
\begin{prop}[Almost completes the proof of locality]
Let $\sca$ be a cover of $X$. For every chain $c\in S_n(X)$, there is a $k\geq 0$ such that $\$^kc\in S^\sca_n(X)$. This is the geometric thing we have to prove.
\end{prop}
\begin{proof}
We may assume that $c:\sigma:\Delta^n\to X$, and this makes sense because you just take the max of the $k$ of the terms of the sum. A great trick is the following: define an open cover $\mathscr{U}$ of $\Delta^n$ defined by $\mathscr{U}:=\{\sigma^{-1}(\mathrm{Int}(A))|A\in\sca\}$. This is a cover, a basic result from topology. Then we use the Lesbegue covering lemma:
\begin{lemma}[Lesbegue covering lemma]
We'll pretend this is part of 18.901. Let $M$ be a compact metric space (eg. $\Delta^n$), and let $\mathscr{U}$ be an open cover. Then there is $\epsilon> 0$ such that for all $x\in M$, there is $B_\epsilon(x)\subseteq U$ for some $U\in \mathscr{U}$.
\end{lemma}
\begin{proof}
Omitted, may be in 18.901. Or even 18.100B.
\end{proof}
Let's apply this to the cover we constructed. What we want is that for all $\epsilon>0$, there is a $k$ such that the diameter of the simplices in $\$^k\iota_n$ is less than $\epsilon$. Let's do that.
\begin{question}
How small are these subdivided simplices in $\$^k\iota_n$?
\end{question}
For example, suppose $\sigma:\Delta^n\to\Delta^n$ is something in the subdivision. These are all affine simplexes, i.e., it's determined by where the simplices of $\Delta^n$ go to in $\sigma$. We can write $\sigma=\langle v_,\cdots,v_n\rangle$. It could be in $\mathbf{R}^N$ if you wanted; maybe it's easier to think of it this way. The barycenter is $\frac{\sum_{i=0}^nv_i}{n+1}$. Let's compute:
\begin{align*}
|b-v_i| & =\left|\frac{v_0+\cdots+v_n-(n+1)v_i}{n+1}\right|\\
& =\left|\frac{(v_0-v_i)+(v_1-v_i)+\cdots+(v_n-v_i)}{n+1}\right|\\
 & \leq \frac{n}{n+1}\max_{i,j}|v_i-v_j|\\
 & = \frac{n}{n+1}\mathrm{diam}(\img\sigma)
\end{align*}
The following lemma completes the proof because there's always a $k$ such that $\left(\frac{n}{n+1}\right)^k<\epsilon$.
\begin{lemma}
Let $\tau$ be a simplex in $\$^k\sigma$ where $\sigma$ is an affine simplex. Then $\mathrm{diam}(\tau)\leq \frac{n}{n+1}\mathrm{diam}(\sigma)$.
\end{lemma}
\begin{proof}
Let's write $\tau=\langle w_0=b,\cdots,w_n\rangle$ and $\sigma=\langle v_0,\cdots,v_n\rangle$. We saw:
\begin{align*}
|b-w_i| & \leq\max_i|b-v_i|\\
 & \leq \frac{n}{n+1}\mathrm{diam}(\sigma)
\end{align*}
For the other cases, well, we use induction:
\begin{align*}
|w_i-w_j|& \leq \mathrm{diam}(\text{simplex in }\$d\sigma)\\
& \leq \frac{n-1}{n}\mathrm{diam}(d\sigma)\\
& \leq \frac{n}{n+1}\mathrm{diam}(\sigma)
\end{align*}
We're almost there. We'll finish the proof of locality on Friday.
\end{proof}
\end{proof}
%\newpage
\section{Concluding Locality! and CW-complexes}
Again recall what $\sca$-small covers, etc. are. We want to prove that:
\begin{theorem}
$S^\sca_\ast(X)\hookrightarrow S_\ast(X)$ is a quasi-isomorphism, i.e., an isomorphism on homology.
\end{theorem}
We developed the subdivision operator $\$^k:S_\ast(X)\to S_\ast(X)$, and proved that it's a chain map. We showed that $T_k:\$^k\sim 1$.
\begin{proof}[Proof of locality]
We want to prove surjectivity of $ H_n(S^\sca_\ast(X))\to H_n(S_\ast(X))= H_n(X)$. Let $c\in Z_n(C_\bullet)(X)$. We want to find an $\sca$-small $n$-cycle that is homologous to $c$. There's only one thing to do. Pick $k$ such that $\$^k c$ is $\sca$-small. This is a cycle because $d\$^k c=\$^k dc=0$ because $\$^k$ is a chain map. I want to compare this new cycle with $c$. Consider the chain homotopy $T_k$; then: $dT_k c+T_kdc=\$^kc-c$. But $dc=0$, so $\$^k c - c=dT_k c$, so they differ by a boundary, and they're homologous.

Now for injectivity. Suppose $c\in S^\sca_n(X)$ with $dc=0$. Suppose that $c=db$ for some $b\in S_{n+1}(X)$, not necessarily $\sca$-small. We want $c$ to be a boundary of an $\sca$-small chain. Well:
\begin{align*}
& dT_kb+T_kdb=\$^k b-b\\
\Rightarrow& dT_kb+T_kc=\$^k b-b\\
\Rightarrow& d(dT_kb+T_kc)=\$^kb-b=dT_kc=d\$^k b-c\\
\Rightarrow& c=d\$^kb-dT_kc=d(\$^k b-T_kc)
\end{align*}
Now, $\$^k$ is $\sca$-small. Is $T_kc$ also $\sca$-small? I claim that it is. Why? It is enough to show that $T_k\sigma$ is $\sca$-small if $\sigma$ is. We know that $\sigma=\sigma_\ast\iota_n$. Because $\sigma$ is $\sca$-small, we know that $\sigma:\Delta^n\to X$ is the composition $i_\ast\overline{\sigma}$ where $\overline{\sigma}:\Delta^n\to A$ and $i:A\to X$ is the inclusion for some $A\in\sca$. This means that $T_k\sigma=T_ki_\ast\overline{\sigma}=i_\ast T_k\overline{\sigma}$, which certainly is $\sca$-small.
\end{proof}
``Are you happy? You should be very happy, because we've finished our first portion of this course. We now have a whole package of homology.''
\subsection{CW-complexes}
Simplicial complexes are rigid and combinatorial. But manifolds are smooth. In between, you have CW-complexes. (A lot of advertisement for this.) We want to ``glue'' things. This is the pushout construction. Namely, if you have $i:A\hookrightarrow B$ and $f:A\to X$, then you define $X\cup_f B$ (or $X\cup_A B$) via:
\begin{equation*}
\xymatrix{A\ar[r]^f\ar@{^(->}[d]_i & X\ar[d]\\
B\ar[r] & X\cup_f B}
\end{equation*}
defined by $X\cup_f B=X\sqcup B/\sim$ where $\forall a\in A$, $f(a)\sim a$. This is $X$ with $B$ attached along $f$. There are two kinds of equivalence classes, namely elements of $B-A$, because anything not in $A$ is just a singleton. The other is $\{x\}\cup f^{-1}(x)$ for $x\in X$, because anything that's not in $\img f$ is a singleton, but if something is in $\img f$, you identify it with its preimage. This is what it is as a set. It has a universal property. Suppose you have another space $Y$.
\begin{equation*}
\xymatrix{A\ar[r]^f\ar@{^(->}[d]_i & X\ar[d]^j\ar[ddr]^{\overline{j}} & \\
B\ar[r]\ar[drr]_{\overline{g}} & X\cup_f B\ar@{-->}[dr] & \\
 & & Y}
\end{equation*}
such that $\overline{j}f=\overline{g}i$. The topology is right too because that's what the quotient topology does for you. As I wrote before, this is called a \emph{pushout} of the following diagram:
\begin{equation*}
\xymatrix{A\ar[r]^f\ar@{^(->}[d]_i & X\\
B &}
\end{equation*}
\begin{example}
Let $X=\ast$. Then you have a pushout:
\begin{equation*}
\xymatrix{A\ar[r]^f\ar@{^(->}[d]_i & \ast\ar[d]\\
B\ar[r] & \ast\cup_f B}
\end{equation*}
So then $\ast\cup_f B=B/A$.
\end{example}
\begin{example}
\begin{equation*}
\xymatrix{\emptyset\ar[r]^f\ar@{^(->}[d]_i & X\ar[d]\\
B\ar[r] & X\cup_f B}
\end{equation*}
It's then clear that this is exactly $X\sqcup B$.
\end{example}
\begin{example}
If both:
\begin{equation*}
\xymatrix{\emptyset\ar[r]^f\ar@{^(->}[d]_i & \ast\ar[d]\\
B\ar[r] & \ast\cup_f B}
\end{equation*}
So $B/\emptyset=\ast\sqcup B$. For example, $\emptyset/\emptyset=\ast$. This is ``creation from nothing''. ``We won't get into the religious ramifications.''
\end{example}
\begin{example}[Attaching a cell, the most important]
Consider:
\begin{equation*}
\xymatrix{S^{n-1}\ar[r]^f\ar@{^(->}[d]_i & X\ar[d]\\
D^n\ar[r] & X\cup_f D^n}
\end{equation*}
This is called attaching a ``cell''. The $D^n$ is what's called a cell. You're attaching a contractible space. You might want to generalize this a little bit:
\begin{equation*}
\xymatrix{\coprod_{\alpha\in A}S^{n-1}_\alpha\ar[r]^f\ar@{^(->}[d]_i & X\ar[d]\\
\coprod_{\alpha\in A}D^n_\alpha\ar[r] & X\cup_f \coprod_{\alpha\in A}D^n_\alpha}
\end{equation*}
\end{example}
What are some examples? When $n=0$, the declaration is that $S^{-1}=\emptyset$, so this is:
\begin{equation*}
\xymatrix{\emptyset\ar[r]^f\ar@{^(->}[d]_i & X\ar[d]\\
\coprod_{\alpha\in A}\ast\ar[r] & X\cup_f \coprod_{\alpha\in A}\ast}
\end{equation*}
You're just adding a bunch of points to $X$. This is a little more interesting. What about:
\begin{equation*}
\xymatrix{S^0\sqcup S^0\ar[r]^f\ar@{^(->}[d]_i & \ast\ar[d]\\
D^1\sqcup D^1\ar[r] & \ast\cup_f (D^1\sqcup D^1)}
\end{equation*}
Then $\ast\cup_f(D^1\sqcup D^1)$ is a figure $8$, because you have two $1$-disks, where you identify the four boundary points together. If we consider $(X,\ast),(Y,\ast)$, then $X\vee Y:= X\sqcup Y/\ast\sim \ast$. So $\ast\cup_f(D^1\sqcup D^1)=S^1\vee S^1$. More interestingly:
\begin{equation*}
\xymatrix{S^1\ar[r]^{aba^{-1}b^{-1}}\ar@{^(->}[d]_i & S^1\vee S^1\ar[d]\\
D^2\ar[r] & (S^1\vee S^1)\cup_f D^2}
\end{equation*}
This is exactly the torus, i.e., $(S^1\vee S^1)\cup_f D^2=T^2$.
\begin{definition}
A \emph{CW-complex} is a space $X$ with a sequence of subspaces $\emptyset=X_{-1}\subseteq X_0\subseteq X_1\subseteq\cdots\subseteq X$ (could be an infinite sequence) such that for all $n$, there is a pushout diagram like this:
\begin{equation*}
\xymatrix{\coprod_{\alpha\in A_n}S^{n-1}_\alpha\ar[r]^f\ar@{^(->}[d]_i & X_{n-1}\ar[d]\\
\coprod_{\alpha\in A_n}D^n_\alpha\ar[r] & X_{n}}
\end{equation*}
And $X=\bigcup X_n$, topologically (i.e. $A\subseteq X$ is open if and only if $A\cap X_n$ is open for all $n$). Often, $X_n=\mathrm{Sk}_n(X)$, called the $n$-skeleton, in honor of Halloween (coming right up!), of $X$.
\end{definition}
\begin{example}
The torus is $\emptyset\subseteq T^2_0\subseteq T^2_1\subseteq T^2$. Here, $T^2_0=\ast$ and $T^2_1=S^1\vee S^1$.
\end{example}
\begin{definition}
A CW-complex is \emph{finite-dimensional} if $X_n=X$ for some $n$. Say that $X$ is of \emph{finite type} if each $A_n$ is finite, i.e., finitely many cell in each dimension. Say that $X$ is \emph{finite} if it's finite-dimensional and of finite type.
\end{definition}
In CW, the C is for cell, and the W is for weak, because of the topology on a CW-complex. This definition is due to J. H. C. Whitehead. Some people say that the ``CW'' comes from his name.
\begin{theorem}
\begin{enumerate}
\item Any CW-complex is Hausdorff, and it's compact if and only if it's finite.
\item Any compact smooth manifold admits a CW structure.
\end{enumerate}
\end{theorem}
\begin{proof}
Not going to do this.
\end{proof}
Note that there could be multiple CW-structures on something.
%\newpage
\section{CW-complexes and cellular homology}
Recall:
\begin{definition}
A \emph{CW-complex} is a space $X$ with a sequence of subspaces $\emptyset=X_{-1}\subseteq X_0\subseteq X_1\subseteq\cdots\subseteq X$ (could be an infinite sequence) such that for all $n$, there is a map $f:\coprod_{\alpha\in A_n}S^{n-1}_\alpha\to X_{n-1}$ (called the \emph{attaching map}), such that there is a pushout diagram like this:
\begin{equation*}
\xymatrix{\coprod_{\alpha\in A_n}S^{n-1}_\alpha\ar[r]^f\ar@{^(->}[d]_i & X_{n-1}\ar[d]\\
\coprod_{\alpha\in A_n}D^n_\alpha\ar[r] & X_{n}}
\end{equation*}
And $X=\bigcup X_n$, topologically (i.e. $A\subseteq X$ is open if and only if $A\cap X_n$ is open for all $n$). Often, $X_n$ is written $\mathrm{Sk}_n(X)$, and is called the $n$-skeleton of $X$.
\end{definition}
\begin{remark}
This means that if you ignore the topology, i.e., as sets: $X=\coprod_{n\geq 0}\left(\coprod_{\alpha\in A_n}\mathrm{Int}(D^n_\alpha)\right)$ where $\mathrm{Int}(D^n)=\{x\in D^n: |x|<1\}$ (the interior of $D^n$), so that $\mathrm{Int}(D^0)=D^0=\ast$. The $\mathrm{Int}(D^n_\alpha)$ are called ``open $n$-cells''. Note that the open $n$-cells are not generally open in the topology on $X$.
\end{remark}
\begin{example}
The $n$-sphere $S^n$. Let $\mathrm{Sk}_0(S^n)=\ast=\mathrm{Sk}_1(S^n)=\cdots=\mathrm{Sk}_{n-1}(S^n)\subseteq \mathrm{Sk}_n(S^n)=S^n$. We attach it by using the pushout:
\begin{equation*}
\xymatrix{S^{n-1}\ar[d]\ar[r] & \ast\ar@{^(->}[d]\\
D^n\ar[r] & S^n}
\end{equation*}
Here's another CW-structure. Let $\mathrm{Sk}_0(S^n)=S^0=S^n\cap \mathbf{R}^1\langle \mathbf{e}_1\rangle$, $\mathrm{Sk}_1(S^n)=S^{1}=S^n\cap\mathbf\mathbf{R}\langle \mathbf{e}_1,\mathbf{e}_2\rangle$, $\mathrm{Sk}_2(S^n)=S^2=S^n\cap\mathbf{R}\langle \mathbf{e}_1,\mathbf{e}_2,\mathbf{e}_3\rangle$, etc. until $\mathrm{Sk}_n(S^n)=S^n$. I have to give maps $u,\ell:D^k\to S^k$ so that you have a pushout:
\begin{equation*}
\xymatrix{D^k\ar[r] & S^k\\
S^{k-1}\ar@{^(->}[u]\ar@{=}[r] & \mathrm{Sk}_k(S^n)\ar@{^(->}[u]}
\end{equation*}
Let $u(x)=(x,\sqrt{1-|x|^2})$ and $\ell(x)(x,-\sqrt{1-|x|^2})$ where $x\in D^k$. Clearly $u,\ell$ take values in $S^k$.
\end{example}
There's another definition I have to make.
\begin{definition}
Let $X$ be a CW-complex. A subcomplex of $X$ is a subspace $Y\subseteq X$ such that $\emptyset\subseteq Y\cap X_0\subseteq Y\cap X_1\subseteq\cdots\subseteq Y\cap X_k\subseteq \cdots\subseteq Y$ is a CW-structure on $Y$.
\end{definition}
\begin{example}
$X_n\subseteq X$ is a subcomplex of a CW-complex $X$. It's not that hard to see why. In particular, $S^0\subseteq S^1\subseteq S^2\subseteq\cdots\subseteq \bigcup_{n\geq 1}S^n=:S^\infty$. This of finite type, but isn't finite-dimensional.
\end{example}
\begin{lemma}
$S^\infty$ is contractible.
\end{lemma}
\begin{proof}
$S^0$ itself is not contractible, but attaching two $1$-cells makes this contractible. Similarly, $S^1$ isn't contractible, but attaching two $2$-cells makes this contractible. This is the idea. You have $S^{k-1}\times I\to S^k$ by $(x,t)\mapsto u(tx+(1-t)\mathbf{e}_1)$ where $u$ is the map we defined above. Therefore we get a map $S^\infty\times I\to S^\infty$ that's a contracting homotopy.
\end{proof}
\begin{example}
Recall $\mathbf{RP}^n=S^n/\sim$ where $x\sim -x$. There's a map from $S^n\to\mathbf{RP}^n$ that's a double cover. Let me propose a CW-decomposition. We have:
\begin{equation*}
\xymatrix{\cdots\ar@{^(->}[r] & S^{k-1}\ar@{^(->}[r]\ar[d] & S^k\ar[d]\ar[r] & \cdots\ar[r] & S^n\ar[d]\\
\cdots\ar@{^(->}[r] & \mathbf{RP}^{k-1}\ar@{^(->}[r] & \mathbf{RP}^k\ar@{^(->}[r] & \cdots\ar@{^(->}[r] & \mathbf{RP}^n}
\end{equation*}
We claim that this is a CW-decomposition. We have a double cover $S^1\to\mathbf{RP}^1=S^1$. The maps $S^{k-1}\to\mathbf{RP}^{k-1}$ are not degree $2$ maps -- they're different spaces! If we use the double cover $S^{k-1}\to\mathbf{RP}^{k-1}$, then we claim that there is a pushout:
\begin{equation*}
\xymatrix{\mathbf{RP}^{k-1}\ar@{^(->}[r]& \mathbf{RP}^k\ar@{^(->}[r] & \cdots\ar@{^(->}[r] & \bigcup_{k\geq 0}\mathbf{RP}^k=\mathbf{RP}^\infty\\
S^{k-1}\ar[u]^{\text{double cover}}\ar[r] & D^k\ar[u]}
\end{equation*}
This is true if you notice that the preimage of any point of $\mathbf{RP}^k$ must be two points, one of which must be in the upper hemisphere, which is a disk, unless both points are on the equatorial sphere.
\end{example}
\subsection{Homology of CW-complexes}
Consider:
\begin{equation*}
\xymatrix{A\ar@{^(->}[r]\ar[d]^f & B\ar[r]\ar[d] & B/A\ar@{-->}[d]\\
X\ar@{^(->}[r] & X\cup_f B\ar[r] & (X\cup_fB)/X}
\end{equation*}
By a diagram chase, the dotted arrow exists and is continuous. This is actually a pointed map. You can see that this is a homeomorphism. What if this is part of a CW-structure?
\begin{equation*}
\xymatrix{\coprod_{\alpha}S^{k-1}\ar@{^(->}[r]\ar[d]^f & \coprod_{\alpha}D^k_\alpha\ar[r]\ar[d] & \bigvee_{\alpha}S^k_\alpha\ar@{-->}[d]\\
X_{k-1}\ar@{^(->}[r] & X_k\cup_f B\ar[r] & X_k/X_{k-1}}
\end{equation*}
where $\bigvee$ is the wedge product (disjoint union with all basepoints identified). Then $\bigvee_{\alpha}S^k_\alpha$ is a bouquet of spheres. So $X_k/X_{k-1}\cong\bigvee_{\alpha}S^k_\alpha$. We know the homology of spheres very well by now, so let's exploit this.
\begin{lemma}
$ H_q(X_k,X_{k-1})\to H_q(X_k/X_{k-1},\ast)$ is an isomorphism.
\end{lemma}
\begin{proof}
Later.
\end{proof}
But now, we know $ H_q(X_k/X_{k-1},\ast)$ very well! It's exactly $\widetilde{ H}_q(\bigvee_{\alpha\in A_k}S^k_\alpha)\cong\begin{cases}\Z[A_k] & q=k \\ 0 & q\neq k\end{cases}$. Therefore the relative homology $ H_q(X_k,X_{k-1})$ counts the number of $k$-cells of $X$.
\begin{definition}
Let $C_k(X):= H_k(X_k,X_{k-1})$. This is the ``cellular $k$-chains'' of $X$.
\end{definition}
\begin{corollary}
There's an exact sequence:
\begin{equation*}
\xymatrix{ & & H_{k+1}(X_k,X_{k-1})=0\ar[dll]\\
 H_k(X_{k-1})\ar[r] & H_k(X_k)\ar[r] & C_k(X)\ar[dll]\\
 H_{k-1}(X_{k-1})\ar[r] & H_{k-1}(X_k)\ar[r] & H_{k-1}(X_k,X_{k-1})=0}
\end{equation*}
And in other dimensions, $ H_q(X_{k-1})\cong H_q(X_k)$ for $q\neq k,k-1$. So:
\begin{enumerate}
\item We have maps $ H_q(X_k)\to H_q(X_{k+1})\to\cdots$ that are all isomorphisms for $q<k$. (There was a lot of confusion here about what $q$ is greater than or less than). All of these map to $ H_q(X)$. There's another lemma that I will defer again:
	\begin{lemma}
	This limit $ H_q(X_k)\to H_q(X_{k+1})\to\cdots\to H_q(X)$ is an isomorphism.
	\end{lemma}
	\begin{proof}
	Deferred.
	\end{proof}
\item (There was a bit of confusion at this point, I'm not sure on what exactly.) $ H_q(X_0)\to H_q(X_1)\to\cdots\to H_q(X_k)$ are all isomorphisms for $q>k$. Agreed? That's not what I wanted to say. I'll continue this on Wednesday. It's not supposed to be confusing.
\end{enumerate}
\end{corollary}
%\newpage
\section{Homology of CW-complexes}
\begin{lemma}
There are isomorphisms:
\begin{equation*}
 H_q(X_n,X_{n-1})\xrightarrow{\cong} H_q(X_n/X_{n-1},\ast)= H_q\left(\bigvee_{\alpha\in A_n}S^n_\alpha,\ast\right)=\begin{cases}0 & q\neq n \\ \Z[A_n] & q=n\end{cases}
\end{equation*}
\end{lemma}
Let's talk about ``characteristic maps''. This is a map $\left(\coprod D^n_\alpha,\coprod S^{n-1}_\alpha\right)\to (X_n,X_{n-1})$. This is like a ``relative homeomorphism'' (I was drinking water, so this isn't exactly accurate). We have a map $ H_q(X_n,X_{n-1})\to H_q(X_n/X_{n-1},\ast)$, to get a commutative diagram:
\begin{equation*}
\xymatrix{ H_q\left(\coprod D^n_\alpha,\coprod S^{n-1}_\alpha\right)\ar[r]\ar[d] & H_q\left(\bigvee S^n_\alpha,\ast\right)\ar[d]\\
 H_q(X_n,X_{n-1})\ar[r] & H_q(X_n/X_{n-1},\ast)}
\end{equation*}
The right arrow is an isomorphism. The top arrow is an isomorphism. The lemma says that the bottom map is an isomorphism, so that $ H_q\left(\coprod D^n_\alpha,\coprod S^{n-1}_\alpha\right)\to H_q(X_n,X_{n-1})$ is an isomorphism. This is called the ``cellular $n$-chains'' on $X$.

Now, fix $q$. For $q=0$, there is:
\begin{equation*}
\xymatrix{ H_1(X_1,X_0)\ar[d] & H_0(X_1,X_0)=0 & H_0(X_2,X_1)=0\\
 H_0(X_0)\ar[r]\ar[drrr] & H_0(X_1)\ar[r]\ar[drr]\ar[u] & H_0(X_2)\ar[u]\ar[r]\ar[dr] & \cdots\ar[d]\\
 & H_1(X_2,X_1)=0\ar[u] & & H_0(X)}
\end{equation*}
We know that $ H_0(X_1,X_0)=0$, but $ H_1(X_1,X_0)$ is not necessarily $0$. This means that $ H_0(X_0)\to H_0(X_1)$ is surjective, and $ H_0(X_1)\cong H_0(X_2)$, and so on for higher dimensions. This makes sense because adding higher dimensional cells does not change path components.

Let's try this for $q>0$. Then you have:
\begin{equation*}
\xymatrix{ & H_{q+1}(X_q,X_{q+1})=0\ar[d]& H_{q+1}(X_{q+1},X_q)\ar[d]\\
\ar[r]\cdots & H_q(X_{q-1})\ar[r]\ar[dr] & H_q(X_q)\ar[r]\ar[d] & H_q(X_{q+1})\ar[r]\ar[d] & H_q(X_{q+2})\ar[d]\ar[r] & \cdots\\
& & H_q(X_{q},X_{q-1}) & H_q(X_{q+1},X_q)=0 & H_q(X)}
\end{equation*}
So the first maps ($ H_q(X_0)\to H_q(X_1)\to\cdots$) are isomorphisms, the map $ H_q(X_{q+1})\to H_q(X_q)$ is an injection, and the map $ H_q(X_q)\to H_q(X_{q+1})$ is surjective. But also, $ H_q(X_{q+1})\cong H_q(X_{q+2})\cong \cdots$. But also, $ H_q(X_0)\cong 0$, and we have:
\begin{corollary}
$ H_q(X)=0$ for $q>\dim X=n$.
\end{corollary}
\begin{lemma}
$ H_q(X_n)\cong H_q(X)$ for $n>0$.
\end{lemma}
I want you to have the following picture in mind. We have a diagram coming from the lexseq in the homology of a pair:
\begin{equation*}
\xymatrix{C_{n+1}(X)= H_{n+1}(X_{n+1},X_n)\ar[d]^\partial\ar[dr]^d & & 0= H_{n-1}(X_{n-2})\ar[d]\\
 H_n(X_n)\ar[r]^j\ar[d] & C_n(X)= H_n(X_n,X_{n-1})\ar[r]^\partial\ar[dr]^d & H_{n-1}(X_{n-1})\ar[d]^j\\
 H_n(X_{n+1})\ar[d] & & C_{n-1}(X)= H_{n-1}(X_{n-1},X_{n-2})\\
0 = H_n(X_{n+1},X_n)}
\end{equation*}
Now, $\partial\circ j=0$. So the composite of the diagonals is zero, i.e., $d^2=0$, and we have a chain complex! More precisely, we get a chain complex, denoted $C_\ast(X)$. This is the ``cellular chain complex'' of $X$. We should compute the homology of this chain complex. Well, $ H_n(C_\ast(X))=\ker d/\img d$. Now, $\ker d=\ker (j\circ\partial)$. But $j$ is injective, so $\ker d=\ker\partial$. Also, $\img d=\img(j\circ\partial)=j(\img\partial)$ because $j$ is injective.

The kernel of $\partial$ is the image of $j$ by exactness, but $j$ is a monomorphism, so $\ker\partial\cong H_n(X)$. Now, $ H_n(C_\ast(X))\cong\frac{ H_n(X)}{\img(\partial)}$. This is equal to $ H_n(X_{n+1})$, again by exactness. But out lemma shows that $ H_n(X_{n+1})= H_n(X)$. In other words, we've proved:
\begin{theorem}
If $X$ is a CW-complex, then $ H_\ast(C_\ast(X))\cong H_\ast(X)$. I didn't use specific attaching maps at all, so this is natural in ``skeletal'' maps of CW-complexes.
\end{theorem}
What is the differential? You have a relative cycle in dimension $(n+1)$, you're taking its boundary, and then working relative the $(n-1)$-skeleton. You'll see this better in the example we're going to do now, namely projective space.
\begin{example}
We'll try $ H_\ast(\mathbf{RP}^n)$. We have: $\mathrm{sk}_k(\RP^n)=\RP^k$, which are just $1$-dimensional subspaces of $\mathbf{R}^{k+1}$. Think of the inclusion $\mathbf{R}^{k+1}\to\mathbf{R}^{n+1}$ as the inclusion of the first $(k+1)$ basis vectors. This is a CW-complex because the map $S^{k-1}\to \mathbf{RP}^{k-1}$ is a double cover, and you have a pushout:
\begin{equation*}
\xymatrix{S^{k-1}\ar[r]\ar@{^(->}[d] & \mathbf{RP}^{k-1}\ar@{^(->}[d]\\
D^k\ar[r] & \mathbf{RP}^k}
\end{equation*}
The attaching maps are the double cover maps.
\end{example}
The notation is as follows. $\mathbf{RP}^n=\mathbf{RP}^{n-1}\cup_f D^n=\mathbf{RP}^{n-1}\cup_f e^n$. The $e^n$ is the notation for an $n$-cell. In particular, $\mathbf{RP}^n=e_0\cup_f e_1\cup_f\cdots\cup_f e_n$. You have:
\begin{equation*}
\xymatrix{0 & C_0(\mathbf{RP}^n)\ar[d]\ar[l] & C_1(\mathbf{RP}^n)\ar[d]\ar[l] & \cdots\ar[l]\ar[d] & C_n(\mathbf{RP}^n)\ar[d]\ar[l] & 0\\
& \Z\langle e^0\rangle & \Z\langle e^1\rangle\ar[l]^{d=0} & \cdots\ar[l] & \Z\langle e^n\rangle\ar[l]}
\end{equation*}
The first differential is zero because we know what $ H_0(\mathbf{RP}^n)$ is (it's $\Z$!). I have $S^{n-1}\xrightarrow{f}\mathbf{RP}^{n-1}\to \mathbf{RP}^{n-1}/\mathbf{RP}^{n-2}=S^{n-1}$. Also recall the commutative diagram from before.
\begin{equation*}
\xymatrix{ H_n(D^n,S^{n-1})\ar[r]^\partial \ar[d]^\cong & H_{n-1}(S^{n-1})\ar[r]\ar[d]^\cong & H_{n-1}(S^{n-1},\ast)\ar[d]^\cong\\
C_n= H_n(\mathbf{RP}^n,\mathbf{RP}^{n-1})\ar[r]^\partial & H_{n-1}(\mathbf{RP}^{n-1}) \ar[r] & H_{n-1}(\mathbf{RP}^{n-1},\mathbf{RP}^{n-2})=C_{n-1}
}
\end{equation*}
The first map on the top is an isomorphism. The bottom composite is our differential. So the map $ H_{n-1}(S^{n-1})\to H_{n-1}(S^{n-1},\ast)$. Therefore, $S^{n-1}\xrightarrow{\text{double cover}}\mathbf{RP}^{n-1}\xrightarrow{\text{pinching}} S^{n-1}$.
\begin{equation*}
\xymatrix{S^{n-1}\ar[r]^{\text{double cover}}\ar[dr] & \mathbf{RP}^{n-1}\ar[r]^{\text{pinching}} & S^{n-1}\\
 & S^{n-1}/S^{n-2}=S^{n-1}\vee S^{n-1}\ar[ur]}
\end{equation*}
One of the maps $S^{n-1}\to S^{n-1}$ from the wedge is the identity, and the other map is the antipodal map, as can be seen by looking at a picture. If $\alpha$ is the antipodal map, then $S^{n-1}\vee S^{n-1}\to S^{n-1}$ is $[1,\alpha]$. If $\sigma$ is a generator of $ H_{n-1}(S^{n-1})$, we have $\sigma\mapsto (\sigma,\sigma)\mapsto \sigma+\alpha_\ast\sigma$. What is the degree of $\alpha_\ast: H_{n-1}(S^{n-1})\to H_{n-1}(S^{n-1})$, so $\deg\alpha=(-1)^n$. Thus the composite, and hence the attaching map, is $(1+(-1)^n)\sigma$. This means the cellular chain complex is:
\begin{equation*}
\xymatrix{0 & \Z\ar[l]^0 & \Z\ar[l]^2 & \cdots\ar[l]^0 & \Z\ar[l]^{2\text{ or }0} & 0\ar[l] & 0\ar[l] & \cdots\ar[l]}
\end{equation*}
We'll continue next time\footnote{Why don't we work in $\Z/2\Z$ coefficients? This is so much easier then. :P}.
%\newpage
\section{Missing lemmas, $\mathbf{RP}^n$ again, and even CW-complexes}
\begin{lemma}
We want to show that $ H_\ast(X_n,X_{n-1})\cong H_\ast(X_n/X_{n-1},\ast)$. We have the characteristic map $\left(\coprod_\alpha D^n,\coprod_\alpha S^{n-1}\right)\to (X_n,X_{n-1})$, where the map $\coprod_\alpha S^{n-1}\to X_{n-1}$ is the attaching map.
\begin{equation*}
\xymatrix{ H_\ast(X_n,X_{n-1})\ar[d]^\cong & H_\ast\left(\coprod_\alpha D^n,\coprod_\alpha S^{n-1}\right)\ar[l]\ar[d]^{\cong,homework}\\
 H_\ast(X_n/X_{n-1},\ast) & H_\ast\left(\bigvee_{\alpha}S^n_\alpha,\ast\right)\ar[l]^\cong}
\end{equation*}
\end{lemma}
For preparation, we will talk about ``strong deformation retracts''. For example, $S^{n-1}\hookrightarrow D^n-\{0\}$. You just deform everything back radially.
\begin{definition}
A subspace of a space $A$ inside $X$ is a \emph{strong deformation retract} if there is a homotopy $h:X\times I\to X$ such that $h(x,0)=x$, $h(x,1)\in A$, and $h(a,t)=a$ if $a\in A$.
\end{definition}
\begin{example}
For example, for the map $S^{n-1}\hookrightarrow D^n-\{0\}$ can be defined as $h(x,t)=(1-t)x+t\frac{x}{||x||}$.
\end{example}
A strong deformation retract is a homotopy equivalence, because we can just define the homotopy inverse to be $h(-,1)$. Then $A\hookrightarrow X\xrightarrow{h(-,1)}A$ is the identity, and $X\xrightarrow{h(-,1)}A\hookrightarrow X$ is homotopic to the identity.
\begin{example}
The map $\coprod_\alpha S^{n-1}_\alpha\xrightarrow\coprod(D^{n-1}_\alpha-\{0\})$.
\end{example}
Terminology: if $X$ is a CW-complex with filtration $X_0\subseteq X_1\subseteq\cdots\subseteq X$. A choice of characteristic maps is a ``cell structure'' for $X$. Note that this isn't specified in the CW-structure.

\begin{proof}[Proof of the lemma]
Let $X$ be a CW-complex, with a choice of a cell structure, say with characteristic maps $g_\alpha:D^n_\alpha\to X_n$. Let $C_n=\{g_\alpha(0)|\alpha\in A_n\}$. We know that $X_{n-1}\hookrightarrow X_n-C_n$. We claim that this is a strong deformation retract. This follows from our observation that $\coprod_\alpha S^{n-1}_\alpha\xrightarrow\coprod(D^{n-1}_\alpha-\{0\})$ is a strong deformation retract. In particular, $X_{n-1}\hookrightarrow X_n-C_n$ is a homotopy equivalence.

For example, consider the torus. If you look at the fundamental polygon, and remove a hole, you can retract everything back to the boundary.

Now, we have:
\begin{equation*}
\xymatrix{ H_\ast\left(\coprod_\alpha D^n_\alpha,\coprod_\alpha S^{n-1}_\alpha\right)\ar[r]\ar[d] & H_\ast(X_n,X_{n-1})\ar[d]\\
 H_\ast\left(\coprod_\alpha D^n_\alpha,\coprod_\alpha (D^n_\alpha-\{0\})\right) & H_\ast(X_n,X_n-C_n)}
\end{equation*}
The downwards arrows are isomorphisms because of strong deformation retractions, homotopy invariance, lexseq, and the 5-lemma. Recall that if $U\subseteq A\subseteq X$, then $ H_\ast(X-U)\cong H_\ast(X,A)$ if $\overline{U}\subseteq \mathrm{int}(A)$. Suppose we consider $X_{n-1}\subseteq X_n-C_n\subseteq X_n$. This is an excision because $X_{n-1}$ is already closed, and $X_n-C_n$ is already open. Then excision tells us that $ H_\ast(X_n-X_{n-1},X_n-X_{n-1}-C_n)$. This means we can extend the diagram as follows.
\begin{equation*}
\xymatrix{ H_\ast\left(\coprod_\alpha D^n_\alpha,\coprod_\alpha S^{n-1}_\alpha\right)\ar[r]\ar[d] & H_\ast(X_n,X_{n-1})\ar[d]\\
 H_\ast\left(\coprod_\alpha D^n_\alpha,\coprod_\alpha (D^n_\alpha-\{0\})\right) & H_\ast(X_n,X_n-C_n)\\
 H_\ast(\coprod_\alpha(D^n_\alpha-S^{n-1}_\alpha),\coprod_\alpha(D^n_\alpha-S^{n-1}_\alpha-\{0\}))\ar[r]\ar[u]^\cong & H_\ast(X_n-X_{n-1},X_n-X_{n-1}-C_n)\ar[u]^\cong}
\end{equation*}
The left arrow on the second row is the excision from $\coprod_\alpha S^{n-1}_\alpha\subseteq \coprod_\alpha D^n_\alpha-\{0\}\subseteq \coprod_\alpha D^n_\alpha$. The bottom right arrow is an isomorphism because $\coprod_\alpha(D^n_\alpha-S^{n-1}_\alpha),\coprod_\alpha(D^n_\alpha-S^{n-1}_\alpha-\{0\})\to (X_n-X_{n-1},X_n-X_{n-1}-C_n)$ is a homeomorphism, and hence an isomorphism. This concludes the proof of the lemma.
\end{proof}
Now for the second lemma
\begin{lemma}
We have:
\begin{equation*}
\xymatrix{\ar[r]\cdots & H_q(X_{q-1})\ar[r]\ar@{=}[d] & H_q(X_q)\ar@{->>}[r]\ar[d]^\cong\ar[drr] & H_q(X_{q+1})\ar[r]^\cong\ar[dr] & H_q(X_{q+2})\ar[d]\ar[r]^\cong & \cdots\ar[dl]\\
& 0 & H_n(C_\ast(X_n))\ar@{=}[d] & & H_n(X) \\
& & \ker(C_n(X)\xrightarrow{d}C_{n-1}(X))\ar@{^(->}[d] & &\\
& & C_n(X_n) & &}
\end{equation*}
So $ H_q(X_q)$ is free abelian. The lemma is that $ H_n(X_{n+1})\to H_n(X)$ is an isomorphism.
\end{lemma}
For preparation, we'll talk about subcomplexes.
\begin{definition}
Let $X$ be a CW-complex with a cell structure $\{g_\alpha:D^n_\alpha\to X_n|\alpha\in A_n\}$. A subcomplex is a subspace $Y\subseteq X$ such that for all $n$, there are $B_n\subseteq A_n$ such that $Y_n=Y\cap X_n$ is a CW-filtration for $Y$ with characteristic maps $\{g_\beta|\beta\in B_n\}$.
\end{definition}
\begin{example}
$X_n\subseteq X$ is a subcomplex.
\end{example}
\begin{prop}[Bredon, p. 196]
Let $X$ be a CW-complex with a chosen cell structure. Let $K\subseteq X$ be compact. Then $K$ sits inside some finite subcomplex. 
\end{prop}
\begin{remark}
For fixed cell structures, unions and intersections of subcomplexes are subcomplexes.
\end{remark}
\begin{proof}[Proof of lemma 2]
Let's do surjectivity. Pick $c\in Z_n(C_\bullet)(X)$. Well, $c=\sum c_i\sigma_i$ where $\sigma_i:\Delta^n\to X$. Since $\Delta^n$ is compact, $\sigma_i(\Delta^n)$ is compact, and thus $\bigcup\sigma_i(\Delta^n)$ is compact, and hence it lies in a finite subcomplex. Hence it sits in some $X_N$ for some $N$, possibly very large. Thus $c\in S_n(X_N)\subseteq S_n(X)$. It's still a cycle because it was a cycle before. (This is a stronger result, we've proved that cycles come from cycles). This is more than enough.

Let's do injectivity. Let $c\in Z_n(C_\bullet)(X_{n+1})$. If $i_\ast$ denotes the maps $ H_n(X_q)\to H_n(X)$, then $i_\ast c\in Z_n(C_\bullet)(X)$. Suppose there was $b$ such that $db=i_\ast(c)$, so that $i_\ast(c)=0$ in $ H_n(X)$. Well, $b=\sum b_i \tau_i$ where $\tau_i:\Delta^{n+1}\to X$. Then $\bigcup \tau_i(\Delta^{n+1})$ is compact, and thus sits inside $X_M$. So $b\in S_{n+1}(X_M)$, so the equation $db=i_\ast(c)$ is still true in $X_M$. So $[c]=0$ in $ H_n(X_M)$. It's not quite what I wanted.

This is good enough, because the maps $ H_n(X_{n+1})\to H_n(X_{n+2})\to \cdots$ are all isomorphisms.
\end{proof}
We'll talk about real projective space next week.
\begin{remark}
Suppose $X$ has only even cells. For example, $\mathbf{CP}^n$, namely complex lines in $\mathbf{C}^{n+1}$ through the origin, or $S^{2n+1}/v\sim \zeta z$ for any $\zeta\in \CC$ such that $|\zeta|=1$. I have a map $S^{2n-1}\to \mathbf{CP}^{n-1}$. We have:
\begin{equation*}
\xymatrix{S^{2n-1}\ar@{^(->}[r]\ar[d] & D^{2n}\ar[d]\\
\mathbf{CP}^{n-1}\ar@{^(->}[r] & \mathbf{CP}^n}
\end{equation*}
The same argument that we had before for $\mathbf{RP}^n$ show that the CW stucture on $\mathbf{CP}^n$ is $\CP^0\subseteq\CP^1\subseteq\cdots\subseteq\CP^n$. So $\CP^n=D^0\cup D^2\cup\cdots\cup D^{2n}$.

Anyway, if you had $X$ only with even cells, then $C_{\text{odd}}(X)=0$, so $ H_n(X)=\begin{cases}C_n(X) & n=2k \\ 0 & n=2k+1\end{cases}$. We've shown that:
\begin{equation*}
 H_k(\mathbf{CP}^n)=\begin{cases}
\Z & k=2n\\
0 & k=2n+1
\end{cases}
\end{equation*}
\end{remark}
%\newpage
\section{Relative attaching maps, $\RP^n$, Euler characteristic, and homology approximation}
Recall:
\begin{equation*}
\xymatrix{ H_n\left(\coprod_\alpha D^n_\alpha\right)\ar[r]^\partial_\cong\ar[d]^\cong_{\text{char. map}} & H_{n-1}\left(\coprod_\alpha S^{n-1}_\alpha\right)\ar[d]_{\text{attaching map}} & H_{n-1}\left(\coprod_\beta D^{n-1}_\beta,\coprod_\beta S^{n-2}_\beta\right) \ar[r]^\cong & \widetilde{ H}_{n-1}\left(\bigvee_\beta D^{n-1}_\beta/S^{n-2}_\beta\right)\ar[d]^\cong\\
 H_n(X_n,X_{n-1})\ar[r]^\partial\ar@{=}[d] & H_{n-1}(X_{n-1})\ar[r]^j & H_{n-1}(X_{n-1},X_{n-2})\ar[r]^\cong\ar[ur]^\cong\ar@{=}[d] & \widetilde{ H}_{n-1}(X_{n-1}/X_{n-2})\\
C_n(X)\ar[rr]^d & & C_{n-1}(X)}
\end{equation*}
This boundary map $d$ is the effect of $ H_{n-1}(-)$ to:
\begin{equation*}
\xymatrix{\coprod_\alpha S^{n-1}_\alpha\ar[r]^{f_{n-1}} & X_{n-1}\ar[d]\ar[r] & X_{n-1}/X_{n-2}\cong \bigvee_\beta D^{n-1}_\beta/S^{n-2}_\beta\\
 & X_n}
\end{equation*}
The composite in the top row of this diagram is called the ``relative attaching map'' because you're working relative to the $(n-2)$-skeleton.

Before, I coyly said before that there is a monoid homomorphism $\deg:[S^{n-1},S^{n-1}]\to\Z_\times$ that sends $f\mapsto ( H_{n-1}(f): H_{n-1}(S^{n-1})\to H_{n-1}(S^{n-1}))$. I said that this was surjective. This is actually an isomorphism. We won't prove injectivity here, but we'll do this in 18.906.
\subsection{$\RP^m$}
Recall the CW-structure $\RP^0\subseteq\RP^1\subseteq\cdots\subseteq\RP^{n-1}\subseteq\RP^n\subseteq \cdots\subseteq\RP^m$, where $\RP^{n-1}$ is the collection of lines in $\RR^n$. The attaching map is the double cover $\pi:S^{n-1}\to\RP^{n-1}$ to get a pushout
\begin{equation*}
\xymatrix{S^{n-1}\ar[r]^{\text{double cover}}\ar[d] & \RP^{n-1}\ar[d]\\
D^n\ar[r] & \RP^n}
\end{equation*}
The cellular chain complex $C_\ast$ will look like:
\begin{equation*}
\xymatrix{0 & C_0=\Z\ar[l] & C_1=\Z\ar[l] & \cdots\ar[l] & C_{n-1}=\Z\ar[l] & C_n=\Z\ar[l] & \cdots\ar[l] & C_m=\Z\ar[l] & 0\ar[l]}
\end{equation*}
The first map $C_1\to C_0$ is easy because $\RP^m$ is connected. Thus $C_1\to C_0$ is the zero map.

The relative attaching maps are: $S^{n-1}\xrightarrow{\pi}\RP^{n-1}\to \RP^{n-1}/\RP^{n-2}\cong S^{n-1}$. All we have to do is figure out the degree of this map. What happens when I collapse out $\RP^{n-2}$? This has the effect of collapsing out by the equator because you are collapsing all those points on the equator of $S^{n-1}$ that go to $\RP^{n-1}$. So the composition $S^{n-1}\xrightarrow{\pi}\RP^{n-1}\to \RP^{n-1}/\RP^{n-2}\cong S^{n-1}$ splits as:
\begin{equation*}
\xymatrix{S^{n-1}\ar[r]^{\pi}\ar[dr]^{\text{pinching}} & \mathbf{RP}^{n-1}\ar[r] & \RP^{n-1}/\RP^{n-2}\cong S^{n-1}\\
 & S^{n-1}/S^{n-2}\ar[ur]\ar@{=}[r] & S^{n-1}_u\vee S^{n-1}_\ell}
\end{equation*}
The map $S^{n-1}_u\vee S^{n-1}_\ell\to S^{n-1}$ sends the top hemisphere to $S^{n-1}$ itself via the identity, so the first factor is a homeomorphism. The lower hemisphere will be sent to $S^{n-1}$ via the antipodal map (called $\alpha$), which is also a homeomorphism, but I won't draw this in because I don't want to do that here. What does this do in homology? In $(n-1)$-dimensional homology, we choose a generator $\sigma$ of $ H_{n-1}(S^{n-1})$.

The pinch map sends $\sigma$ to $(\sigma,\sigma)$. The map from $S^{n-1}_u\vee S^{n-1}_\ell$ to $S^{n-1}$ sends $(\sigma,\sigma)\mapsto \sigma+\alpha_\ast\sigma$. The degree of $\alpha_\ast$ is $(-1)^n$, as you saw in homework. The composite in homology for $S^{n-1}$ is multiplication by $1+(-1)^n$. Thus the differential $d:C_n(X)\to C_{n-1}(X)$ is multiplication by $1+(-1)^n$. So the cellular chain complex now looks like, if $n$ is even:
\begin{equation*}
\xymatrix{0 & C_0=\Z\ar[l] & C_1=\Z\ar[l]^0 & C_2=\Z \ar[l]^2 & \cdots\ar[l]^0 & C_{n-1}=\Z\ar[l]^0 & C_n=\Z\ar[l]^2 & 0\ar[l]}
\end{equation*}
and if $n$ is odd:
\begin{equation*}
\xymatrix{0 & C_0=\Z\ar[l] & C_1=\Z\ar[l]^0 & C_2=\Z \ar[l]^2 & \cdots\ar[l]^0 & C_{n-1}=\Z\ar[l]^2 & C_n=\Z\ar[l]^0 & 0\ar[l]}
\end{equation*}
Thus:
\begin{equation*}
 H_k(\RP^n)=\begin{cases}
\Z & k=0\text{ and }k=n\text{ odd}\\
\Z/2\Z & k\text{ odd, }0<k<n\\
0 & \text{else}
\end{cases}
\end{equation*}
This means that odd-dimensional real projective space is orientable, and even-dimensional real projective is non-orientable.
\subsection{Euler char.}
On Friday, I made the comment that things are simpler if you have (?). Here's a lemma.
\begin{lemma}
If $X$ is a CW-complex with only even cells (eg. $\CP^n,\mathbb{H}\mathbf{P}^n$), then $ H_\text{odd}(X)=0$, and $ H_\text{even}(X)=C_\text{even}(X)$. Actually, I can just write $ H_\ast(X)\cong C_\ast(X)$. Even homology groups are free abelian groups with rank given by the number of $(2q)$-cells.
\end{lemma}
\begin{proof}
Trivial.
\end{proof}
Here's a result that'll improve this.
\begin{theorem}[``Euler'' because this is the generalization of the Euler characteristic]
Let $X$ be a finite CW-complex\footnote{Some alarm starts ringing. ``What are we supposed to do? It's just here to annoy us. It's ringing, but there's nothing to answer. Can we ignore it? (Turns off the light.) Let's just talk over it''.}. (We write $A_n$ to index the $n$-cells.)\footnote{Alarm ends, yay!} Then $\sum^\infty_{n=0}(-1)^n\# A_n=:\chi(X)=\text{Euler characteristic}$ is independent of the CW-structure on $X$. 
\end{theorem}
When $n$ is even, the lemma is much stronger than this. I'm going to prove this theorem. Now I want to give a little reminder about the structure of finitely generated abelian groups.
\subsection{Finitely generated abelian groups}
If you have an abelian group $A$, you have a torsion subgroup $T(A)$, i.e., elements of finite order in $A$, i.e., $\{a\in A|\exists n\in \Z_{>0},na=0\}$. Then $A/T(A)$ is \emph{torsion free}. For a general abelian group, that's all you can say. Assume $A$ is finitely generated. Then $A/T(A)$ is also a finitely generated torsion free abelian group (take the image of the generators of $A$). This is actually a \emph{free abelian group}, and so it's isomorphic to $\Z^r$. We say that $r$ is the \emph{rank} of $A$. It's an invariant of $A$.

Another fact is the following. Recall that any subgroup of $A$ is finitely generated (nontrivial fact). This means that $T(A)$ is finitely generated. It is true that $T(A)=\Z/n_1\oplus\Z/n_2\oplus\cdots\oplus\Z/n_t$ where $n_1|n_2|\cdots|n_t$, where $t$ is well-defined and is ``the number of torsion generators''. What this means for us is that $A\cong T(A)\oplus A/T(A)\cong \Z^r\oplus\Z/n_1\oplus\Z/n_2\oplus\cdots\oplus\Z/n_t$ where $n_1|n_2|\cdots|n_t$. If $0\to A\to B\to C\to 0$ is a sexseq of finitely generated abelian groups, then $\text{rank}(A)+\text{rank}(B)=\text{rank}(C)$.
%\newpage
\section{``Euler's theorem'', and ``homology approximation'' - CTC Wall. I) Singular homology, II) CW complexes, III) ``homological algebra''}
\begin{theorem}[``Euler'']
Let $X$ be a space which admits the structure of a finite CW complex. The sum $\sum_{h=0}^\infty (-1)^k\#(k\text{-cells})$ (generalizes $V-E+F$) is independent of that structure.
\end{theorem}
\begin{proof}
Pick a CW-structure. We have $0\to C_n\to\cdots\to C_2\to C_1\to C_0\to 0$. We also have a sexseq $0\to Z_k\to C_k\to B_{k-1}\to 0$, and another one $0\to B_k\to Z_k\to H_k\to 0$. Let's use them and facts about rank that I talked about on Monday to compute what this alternating sum is. The Euler sum is the same as:
\begin{align*}
\sum_{h=0}^\infty (-1)^k\#(k\text{-cells}) & = \sum^\infty_{k=0}(-1)^k\rank(C_k)\\
& = \sum^\infty_{k=0}(-1)^k\rank(Z_k)+\sum^\infty_{k=0}(-1)^k\rank(B_{k-1})\\
& = \sum^\infty_{k=0}(-1)^k(\rank( H_k)+\rank(B_k)+\rank(B_{k-1}))
\end{align*}
The terms $\rank B_k+\rank B_{k+1}$ telescope because it's an alternating sum, and hence vanish. The sum is $\sum^\infty_{k=0}(-1)^k\rank( H_k)$. But $ H_k(X)= H_k^\text{sing}(X)$ is an invariant of the space, independent of the CW-structure.
\end{proof}
Given $ H_k(X)$, $X$ a finite type CW-complex, what's a lower bound on the number of $k$-cells? Let's see. $ H_k(X)$ is finitely generated because $C_k(X)\subseteq Z_k(X)$ is, and it surjects onto $ H_k(X)$. Thus $ H_k(X)=\bigoplus^{t(k)}_{i=1}\Z/n_i(k)\Z\oplus \Z^{r(k)}$ where the $n_1(k)|\cdots|n_{t(k)}(k)$ are the torsion indices.

The minimal chain complex with $ H_k=\Z$ and $ H_q=0$ for $q\neq k$ is just the chain complex with $0$ everywhere else except for $\Z$ in the $k$th degree. The minimal chain complex with $ H_k=\Z/n\Z$ and $ H_q=0$ for $q\neq k$ is just the chain complex with $0$ everywhere else except for $\Z\xrightarrow{n}\Z$ in dimension $k+1$ to $k$. These things are called elementary chain complexes.

A lower bound on the minimal number of $k$-cells is $r(k)+t(k)+t(k-1)$ where the last term comes for the ``torsion generator in dimension $k-1$'' (didn't catch that).
\begin{theorem}[Wall]
Let $X$ be a simply connected CW-complex of finite type. Then there exists a CW complex $Y$ with $r(k)+t(k)+t(k-1)$ $k$-cells, for all $k$, and a homotopy equivalence $Y\to X$.
\end{theorem}
I'm not going to prove this theorem. You can read Wall's theorem. You really can't ask for more. Oh, also here's a theorem.
\begin{theorem}
Let $X$ be connected and pointed $\ast\in X$. Then $\pi_1(X,\ast)\to H_1(X,\ast)$ exists, called the Hurewicz homomorphism, and it factors as $\pi_1(X,\ast)\to \pi_1(X,\ast)^{ab}\to H_1(X,\ast)$. The last map is an isomorphism.
\end{theorem}
Some examples of Wall's theorem:
\begin{example}
We know that $S^k$ has $\widetilde{ H}_q(X)=\Z$ when $q=k$ and $0$ else. Can you construct a space with $\widetilde{ H}_q(X)=\Z/n\Z$ when $q=k$ and $0$ else? We need to construct a space with the elementary chain complex with $0$ everywhere else except for $\Z\xrightarrow{n}\Z$ in dimension $k+1$ to $k$. You need to have one $0$-cell, do nothing until you get to dimension $k$, which is when you add a $k$-cell, and then use the attaching map $S^k\to S^k$ of degree $n$, i.e.:
\begin{equation*}
\xymatrix{S^k\ar[r]^{\text{degree }n}\ar[d] & S^k\ar[d]\\
D^{k+1}\ar[r] & X}
\end{equation*}
For example, when $k=1$ and $n=2$, you have $\RP^2$. This is called a ``Moore space''.
\end{example}
I brought up doing this in more generality with generators and relations, and Professor Miller built up on that:
\begin{example}
For more general abelian groups, you have a free abelian group $F_0$ sitting in a sexseq $0\to F_1\to F_0\to M\to 0$ (this is an example of a \emph{resolution of $M$}, which is what I'm going to start talking about). Then $F_1$ is also free. Pick some $k>0$. You get a space whose homology is $F_0$, namely $\bigvee_\alpha S^k$, and a space whose homology is $F_1$, namely $\coprod S^k$. You can construct a map $\coprod S^k\to \bigvee_\alpha S^k$ such that the map $\alpha:F_1\to F_0$ is what's induced on homology. Then you get:
\begin{equation*}
\xymatrix{\coprod S^k\ar[r]^{\text{gives }\alpha}\ar[d] & \bigvee_\alpha S^k\ar[d]\\
\coprod D^{k+1}\ar[r] & X}
\end{equation*}
Such an $X$ is called a Moore space, and has homology $M$ in dimension $k$ and zero everywhere else. You can't make this into a functor, i.e., this can't be made into a functor $\mathbf{Ab}\to\mathbf{Top}$.
\end{example}
\subsection{Homological algebra}
You can put coefficients into homology. Let $M$ an abelian group. You can talk about homology with coefficients in $M$. For example, $M=\Z,\QQ,\Z/n\Z,\cdots$. The $\Z/n\Z$ case when $n$ is prime is pretty important because it's then a field.

Given $X$, you get a singular simplicial set $\Sin_\ast(X)$. Then we took the free abelian group $S_\ast$ generated by $\Sin_\ast(X)$. I.e., $S_n=\Z[\Sin_n(X)]=\bigoplus_{\Sin_n(X)}\Z$. But I could replace $\Z$ with anything I wanted, and do the \emph{exact} same construction. I can just as well as put any abelian group here.

Define the ``singular chain complex with coefficients in $M$'' as $S_n(X;M)=\bigoplus_{\Sin_n(X)}M$. There's a boundary map $d:S_n(X;M)\to S_{n-1}(X;M)$. Then the homology $ H(S_\ast(X;M))=: H_\ast(X;M)$. You can verify all the Eilenberg-Steenrod axioms yourself, except for one, namely the dimension axiom - $ H_k(\ast;M)=\begin{cases}M & k=0 \\ 0 & k\neq 0\end{cases}$.

If you think about it, you'll realize that this whole unit in CW-complexes didn't use anything except for the Eilenberg-Steenrod axioms. This shows, by the way, that if you get some weird homology theory satisfying the Eilenberg-Steenrod axioms you get all the same results as if you used what we constructed before.

As an experiment, let's compute $ H_\ast(\RP^n;\Z/2\Z)$. The cellular chain complex is $0\to \Z/2\Z\to\cdots\to\Z/2\Z\to\Z/2\Z\to 0$ where the maps are alternately multiplying by $2$ and $0$. But in this case, all the maps are $0$ because $2=0$! So $ H_k(\RP^n;\Z/2\Z)=\begin{cases}\Z/2\Z & 0\leq k\leq n \\ 0 & \text{else}\end{cases}$. How about $ H_\ast(\RP^n;\QQ)$? Or $ H_\ast(\RP^n;\Z[\frac{1}{p}])$ where $\Z[\frac{1}{p}]\subseteq \QQ$? What about $\Z_{(p)}\subseteq \QQ$ where you've localized at $p$?

Anyway, if I consider $ H_\ast(\RP^n;\Z[\frac{1}{2}])$, then the cellular chain complex simplifies, but in a different way. You have $0\to \Z[\frac{1}{2}] \to\cdots\to \Z[\frac{1}{2}] \to \Z[\frac{1}{2}] \to 0$. Multiplication by $2$, however, is an isomorphism. So, $ H_k(\RP^n;\Z[\frac{1}{2}])=\begin{cases}\Z[\frac{1}{2}] & q=0,n,\, q \text{ odd} \\ 0 & \text{else}\end{cases}$. You get a much simpler result. From this point of view, even projective spaces look like a point, and odd projective spaces look like a sphere!

It's a little awkward to go through this thing. I'd like to understand:
\begin{question}
How is $ H_\ast(X;M)$ related to $ H_\ast(X)= H_\ast(X;\Z)$? This is a reasonable question.
\end{question}
The answer is called the ``universal coefficient theorem''. I'll spend a few days developing what we need to talk about this.

I want to talk about tensor products. Let me take a poll. Do you know tensor products? Working with a commutative ring instead of $\Z$? Actually, all of these examples $M=\Z,\QQ,\Z/n\Z,\Z[\frac{1}{p}]\subseteq\QQ\supseteq\Z_{(p)},\cdots$ are rings. The boundary map $d:S_n(X;M)\to S_{n-1}(X;M)$ is a module homomorphism if $M=R$ is a (\emph{always commutative}) ring.

This means that if $R$ is a commutative ring, then $ H_\ast(X;R)$ is an $R$-module. If $R$ is a ring and $M$ is an $R$-module, then $ H_\ast(X;M)$ is an $R$-module. Just look at what you have here. The $\bigoplus_{\Sin_n(X)}M$ is an $R$-module, and $d$ is an $R$-module homomorphism.

I'll admit, this is a little bit scary, because commutative rings are pretty complicated in general. I won't talk about some weirdo rings, though. I'll develop this more on Friday. Let me pass out homework.
%\newpage
\section{$\bigotimes$}
Welcome to algebraic topology! This is family weekend, so welcome. Today'll be more about algebra, and there'll be very little topology, I'm afraid. Today'll be about tensor products. I got your permission to talk about modules over a commutative ring. We're always going to let $R$ be a commutative ring (they're going to be simple; for example, $\QQ,\FF_p,\Z,\Z/n\Z,\cdots,\text{PIDs}$).

I want to tell you that the category of $R$-modules is what's called a ``categorical ring'', where the addition corresponds to the direct sum, the zero element is the zero module, $1$ is $R$ itself, and multiplication is where you put a circle around a multiplication symbol.

The reason we do this is because of bilinear maps. Let me recall the definition of a bilinear map.
\begin{definition}
If I have $M,N,P$ are $R$-modules, then a bilinear (or if you want to be annoying, $R$-bilinear) map is a map $\beta:M\times N\to P$ such that $\beta(x+x^\prime,y)=\beta(x,y)+\beta(x^\prime,y)$ and $\beta(x,y+y^\prime)=\beta(x,y)+\beta(x,y^\prime)$, and such that $\beta(rx,y)=r\beta(x,y)$ and $\beta(x,ry)=r\beta(x,y)$.
\end{definition}
\begin{example}
$\RR^n\times\RR^n\to\RR$ given by the dot product is a $\RR$-bilinear map. The cross product $\RR^3\times\RR^3\to\RR$ is $\RR$-bilinear. More generally, if $R$ is a ring then the multiplication $R\times R\to R$ is $R$-bilinear, and the multiplication on an $R$-module $M$ given by $R\times M\to M$ is $R$-bilinear. This enters into topology because the map $ H_n(X;R)\times H_n(Y;R)\xrightarrow{\times} H_{m+n}(X\times Y;R)$ is $R$-bilinear.
\end{example}
Wouldn't it be great to reduce stuff about bilinear maps to linear maps? We're going to do this by means of the universal property.
\begin{definition}
Let $M,N$ be $R$-modules. A \emph{tensor product} of $M,N$ is a $R$-module $P$ and a bilinear map $M\times N\xrightarrow{\beta_0}P$ such that for every bilinear map $M\times N\xrightarrow{\beta}Q$ there is a unique factorization.
\begin{equation*}
\xymatrix{M\times N\ar[r]^{\beta_0}\ar[dr]^\beta & P\ar@{-->}[d]^f\\
 & Q}
\end{equation*}
through an $R$-module homomorphism $f$. It's easy to check that $f\circ\beta_0$ is bilinear.
\end{definition}
So $\beta_0$ is universal bilinear map out of $M\times N$. Instead of $\beta_0$ we're going to write $M\times N\xrightarrow{\otimes}P$. This means that $\beta(x,y)=f(x\otimes y)$ in the above diagram. There are lots of things to say about this. When you have something that is defined via a universal property, you first have to check that it exists!
\begin{construction}
I want to construct an $R$-bilinear map out of $M\times N$. I guess I should say it like this. Let $\beta:M\times N\to Q$ be any $R$-bilinear map. This $\beta$ isn't linear. Maybe we should first extend it to a linear map. Consider $R\langle M\times N\rangle$, the free $R$-module generated by $M\times N$. Well, $\beta$ is a map of sets, so there's a unique $R$-linear homomorphism $\overline{\beta}:R\langle M\times N\rangle\to Q$. Then I get a factorization:
\begin{equation*}
\xymatrix{M\times N\ar[rr]^\beta\ar[dr]^{[-]} & & Q\\
& R\langle M\times N\rangle\ar[ur]^{\overline{\beta}} &}
\end{equation*}
The map $[-]$ isn't bilinear. So we should quotient $R\langle M\times N\rangle$ by a submodule $S$ of relations. More precisely, $S$ is the sub $R$-module generated by the relations needed to map $[-]$ a $R$-bilinear map, namely:
\begin{enumerate}
\item $[(x+x^\prime,y)]-[(x,y)]-[(x^\prime-y)]$.
\item $[(x,y+y^\prime)]-[(x,y)]-[(x,y^\prime)]$.
\item $[(rx,y)]-r[(x,y)]$.
\item $[(x,ry)]-r[(x,y)]$
\end{enumerate}
for all $x,x^\prime\in M$ and $y,y^\prime\in N$. Now, this map $[-]$ is bilinear - we've quotiented out by all things that made it false! Now the map $R\langle M\times N\rangle\to Q$ factors through via $R\langle M\times N\rangle\to R\langle M\times N\rangle/S\xrightarrow{f} Q$ because the map $\overline{\beta}$ is linear, and $f$ is unique because the $\overline{\beta}$ is unique, so there's at most one factorization. We just checked that there was one, so we're done. We'll also write the composition $M\times N\xrightarrow{[-]}R\langle M\times N\rangle\to R\langle M\times N\rangle/S$ as $\otimes$.
\end{construction}
You're never going to use this construction to compute anything. If you find yourself using this construction, stop and think about what you're doing.
\begin{remark}
Note that the image of $(m,n)$ in $R\langle M\times N\rangle/S$ generates $R\langle M\times N\rangle/S$ as an $R$-module. The $R$-module $R\langle M\times N\rangle/S$ contains elements of the form $x\otimes y$ with $x\in M$ and $y\in N$ because they generate $R\langle M\times N\rangle$, and $R\langle M\times N\rangle/S$ is a quotient of that.

These $x\otimes y$ are called ``decomposable tensors''. (I've heard them called pure tensors.)
\end{remark}
What are the properties of $R\langle M\times N\rangle/S=:P$?
\begin{enumerate}
\item How many maps are there that make the following diagram commute?
\begin{equation*}
\xymatrix{& P\ar@{-->}[dd]\\
M\otimes N\ar[ur]^\otimes\ar[dr]_\otimes & \\
& P}
\end{equation*}
By the uniqueness statement, there's only one map, namely the identity!
\item Suppose that we have two tensor products of $M$ and $N$, say $P$ and $P^\prime$. We have
\begin{equation*}
\xymatrix{& P\ar@{-->}[dd]^b\\
M\otimes N\ar[ur]^\otimes\ar[dr]_\otimes & \\
& P^\prime\ar@{-->}[uu]_{b^\prime}}
\end{equation*}
And $b,b^\prime$ are unique. If you compose $b$ and $b^\prime$, you'll see that you get the identity of $P$ and $P^\prime$, depending on how you compose the maps. More precisely, you have:
\begin{equation*}
\xymatrix{& P\ar@{-->}[d]^b\\
M\otimes N\ar[ur]^\otimes\ar[dr]_\otimes & P^\prime\ar[d]^{b^\prime}\\
& P^\prime}
\end{equation*}
and
\begin{equation*}
\xymatrix{& P^\prime\ar@{-->}[d]^{b^\prime}\\
M\otimes N\ar[ur]^\otimes\ar[dr]_\otimes & P\ar[d]^{b}\\
& P^\prime}
\end{equation*}
Thus $bb^\prime=1$ and $b^\prime b=1$. So $b,b^\prime$ are isomorphisms, i.e., $P\cong P^\prime$. We say that there is a canonical\footnote{This means god given, but here it means that it's naturally constructed.} isomorphism between any two constructions of a tensor products. The universal property defines the object up to canonical isomorphism. This is a general principle.

We can thus write the tensor product as if it just depended on just $M$ and $N$. We write $M\otimes N$. A general element is a finite sum $\sum_i x_i\otimes y_i$. To be really honest, we'll write $M\otimes_R N$. If $R$ is understood, we'll omit it. I'll usually forget to add the $\otimes_R$, and simply write $\otimes$.
\item Functoriality. If I have homomorphisms $M\times N\xrightarrow{f\times g}M^\prime\times N^\prime$. I have:
\begin{equation*}
\xymatrix{M\times N\ar[d]^{f\times g}\ar[r]^\otimes\ar[dr] & M\otimes N\ar@{-->}[d]\\
M^\prime\times N^\prime\ar[r]^\otimes & M^\prime\otimes N^\prime}
\end{equation*}
The dotted map exists because the diagonal map is $R$-bilinear. We write the map $M\otimes N\to M^\prime \otimes N^\prime$ as $f\otimes g$. We need to check stuff though.
\begin{equation*}
\xymatrix{M\times N\ar[d]^{f\times g}\ar[r]^\otimes\ar[dr] & M\otimes N\ar@{-->}[d]^{f\otimes g}\\
M^\prime\times N^\prime\ar[r]^\otimes\ar[d]^{f^\prime\times g^\prime} & M^\prime\otimes N^\prime\ar@{-->}[d]^{f\otimes g}\\
M^{\prime\prime}\times N^{\prime\prime}\ar[r]^\otimes & M^{\prime\prime}\otimes N^{\prime\prime}}
\end{equation*}
And the composite matches up, i.e., $(f^\prime\otimes g^\prime)(f\otimes g)=(f^\prime f)\otimes g^\prime g$.
\item I said that this was gonna be a categorical ring, so we need to check this. Well, $R\otimes_R M$ should be isomorphic to $M$. Let's think about this for a minute. I just need to check the universal property. Suppose I have an $R$-bilinear map $\beta:R\times M\to P$. We already have a universal $R$-bilinear map $\varphi:R\times M\to M$. I have to construct a universal factorization $f:M\to P$. Just let $f(x)=\beta(1,x)$. It's $R$-bilinear. We can check that this diagram commutes now because $f(\varphi(r,x))=f(rx)=\beta(1,rx)=r\beta(1,x)=\beta(r,x)$. Well, this map $R\times M\to M$ is surjective, so there's at most one factorization. So we're done. There are other checks that are extremely boring, but they're part of the toolkit.

I need to check that $L\otimes(M\otimes N)\cong (L\otimes M)\otimes N$ that's compatible with $L\times (M\times N)\cong (L\times M)\times N$. There's a canonical isomorphism. I don't know how to not say that this is trivial. Also, we need to check that $M\otimes N\cong N\otimes M$. (Just do this yourself. It's really easy.)
\item What happens with $M\otimes\left(\bigoplus_{\alpha\in A}N_\alpha\right)$? It might be a finite direct sum, or maybe an uncountable collection. How does this relate to $\bigoplus_{\alpha\in A}(M\otimes N_\alpha)$? Let's construct a map $\displaystyle\bigoplus_{\alpha\in A}(M\otimes N_\alpha)\to M\otimes\left(\bigoplus_{\alpha\in A}N_\alpha\right)$. We just need to define maps $M\otimes N_\alpha\to M\otimes\left(\bigoplus_{\alpha\in A}N_\alpha\right)$ because direct sums are coproducts. Let this map be $1\otimes\text{in}_\alpha$ where $\mathrm{in}_\alpha:N_\alpha\to \bigoplus_{\alpha\in A}N_\alpha$. These give you a map $f:\bigoplus_{\alpha\in A}(M\otimes N_\alpha)\to M\otimes\left(\bigoplus_{\alpha\in A}N_\alpha\right)$

What about a map the other way? This is a bit trickier. An element of $M\otimes\left(\bigoplus_{\alpha\in A}N_\alpha\right)$ is $x\otimes(y_\alpha)_{\alpha\in A}$, where you note that $y_\alpha=0$ for all but finitely many $\alpha\in A$. Define $g:M\otimes\left(\bigoplus_{\alpha\in A}N_\alpha\right)\to \bigoplus_{\alpha\in A}(M\otimes N_\alpha)$ via $x\otimes(y_\alpha)_{\alpha\in A}\mapsto (x\otimes y_\alpha)_{\alpha\in A}$. It's up to you to check that these are inverses and that you can extend to a general nondecomposable tensor by linearity.
\end{enumerate}
We have not done any computations yet. I guess I should end with the statement that $S_\ast(X;M):=S_\ast(X)\otimes_R M$ if $M$ is an $R$-module. We'll discuss on Monday the question we raised last time, namely:
\begin{question}
How is $ H_\ast(X;M)$ related to $ H_\ast(X)= H_\ast(X;\Z)$? This is a reasonable question.
\end{question}
%\newpage
\section{Tensor and Tor}
Office hours are: for Hood, today from 1:30 to 3:30 in 2-390, and for me on Tuesday from 1 to 3 in 2-478. Point-set topology is the hardest part of this course, sorry for messing up the question on this week's pset. I like to emphasize the algebraic part.
\subsection{Properties over $\otimes_R$}
\begin{enumerate}
\setcounter{enumi}{5}
\item A ring is precisely specified by a map $R\otimes_\Z R\xrightarrow{\mu}R\xleftarrow{\eta}\Z$. You can define a ring purely diagramattically. Associativity is commutativity of the following diagram:
\begin{equation*}
\xymatrix{R\otimes R\otimes R\ar[r]^{\mu\otimes 1}\ar[d]^{1\otimes \mu} & R\otimes R\ar[d]^{\mu}\\
R\otimes R\ar[r]^{\mu} & R}
\end{equation*}
The identity map is commutativity of the following diagram.
\begin{equation*}
\xymatrix{\Z\otimes R\ar[r]^{\eta\otimes 1}\ar[dr]_{\cong} & R\otimes R\ar[d]^{\mu} & R\otimes \Z\ar[l]^{1\otimes\eta}\ar[dl]_{\cong}\\
& R & }
\end{equation*}
In fact, an $R$-module is an abelian group with a map $R\otimes M\xrightarrow{\varphi}M$ such that the following diagram commutes.
\begin{equation*}
\xymatrix{R\otimes R\otimes M\ar[r]^{\mu\otimes 1}\ar[d]^{1\otimes \eta} & R\otimes M\ar[d]^{\varphi}\\
R\otimes M\ar[r]^{\varphi} & R}
\end{equation*}
If $A$ is an abelian group, then $R\otimes A$ is an $R$-module, where the multiplication is: $R\otimes(R\otimes A)\to (R\otimes R)\otimes A\xrightarrow{\mu\otimes 1}R\otimes A$. If $A$ is an abelian group, then $A\to R\otimes A$ sending $a\mapsto 1\otimes a$ is universal for maps from $A$ to an $R$-module. We say that it's ``initial''. This means that if $M$ is an $R$-module, there is a factorization:
\begin{equation*}
\xymatrix{A\ar[r]\ar[d]^f & R\otimes A\ar@{-->}[dl]\\
M}
\end{equation*}
Where the map $R\otimes A\to M$ is an $R$-module homomorphism and the map $A\to M$ is an abelian group homomorphism. Why is this true? We have a map $R\otimes A\xrightarrow{1\otimes f}R\otimes M$, so the multiplication $\varphi:R\otimes M\to M$ is what we want. I.e., the extension is the composition:
\begin{equation*}
\xymatrix{A\ar[r]\ar[d]_f & R\otimes A\ar[d]^{1\otimes f}\ar[dl]|{\varphi\circ(1\otimes f)}\\
M & R\otimes M\ar[l]^{\varphi}}
\end{equation*}
\begin{example}
What if we let $A=\Z/n\Z$? Then if $B$ is an abelian group (i.e., a $\Z$-module), $B\otimes \Z/n\Z\cong B/nB$.
\end{example}
\item Consider $0\to \Z\xrightarrow{2}\Z\to \Z/2\Z\to 0$. Let's tensor with $\Z/2\Z$, to get $0\to \Z/2\Z\to\Z/2\Z\to\Z/2\Z\to 0$. This cannot be a sexseq! But it's clear that the surjection $\Z\to\Z/2\Z$ gives an isomorphism $\Z/2\Z\to\Z/2\Z$, i.e., $0\to \Z/2\Z\xrightarrow{0}\Z/2\Z\xrightarrow{\cong}\Z/2\Z\to 0$. This is one of the major tragedies, that tensoring isn't exact. Exact means preserves exact sequences. The moral is that tensoring isn't generally exact, but preserves cokernels. More precisely:
\begin{prop}
The functor $N\otimes M\otimes_R N$ preserves cokernels. What do I mean? This means that this functor is \emph{right exact}, i.e., if $N^\prime\xrightarrow{i} N\xrightarrow{p} N^{\prime\prime}\to 0$ is exact, then so is $M\otimes_R N^\prime\to M\otimes_R N\to M\otimes_R N^{\prime\prime}\to 0$.
\end{prop}
\begin{proof}
We have:
\begin{equation*}
\xymatrix{M\otimes_R N^\prime\ar[r]^{1\otimes i} & M\otimes_R N\ar[r]\ar[d] & M\otimes_R N^{\prime\prime}\\
 & M\otimes_R N/(\img(1\otimes i))=M\otimes_R N/I\ar@{-->}[ur]_{\overline{\phi}}}
\end{equation*}
At least we know that the composite $M\otimes_R N^\prime\to M\otimes_R N\to M\otimes_R N^{\prime\prime}$ is zero. But this means that the dotted map exists, because the image $I$ has to be sent to zero. The claim is that $\overline{\phi}$ is an isomorphism. We can construct an inverse to $\overline{\phi}$. It's easy to construct maps \emph{out} of tensor products. This inverse will be a map $M\otimes_R N^{\prime\prime}\xrightarrow{q}M\otimes_R N/I$. How do we construct maps out of a tensor product? Consider:
\begin{equation*}
\xymatrix{M\otimes_R N^{\prime\prime}\ar@{-->}[r]^{\overline{q}} & M\otimes_R N/I\\
M\times N^{\prime\prime}\ar[u]\ar[ur]^q}
\end{equation*}
Where will $x\otimes y$ be sent? Let's pick $\overline{y}\in N$ such that $p\overline{y}=y$. I can do that because I supposed that $p$ was surjective in the first place. Maybe I'm using the axiom of choice. (By the way, if I had a split exact sequence, tensoring will preserve split exact sequences, but not general exact sequences.) Anyway, map $x\otimes y\mapsto x\otimes\overline{y}+I$. That's the only thing I can think of doing, and so we pray and hope that it works. Let's check that this is well-defined first.

We know that $\overline{y}$ is only well-defined up to the image of something from $N^\prime$. So consider $\overline{y}^\prime=\overline{y}+iz$ for $z\in N^\prime$. These are the only possible lifts. Then we get $x\otimes\overline{y}^\prime=x\otimes(\overline{y}+iz)+x\otimes\overline{y}+x\otimes i(z)=x\otimes\overline{y}+(1\otimes i)(x\otimes z)\in x\otimes\overline{y}+I$. Luckily, we divided out by $I$. There's \emph{four} other things I have to check. I have to check that this is linear in each variable. This is just fussing around with the formula. Let's assume we've done that.

Pretty much by construction, $\overline{q}$ is the inverse for $\overline{p}$. This is because $p$ takes $x\otimes\overline{y}+I$ to $x\otimes y$ because that's what $\overline{p}$ does -- it just applies $p$ to the second factor. 
\end{proof}
\end{enumerate}
How about this failure of exactness? What can we do about that? Failure of exactness is bad, so let's try to repair it.

Think of a sexseq of chain complexes (that are bounded below by $0$ and are nonnegatively graded) $0\to N^\prime_\bullet\to N_\bullet\to N^{\prime\prime}_\bullet\to 0$. We get an exact sequence $ H_0 N^\prime\to H_0 N\to H_0 N^\prime\prime\to 0$. We already know that this isn't exact on the left because we have a lexseq in homology (because $ H_1 N^\prime\prime$ need not be trivial). Let's imagine $M\otimes_R-$ as analogous to $ H_0$. We already have an example of a functor that is right exact but not left exact (namely $ H_0$), so this isn't unreasonable. I think I'll write down a theorem and finish the proof on Wednesday.
\begin{theorem}
There are functors $\Tor^R_n(M,-):\mathbf{Mod}_R\to\mathbf{Mod}_R$ for $n\geq 0$, where I have a fixed ring $R$ and a fixed $R$-module $M$, and natural transformations sending a sexseq $0\to N^\prime\to N\to N^{\prime\prime}\to 0$ to $\partial:\Tor^R_n(M,N^{\prime\prime})\to \Tor^R_{n-1}(M,N^\prime)$ such that you get a lexseq:
\begin{equation*}
\xymatrix{\cdots\ar[r] & \Tor^R_n(M,N)\ar[r] & \Tor^R_n(M,N^{\prime\prime})\ar[dll]\\
\Tor^R_{n-1}(M,N^\prime)\ar[r] & \Tor^R_{n-1}(M,N)\ar[r] & \cdots}
\end{equation*}
such that $\Tor^R_0(M,N)=M\otimes_R N$. Basically, $\Tor$ fulfills the same role as homology.
\end{theorem}
Some properties are as follows.
\begin{itemize}
\item $\Tor^R_q(M,N)=0$ for $q>1$ is $R$ is a PID.
\item $\Tor^R_q(M,F)=0$ for $q>0$ if $F$ is a free $R$-module.
\end{itemize}
Let's explore what this gives us before we construct it.
\begin{example}
Let $R=\Z$, and consider the sexseq $0\to \Z\xrightarrow{n}\Z\to\Z/n\Z\to 0$. Because $\Z$ is free, you have:
\begin{equation*}
\xymatrix{\cdots\ar[r] & 0\ar[r] & \Tor^\Z_n(C_\bullet)(M,\Z/n\Z)\ar[dll]\\
\Tor^\Z_{0}(M,\Z)=M\otimes\Z\ar[r]^{\times n} & \Tor^\Z_{0}(M,\Z)=M\otimes\Z\ar[r] & \Tor^\Z_0(M,\Z/n\Z)=M/nM\ar[r] & 0}
\end{equation*}
So $\Tor^\Z_1(M,\Z/n\Z)=\ker(M\xrightarrow{n}M)$. This is the \emph{$n$-torsion} of $M$. That's the origin of $\Tor$. This is the key example to keep in mind. He said something like ``In general, $\Tor$ isn't free, but it is here because $\Z$ is a PID.''
\end{example}
Take a general $R$-module $N$. You can always take a free module $F_0$ that surjects onto $N$, i.e., $F_0\to N\to 0$. For example, you can let $F_0$ be the free $R$-module on the underlying set of $N$. Form a sexseq $0\to K_0\to F_0\to N\to 0$. You have an exact sequence for $n>1$:
\begin{equation*}
\xymatrix{\cdots\ar[r] & 0\ar[r] & \Tor^R_n(M,N)\ar[dll]\\
\Tor^R_{n-1}(M,K_0)\ar[r] & 0\ar[r] & \cdots}
\end{equation*}
So for $n>1$, $\Tor^R_n(M,N)\to \Tor^R_{n-1}(M,K_0)$ is an isomorphism. If $n=1$, then:
\begin{equation*}
\xymatrix{\cdots\ar[r] & 0\ar[r] & \Tor^R_1(M,N)\ar[dll]\\
M\otimes_R K_0\ar[r] & M\otimes_R F_0\ar[r] & M\otimes_R N\ar[r] & 0}
\end{equation*}
The maps between the tensors might be hard to compute, but you can compute this as a kernel.

But I've not constructed the functors yet. I just said to assume that it exists. This was so much fun, taking a free module and surjecting it onto $N$. What I'm trying to do is:
\begin{equation*}
\xymatrix{\cdots\ar@{-->}[rr] & & F_2\ar[dr]\ar@{-->}[rr]^d & & F_1\ar[dr]\ar@{-->}[rr]^d & & F_0\ar[dr]\\
& K_2\ar[ur]\ar[dr] & & K_1\ar[ur]\ar[dr] & & K_0\ar[ur]\ar[dr] & & N\ar[dr]\\
0\ar[ur] & & 0\ar[ur] & & 0\ar[ur] & & 0\ar[ur] & & 0}
\end{equation*}
Where $F_{i+1}$ surjects onto $K_i$ and the $F_i$ are free $R$-modules. Splicing these exact sequences gives you a exact sequence in the top row. This is what's called a \emph{free resolution of $N$}. You can actually write this as:
\begin{equation*}
\xymatrix{\cdots\ar[r] & F_2\ar[r] & F_1\ar[r] & F_0\ar[r]\ar[d] & 0\\
 & & & N & }
\end{equation*}
The $F_0$ are generators of $N$, the $F_1$ are relations, the $F_2$ are relations between relations, and so on. We say that these are syzygies. The singular term is syzygy.
%\newpage
\section{More about $\Tor$}
Where is everybody? Looks like nobody wants to hear about $\Tor$. You're the select few.

On Monday I gave ``axioms'' for $\Tor$, basically by saying that $\Tor^R_n(M,-):\mathbf{Mod}_R\to\mathbf{Mod}_R$ is like a homology theory. Today I'm going to show a construction of $\Tor$, and verify the axioms. Or at least the lexseq business. I also tried to show that it's a reasonable idea to study free resolutions, namely:
\begin{equation*}
\xymatrix{\cdots\ar@{-->}[rr] & & F_2\ar[dr]\ar@{-->}[rr]^d & & F_1\ar[dr]\ar@{-->}[rr]^d & & F_0\ar[dr]\\
& K_2\ar[ur]\ar[dr] & & K_1\ar[ur]\ar[dr] & & K_0\ar[ur]\ar[dr] & & N\ar[dr]\\
0\ar[ur] & & 0\ar[ur] & & 0\ar[ur] & & 0\ar[ur] & & 0}
\end{equation*}
Where $F_{i+1}$ surjects onto $K_i$ and the $F_i$ are free $R$-modules. Splicing these exact sequences gives you a exact sequence in the top row, which is a free resolution of $N$. Of course there are a lot of choices involved, so free resolutions aren't unique. The resolution $F_\bullet$ does \emph{not} include $N$, and in the following diagram, the top row isn't exact but $\cdots\to F_0\to N\to 0$ is exact.
\begin{equation*}
\xymatrix{\cdots\ar[r] & F_2\ar[r] & F_1\ar[r] & F_0\ar[r]\ar[d]^\epsilon & 0\\
 & & & N & }
\end{equation*}
Then, note that:
\begin{equation*}
 H_q(F_\bullet)=\begin{cases}
N & q=0\\
0 & q>0
\end{cases}
\end{equation*}
\begin{construction}
We construct $\Tor^R_n(M,N)$ via $ H_n(M\otimes_R F_\bullet)$ where $F_\bullet$ is a free resolution of $N$.
\end{construction}
I have to check that this is well-defined, that it's functorial, and that it satisfies the lexseq. Maybe I should also check what $ H_0(M\otimes_R F_\bullet)$ is. I do get $M\otimes_R F_\bullet$, because tensoring with $M$ is right exact, i.e., you have an exact sequence $M\otimes_R F_1\xrightarrow{p} M\otimes_R F_0\to M\otimes_R N\to 0$, and the zeroth homology is the cokernel of $p$, which is $M\otimes_R N$.

The check that it's well-defined goes like this. I call this the fundamental theorem of homological algebra.
\begin{theorem}[Fundamental theorem of homological algebra]
Let $f:M\to N$ be an $R$-module homomorphism. Let $\cdots\to E_1\to E_0\to M\to 0$ be such that each $E_n$ is free, and $\cdots\to F_1\to F_0\to N\to 0$ is exact. The fundamental theorem says that I can lift the map $f:M\to N$ to a chain map $E_\bullet\to F_\bullet$ (i.e. they commute with the differentials and the augmentations $\epsilon_N:F_0\to N$ and $\epsilon_M:E_0\to M$), that is unique up to chain homotopy. I.e., they sit in the following commutative diagram:
\begin{equation*}
\xymatrix{\cdots\ar[r] & E_2\ar[r]\ar@{-->}[d]^{f_2} & E_1\ar[r]\ar@{-->}[d]^{f_1} & E_0\ar[r]^{\epsilon_M}\ar@{-->}[d]^{f_0} & M\ar[d]^f\ar[r] & 0\\
\cdots\ar[r] & F_2\ar[r] & F_1\ar[r] & F_0\ar[r]^{\epsilon_N} & N\ar[r] & 0}
\end{equation*}
\end{theorem}
I'm making a big deal about homological algebra in this course on algebraic topology, because this really is a homotopy-theoretic statement. It's part of the homotopy theory of chain complexes. I just want to mention something.
\begin{definition}
A projective $R$-module $P$ is something such that there's a lift:
\begin{equation*}
\xymatrix{ & M\ar@{->>}[d]\\
P\ar@{-->}[ur]\ar[r] & N}
\end{equation*}
\end{definition}
Every free module is projective, clearly. Anything that's a direct summand in a projective is also projective. Any projective module is a direct summand of a free module.
\begin{example}
Let $k$ be a field. Then $k\times k$ acts on $k$ via $(a,b)c=ac$. This is an example of a projective that isn't free.
\end{example}
\begin{remark}
This proof uses only that $E_n$ is projective. But if you have a PID, there's no difference between projective and free.
\end{remark}
\begin{proof}[Proof of the fundamental theorem of homological algebra]
Let's try to construct $f_0$. Consider:
\begin{equation*}
\xymatrix{0\ar[r] & K_0\ar[r]\ar@{-->}[d]^{g_0} & E_0\ar[r]^{\epsilon_M}\ar@{-->}[d]^{f_0} & M\ar[d]^f &\\
0\ar[r] & L_0=\ker(\epsilon_N)\ar[r] & F_0\ar@{->>}[r]^{\epsilon_N} & N\ar[r] & 0}
\end{equation*}
We know that $E_0=R\langle S\rangle$. What we do is push forward the generators of $E$ via $\epsilon_M$, push it forward to $f$, and pull it back via $\epsilon_N$ which makes sense because it's surjective. This gives us $f_0$. You can restrict it to get $g_0$. Now I'm in exactly the same situation.
\begin{equation*}
\xymatrix{0\ar[r] & K_1\ar[r]\ar@{-->}[d]^{g_1} & E_1\ar[r]^{\epsilon_M}\ar@{-->}[d]^{f_1} & K_0\ar[d]^{g_0} &\\
0\ar[r] & L_1\ar[r] & F_1\ar[r] & L_0\ar[r] & 0}
\end{equation*}
And $g_1$ exists. Now we need to prove the chain homotopy claim. Suppose I have $f_\bullet:E_\bullet\to F_\bullet$ and $f^{\prime}_\bullet:E_\bullet\to F_\bullet$. Then $f^\prime_n-f_n$ (which we'll rename $\ell_n$) is a chain map lifting $0:M\to N$. Let's rename things, so I have:
\begin{equation*}
\xymatrix{\cdots\ar[r] & E_2\ar[r]\ar[d]^{\ell_2} & E_1\ar[r]\ar[d]^{\ell_1} & E_0\ar[r]^{\epsilon_M}\ar[d]^{\ell_0} & M\ar[d]^0\ar[r] & 0\\
\cdots\ar[r] & F_2\ar[r] & F_1\ar[r] & F_0\ar[r]^{\epsilon_N} & N\ar[r] & 0}
\end{equation*}
We want that $\ell_\bullet\simeq 0$. That is, we want $h:E_n\to F_{n+1}$ such that $dh+hd=\ell$. To begin with, we consider:
\begin{equation*}
\xymatrix{ & E_0\ar[d]^{\ell_0}\ar@{-->}[dl]^h & \\
F_1\ar[r]^d & F_0}
\end{equation*}
At the beginning, we want $dh=0$. Well, we consider:
\begin{equation*}
\xymatrix{ & & E_0\ar[d]^{\ell_0}\ar[dl]\ar@{-->}[dll] & \\
F_1\ar@{->>}[r] & L_0\ar[r] & F_0}
\end{equation*}
Because $F_1\to L_0$ is a surjection, the lift exists, and we have $dh=\ell_0$. For the next step, we have:
\begin{equation*}
\xymatrix{ & & E_1\ar[r]\ar[d]^{\ell_1}\ar@{-->}[dll] & E_0\ar[d]^{\ell_0}\ar[dl]^h & \\
F_2\ar@{->>}[r] & L_1\ar[r] & F_1\ar[r]^d & F_0}
\end{equation*}
So what do I want to do here? Ultimately what I want is that $dh=\ell_1-hd$. Well, $d(\ell_1-hd)=d\ell_1-dhd=d\ell_1-\ell_0d=0$ where the last equality comes because $\ell$ is a chain map. So now we can use exactness of $E_\bullet$ to define $h$. Exactly the same process continues.
\end{proof}
That's it. We're going to use this several times. I'm glad to have mentioned the notion of projectivity, because we'll use it later. Now, apply $M\otimes_R -$ to that resolution (???). Suppose I have $f:N\to N^\prime$, and get a map $f_\bullet:F_0\to F^\prime_\bullet$. Apply $M\otimes_R -$ to this, to get a chain map $M\otimes_R F_\bullet\to M\otimes_R F^\prime_\bullet$ to get a map in homology $ H_\ast(M\otimes_R F_\bullet)\to H_\ast(M\otimes_R F^\prime_\bullet)$. How independent is this of the lifting that I chose? Suppose I have two chain maps $1\otimes f_0,f\otimes f_0^\prime:M\otimes_R F_\bullet\to M\otimes_R F^\prime_\bullet$. I can certainly form $1\otimes h:M\otimes_R F_n\to M\otimes_R F^\prime_{n+1}$. I know that $dh+hd=f-f^\prime$. When I tensor, I get $1\otimes(hd+dh)=1\otimes(f-f^\prime)$. But I want that $(1\otimes h)(1\otimes d)+(1\otimes d)(1\otimes h)=1\otimes f-1\otimes f^\prime$. We use a further property of the tensor product:
\begin{enumerate}
\setcounter{enumi}{7}
\item If $f,f^\prime:N\to N^\prime$, then $1\otimes(f+f^\prime)=1\otimes f+1\otimes f^\prime:M\otimes_R N\to M\otimes_R N^\prime$, and $1\otimes(rf)=r(1\otimes f)$. And $M\otimes_R -$ is an $R$-linear functor. 
\end{enumerate}
There's things called derived functors. In more general cases, you can't use chain complexes, but rather you use simplicial resolutions. There's non-additive homological algebra. Anyway, you check that $1\otimes f$ and $1\otimes f^\prime$ are indeed chain homotopic, and so you're done.

I think I've verified that it's well-defined and functorial. What about the lexseq? Now, I start with a sexseq and want to get an lexseq. Suppose I have a sexseq $0\to A\to B\to C\to 0$. I should first come up with an sexseq of resolutions. Consider:
\begin{equation*}
\xymatrix{0\ar[r] & A\ar[r] & B\ar[r] & C\ar[r] & 0\\
 & F^\prime_0\ar[u] & & F^{\prime\prime}_0\ar[u] & \\
 & F^\prime_1\ar[u] & & F^{\prime\prime}_1\ar[u] & \\
 & \vdots\ar[u] & & \vdots\ar[u] & }
\end{equation*}
I want to get a free resolution in the middle. The only thing that I can think of doing is constructing:
\begin{equation*}
\xymatrix{0\ar[r] & A\ar[r]^i & B\ar[r] & C\ar[r] & 0\\
0\ar[r] & F^\prime_0\ar[u]^{\epsilon_A}\ar[r] & F^\prime_0\oplus F^{\prime\prime}_0\ar@{-->}[u]^{\epsilon_B}\ar[r] & F^{\prime\prime}_0\ar[u]^{\epsilon_B}\ar[r] & 0 \\
 & F^\prime_1\ar[u] & & F^{\prime\prime}_1\ar[u] & \\
 & \vdots\ar[u] & & \vdots\ar[u] & }
\end{equation*}
In fact, it's the only choice because you have a free module and the sexseq splits. If I'm going to make this work, this is the only thing I can do. I need the augmentation, though. We can think of $\epsilon_B$ as a row vector. The first entry obviously has to be $i\epsilon$. And, well, there's a lift\footnote{There's some ambiguity here. I have to make a choice. It might seem that the boundary map is made up of the choices, but it \emph{isn't}! I haven't proved that. It still needs to be proved.} because $F^{\prime\prime}_0$ is a free resolution:
\begin{equation*}
\xymatrix{0\ar[r] & A\ar[r]^i & B\ar[r] & C\ar[r] & 0\\
0\ar[r] & F^\prime_0\ar[u]^{\epsilon_A}\ar[r] & F^\prime_0\oplus F^{\prime\prime}_0\ar@{-->}[u]^{\epsilon_B}\ar[r] & F^{\prime\prime}_0\ar[u]^{\epsilon_B}\ar@{-->}[ul]^{\overline{\epsilon}}\ar[r] & 0 \\
 & F^\prime_1\ar[u] & & F^{\prime\prime}_1\ar[u] & \\
 & \vdots\ar[u] & & \vdots\ar[u] & }
\end{equation*}
So that $\epsilon_B=[i\epsilon,\overline{\epsilon}]$. This is surjective by the Snake lemma. Consider:
\begin{equation*}
\xymatrix{& 0 & 0 & 0 & \\
0\ar[r] & A\ar[r]^i\ar[u] & B\ar[r]\ar[u] & C\ar[r]\ar[u] & 0\\
0\ar[r] & F^\prime_0\ar[u]^{\epsilon_A}\ar[r] & F^\prime_0\oplus F^{\prime\prime}_0\ar@{-->}[u]^{\epsilon_B}\ar[r] & F^{\prime\prime}_0\ar[u]^{\epsilon_B}\ar@{-->}[ul]^{\overline{\epsilon}}\ar[r] & 0\\
 0\ar[r] & K^\prime_0=\ker\epsilon_A\ar[u]\ar[r] & K_0\ar[r]\ar[u] & K^{\prime\prime}_0=\ker\epsilon_B\ar[u]\ar[r] & 0\\
 & 0\ar[u] & 0\ar[u] & 0\ar[u] & }
\end{equation*}
The bottom row is exact by the $3\times 3$-lemma. It's why I gave it to you for homework! Anyway, I now have a sexseq of free resolutions $0\to F^\prime_\bullet\to F_\bullet\to F^{\prime\prime}_\bullet\to 0$. Now I want a sexseq $0\to M\otimes_R F^\prime_\bullet\to M\otimes_R F_\bullet\to M\otimes_R F^{\prime\prime}_\bullet\to 0$, but I don't know this because $M\otimes_R -$ isn't exact. It's why we got into the business in the whole place. But $0\to F^\prime_\bullet\to F_\bullet\to F^{\prime\prime}_\bullet\to 0$ is split. And applying any functor gives a splitting of the sexseq, i.e., $M\otimes_R -$ sends split sexseqs to (split) sexseq. This means that $0\to M\otimes_R F^\prime_\bullet\to M\otimes_R F_\bullet\to M\otimes_R F^{\prime\prime}_\bullet\to 0$ also splits. Thus we're done proving the lexseq in $\Tor$.

The key idea in homological algebra is that free modules are good.
%\newpage
\section{Direct Limits}
Goals are UCT (universal coefficient theorem), which is about $ H_\ast(X;M)$ for varying $M$, the K\"{u}nneth theorem (which is about $ H_\ast(X\times Y)$), cohomology, and Poincar\'{e} duality.
\subsection{Two more things about $\Tor$}
If $R$ is a PID, then there's not so much to say about $\Tor$, because any submodule of a free module is free. So that means that any $R$-module has a free resolution $0\to F_1=\ker(f)\to F_0\xrightarrow{f}\to N\to 0$. It follows that $\Tor^R_n(M,N)=0$ for $n>1$. If you have a field, then tensoring is exact, so $\Tor^k_0(M,N)=0$ for $n>0$. That's why it's easy to work with fields. (There's also Prufer rings, where every module is flat.) By the way, this means that if you have a sexseq $0\to A\to B\to C\to 0$, then over a PID $R$, there's a six-term exact sequence $0\to\Tor^R_1(M,A)\to \Tor^R_1(M,B)\to \Tor^R_1(M,C)\to M\otimes_R A\to M\otimes_R B\to M\otimes_R C\to 0$.
\begin{example}
I want to give an example when you do have higher $\Tor$. Let $k$ be a field. Let $R=k[e]/(e^2)$. This is sometimes called the ``dual numbers'', or the exterior algebra over $k$. We're going to consider $R$-modules. Let's construct a projective resolution of $k$. Hmm. What is an $R$-module $M$? It's just a $k$-vector space $M$ with an operator $d$ that has action given by multiplication by $e$, and this satisfies $d^2=0$. And this is a chain complex! I guess it's not quite a chain complex because for us chain complexes are graded. So I guess it's an ungraded chain complex. I can consider $ H(M;d):=\ker d/\img d$. Here's an example of an $R$-module. There's the augmentation $R\to k$ sending $e\mapsto 0$. This makes $k$ an $R$-module, where $d=0$. Let's construct a free resolution of $k$.

Here we go. We're going to write $k=\bullet(=1)$ and $R:=(1=)\bullet\xrightarrow{d}\bullet(=e)$. Well, we have $R\to k$ given by $(\bullet\xrightarrow{d}\bullet)\to \bullet$. The kernel is not free, so we get $(\bullet\xrightarrow{d}\bullet)\to (\bullet\xrightarrow{d}\bullet)\to \bullet$. And this continues, so we get a projective resolution $\cdots\xrightarrow{e} R\xrightarrow{e} R\xrightarrow{e} R\to k$. What is $\Tor$? Well, $\Tor^R_\ast(M,k)$ is the homology of the following chain complex $\cdots\xrightarrow{d} M\xrightarrow{d} M\to 0$. What is that homology? Clearly $\Tor^R_0(M,k)=M\otimes_R k=M/dM=M/eM$. This is often called the module of indecomposables. And, $\Tor^R_n(M,k)= H(M;d)$.
\end{example}
Last comment about $\Tor$ is that there's a symmetry there. Of course, $M\otimes_R N\cong N\otimes_R M$. This uses the fact that $R$ is commutative. This leads right on to saying that $\Tor^R_n(M,N)\cong \Tor^R_n(N,M)$. We've been computing $\Tor$ by taking a resolution of the second variable. But I could equally have taken a resolution of the first variable. This follows from the fundamental theorem of homological algebra.
\subsection{Direct limits}
A long time ago, I said what a poset was. Let me tell you a joke about posets. I was at a conference, and Quillen was giving a talk. He was a student of Raoul Bott. Quillen was giving his talk, and he used the term ``poset''. This word was invented by Garrett Birkhoff(?). Then Bott objected and said ``What is this crazy word?'', and Quillen responded ``What are you talking about? Your colleague invented it!''. Anyway, it's not a joke. I guess it's just a piece of MIT and Harvard rivalry.

Anyway, a poset is a small category $\cI$ such that $\#\cI(i,j)\leq 1$ and isomorphism implies identity. I want to talk about a \emph{directed set}.
\begin{definition}
A poset $(\cI,\leq)$ is \emph{directed} if, for every $i,j$, there exists a $k$ such that $i\leq k$ and $j\leq k$.
\end{definition}
\begin{example}
For example, the natural numbers $\Z_{\geq 0}$ with equality. Another example: if $X$ is a space and $I$ is the set of open subsets of $X$. It's directed by saying that $U\leq V$ if $U\subseteq V$. This is because $U,U^\prime$ need not be comparable, but $U,U^\prime\subseteq U\cup U^\prime$. Another example is $\Z_{>0}$ where $i\leq j$ if $i|j$. This is because $i,j|(ij)$.
\end{example}
\begin{definition}
Let $\cI$ be a directed set. An $\cI$-directed diagram in $\cc$ is a functor $\cI\to\cc$. This means that for every $i\in \cI$, there is $X_i\in\cc$, and for every $i\leq j$, there's a map $X_i\xrightarrow{f_{ij}} X_j$ (and similarly for composition).
\end{definition}
\begin{example}\label{linear}
If $\cI=(\Z_{\geq 0},\leq)$, then you get $X_0\xrightarrow{f_{01}}X_1\xrightarrow{f_{12}}X_2\to\cdots$. This is the most important.
\end{example}
\begin{example}
Suppose $\cI=(\Z_{>0},|)$, i.e., the third example above. You can consider $\cI\to\mathbf{Ab}$, say assigning to each $i$ the integers $\Z$, and $f_{ij}:\Z\xrightarrow{j/i}\Z$. You get the picture.
\end{example}
These directed systems are a little complicated. But there's a simple one, namely the constant one. 
\begin{example}
Let $\cI$ be any directed set. You have a constant functor $c_A:\cI\to\cc$ at some $A\in\cc$.
\end{example}
Of course, $\cI$-directed systems in $\cc$ are functors $\cI\to\cc$. They have natural transformations, and those are the morphisms in the category of $\cI$-directed systems. That just means that if I have two directed systems $X,Y:\cI\to\cc$, then a map from one to the other is a commuting diagram:
\begin{equation*}
\xymatrix{X_i\ar[r]\ar[d]^{g_i} & X_j\ar[d]^{g_j}\\
Y_i\ar[r] & Y_j}
\end{equation*}
for all $i\leq j$.

It'd be great if every directed system was constant, but this isn't true. This leads to direct limits.
\begin{definition}
A direct limit is an object $L$ and a map $X\to c_L$, which is initial among maps to constant systems. This means that I have some other map $X\to c_A$, then there's a unique induced map $c_L\to c_A$ that is induced from a map $L\to A$. We write $\varinjlim_{i\in \cI}X_i=\colim_{i\in I}X_i$. (My own note: it's also sometimes called an an inductive limit.)
\end{definition}
This is a universal property. So two different direct limits are canonically isomorphic.
\begin{example}
Consider $\cI=(\Z_{\geq 0},\leq)$, then you get $X_0\xrightarrow{f_{01}}X_1\xrightarrow{f_{12}}X_2\to\cdots$ in $\mathbf{Top}$. What is the direct limit? It's going to be $\bigcup_i X_i$. But what's the topology? Give it the finest topology so that all of the maps to the union are open. This just means that a subset is open in $\bigcup_i X_i$ if the preimage is open.
\end{example}
\begin{example}
Recall our example where we let $\cI=(\Z_{>0},|)$, i.e., the third example above. You can consider $\cI\to\mathbf{Ab}$, say assigning to each $i$ the integers $\Z$, and $f_{ij}:\Z\xrightarrow{j/i}\Z$. The colimit is $\QQ$, where you send $X_n\to\QQ$ via $1\mapsto \frac{1}{n}$.
\end{example}
\begin{lemma}
Let $X:\cI\to\mathbf{Ab}$ (or $\mathbf{Mod}_R$). A map $f:X\to c_L$ is the direct limit (we write $f_i:X_i\to L$) if and only if:
\begin{enumerate}
\item For every $x\in L$, there exists an $i$ and an $x_i\in X_i$ such that $f_i(x_i)=x$.
\item Let $x_i\in X_i$ be such that $f_i(x_i)=0$ in $L$. Then there exists some $j\geq i$ such that $f_{ij}(x_i)=0$ in $X_j$.
\end{enumerate}
\end{lemma}
\begin{proof}
Straightforward.
\end{proof}
It generalizes the observation that $\QQ$ is the colimit of the diagram we drew above for $\cI=(\Z_{>0},|)$.
\begin{corollary}
The direct limit $\varinjlim_I:\Fun(\cI,\mathbf{Ab})\to\mathbf{Ab}$ is exact. In other words, $X_\bullet\to Y_\bullet\xrightarrow{p} Z_\bullet$ is an exact sequence of $\cI$-directed systems (at every degree, we get an exact sequence of abelian groups), then $\varinjlim_IX_\bullet\xrightarrow{i} \varinjlim_IY_\bullet\xrightarrow{p} \varinjlim_IZ_\bullet$.
\end{corollary}
\begin{proof}
First of all, $X_\bullet\to Z_\bullet$ is zero. Thus it factors through the constant zero object, so that $\varinjlim_IX_\bullet\to \varinjlim_I Z_\bullet$ is zero. Let $y\in \varinjlim_IY_\bullet$, and suppose $y$ maps to $0$ in $\varinjlim_IZ_\bullet$. By the first condition, there exists $i$ such that $y=f_i(y_i)$ for some $y_i\in Y_i$. Then $p(y)=f_ip(y_i)$ because $p$ is a map of systems. This is zero. This means that there is $j\geq i$ such that $f_{ij}p(y_i)=0$. We have an element in $Y_j$ that maps to zero, so there is some $x_j$ that is the preimage of the element in $Y_j$. So we're done.
\end{proof}
This makes the world a nice place to live.
%\newpage
\section{Universal coefficient theorem (and $\Hom$, adjointness)}
On Wednesday, we'll talk about the K\"{u}nneth theorem, and later we'll talk about the K\"{u}nneth theorem. We've been talking about tensor products of $R$-modules, but we can do something that's more natural in a way. That's the notion of $\Hom_R(M,N)$, which is the collection of $R$-linear homomorphisms between $R$-modules $M$ and $N$. This is actually itself an $R$-module. It's an abelian group, first of all, because you can add morphisms. How does $r\in R$ act on $f\in \Hom_R(M,N)$? Just define $(rf)(x)=f\cdot f(x)$. You should check that this does actually define an $R$-module homomorphism. (This is trivial.) If $R$ isn't commutative I guess there'd be an action of $Z(R)$ on $\Hom_R(M,N)$. In particular, $\Hom_R(M,-):\mathbf{Mod}_R\to\mathbf{Mod}_R$.
\begin{remark}
You're supposed to technically write $\underline{\Hom}_R(M,N)$ to mean $\Hom_R(M,N)$ with the structure of an $R$-module. But in these notes, I will not do this.
\end{remark}
I wanted to bring this up because it relates to tensor products in a beautiful way. Consider $\Hom_R(M\otimes_R N,L)$. This is the collection of $R$-bilinear maps $M\times N\to L$. I claim that $\Hom_R(M\otimes_R N,L)\cong\Hom_R(M,\Hom_R(N,L))$. The way this works is the following. Suppose $f:M\otimes_R N\to L$. Define $\widehat{f}:M\to\Hom_R(N,L)$ via $\widehat{f}:m\mapsto(n\mapsto f(m\otimes_R n))$. This is a special case of the notion of an adjoint functor, introduced by Dan Kan, who was actually here at MIT. This is a big part of category theory.
\begin{prop}
Let $\cI$ be a direct set, and let $M:\cI\to\mathbf{Mod}_R$ be a $\cI$-directed system of $R$-modules. There is a natural isomorphism $(\varinjlim_I M_i)\otimes_R N\cong \varinjlim_I (M_i\otimes_R N)$. It's very technical but it might be very useful. Maybe in the homework for example \emph{;-)}
\end{prop}
\begin{proof}
Consider $\Hom_R((\varinjlim_I M_i)\otimes_R N,L)\cong\Hom_R(\varinjlim_I M_i,\Hom_R(N,L))$. That's cool, because this is the same thing as $\Map_{\Fun(\cI,\mathbf{Mod}_R)}(\{M_i\},c_{\Hom_R(N,L)})$ because $\{M_i\}$ is a $\cI$-directed system. Now, this is the same as $\Map_{\Fun(\cI,\mathbf{Mod}_R)}(\{M_i\otimes_R N\},c_{L})$ by the Hom-tensor adjunction. We can unspool this to see that this is $\Hom_R(\varinjlim_\cI (M_i\otimes_R N),L)$. Now conclude via the Yoneda lemma (which we haven't discussed yet, but I think is a homework problem). Basically this states that $\Map_\cc(X,-)$ determines $X$.
\end{proof}
We'll talk a lot more about $\Hom$ and adjunctions, but not today.

Here's the question I want to talk about today. Suppose that I'm given $ H_\ast(X;\Z)$. Does it determine $ H_\ast(X;\Z/2\Z)$? Consider $\RP^2\to S^2$. In homology with coefficients in $\Z$, in dimension $2$, this map must induce $0$. But in $\Z/2\Z$-coefficients, in dimension $2$, this map gives an isomorphism. I could have considered reduced homology. This shows that there's not a functorial relationship between $ H_\ast(X;\Z)$ and $ H_\ast(X;\Z/2\Z)$. So how \emph{do} we go between different coefficients? That's the mystery.

Let $R$ be a commutative ring. Let $M$ be a $R$-module. I want to think about some chain complex $C_\bullet$ of $R$-modules. It could be the singular complex of a space, but it doesn't have to be. I'm going to forget to write $\otimes_R$ now; I'll just write $\otimes$. I can consider $ H_n(C_\bullet)\otimes M$, or $ H_n(C_\bullet\otimes M)$. The latter thing gives homology with coefficients in $M$. How can we compare these two? I claim that I can construct a map $\alpha: H_n(C_\bullet)\otimes M\to H_n(C_\bullet\otimes M)$. Recall the exact sequence $0\to B_n\to Z_n(C_\bullet)\to H_n\to 0$ that defines homology. So I get an exact seqeucen $B_n\otimes M\to Z_n(C_\bullet)\otimes M\to H_n(C_\bullet)\otimes M\to 0$. And there's a surjection $Z_n(C_\bullet)(C\otimes M)\to H_n(C_\bullet\otimes M)$. I have to tell you where $x\otimes m\in Z_n(C_\bullet)\otimes M$ goes. I'll send it to $x\otimes m\in Z_n(C_\bullet)(C_\bullet\otimes M)$. I claim that this is a cycle, because $d(x\otimes m)=(dx)\otimes m$. But $x\in\ker d$, so this is zero, and thus $x\otimes m\in Z_n(C_\bullet)(C_\bullet\otimes M)$. Does it descend to a map in homology? We want to check that $B_n\otimes M\to Z_n(C_\bullet)(C_\bullet\otimes M)$ is zero. Suppose $y\in C_{n+1}$. Then $dy\in C_n$. Where does $dy\otimes x$ go? Send it to $d(y\otimes x)\in B_n(C_\bullet\otimes M)$. And this maps to zero.

The problem is that $\alpha$ is not always an isomorphism. But it is if $M$ is free, say $M=R\langle S\rangle$. That's because then $C_\bullet\otimes M\cong\bigoplus_S C_\bullet$. Now there's a little lemma that nobody tells you about, because it's obvious, but here it is anyway:
\begin{lemma}
Suppose I have a collection of exact sequences of $R$-modules $A_i\to B_i\to C_i$. Then $\bigoplus A_i\to \bigoplus B_i\to \bigoplus C_i$ is short exact, i.e., $\bigoplus$ is an exact functor.
\end{lemma}
\begin{proof}
The composition is obviously zero. If $(b_i)\in\bigoplus B_i$ maps to $0$, then by exactness, there are $a_i$ that map to $b_i$, and we assume that if some $b_i=0$, then $a_i=0$.
\end{proof}
This in particular implies that $ H(\bigoplus C_i)\cong\bigoplus H(C_i)$.

Consider a free resolution of $M$. Assume $R$ is a PID, so that $M$ has a free resolution of the form $0\to F_1\to F_0\to M\to 0$. Thus we get a chain complex $C_\bullet\otimes F_1\to C_\bullet\otimes F_0\to C_\bullet M\to 0$. Now I get a lexseq in $\Tor$, namely $\cdots\to\Tor^R_1(C_\bullet,M)\to C_\bullet\otimes F_1\to C_\bullet\otimes F_0\to C_\bullet M\to 0$.

Now I'm going to make a second assumption. Suppose $C_n$ is a free $R$-module for all $n$. At least that $\Tor^R_1(C_n,M)=0$. This shouldn't bother you at all, because the chain complexes that we need satisfy this condition. In particular, we have a sexseq $0\to C_\bullet\otimes F_1\to C_\bullet\otimes F_0\to C_\bullet M\to 0$. What happens then? We get a lexseq. I want to give an unspliced form of this (huge diagram coming up!).
\begin{equation*}
\xymatrix{0\ar[d]\ar@{=}[r] & 0\ar[d]\\
\coker( H_n(C_\bullet\otimes F_1)\to H_n(C_\bullet\otimes F_0))\ar[d]\ar@{=}[r] & H_n(C_\bullet)\otimes M\ar[d]^\alpha\\
 H_n(C_\bullet\otimes M)\ar[d]^\partial\ar@{=}[r] & H_n(C_\bullet\otimes M)\ar[d]^\partial\\
\ker( H_{n-1}(C_\bullet\otimes F_1)\to H_{n-1}(C_\bullet\otimes F_0))\ar@{=}[r]\ar[d] & \Tor^R_{1}( H_{n-1}(C_\bullet),M)\ar[d]\\
0\ar@{=}[r] & 0}
\end{equation*}
Because $\ker( H_{n-1}(C_\bullet\otimes F_1)\to H_{n-1}(C_\bullet\otimes F_0))=\ker( H_{n-1}(C_\bullet)\otimes F_1\to H_{n-1}(C_\bullet)\otimes F_0)$ and $\coker( H_n(C_\bullet)\otimes F_1\to H_n(C_\bullet)\otimes F_0)$. Also, $\ker( H_{n-1}(C_\bullet\otimes F_1)\to H_{n-1}(C_\bullet\otimes F_0))=\Tor^R_{1}( H_{n-1}(C_\bullet),M)$ because of the lexseq $0\to \Tor^R_1( H_{n-1}(C_\bullet),M)\to H_{n-1}(C_\bullet)\otimes F_1\to H_{n-1}(C_\bullet)\otimes F_0\to H_{n-1}(C_\bullet)\otimes M\to 0$.

Thus we have a sexseq, which gives the universal coefficient theorem:
\begin{theorem}[Universal Coefficient Theorem]
If $R$ is a PID and $C_n$ is free for all $n$, then there is a natural sexseq of $R$-modules:
\begin{equation*}
0\to H_n(C_\bullet)\otimes M\xrightarrow{\alpha} H_n(C_\bullet\otimes M)\xrightarrow{\partial}\Tor^R_1( H_{n-1}(C_\bullet),M)\to 0
\end{equation*}
A further fact that we won't prove is that this splits as a sexseq of $R$-modules, but not naturally.
\end{theorem}
\begin{example}
Consider $ H_2(\RP^2;\Z/2\Z)\cong\Z/2\Z$, and we can consider $ H_2(\RP^2;\Z)\otimes\Z/2\Z=0$. So by the UCT, this must come from $\Tor^\Z_1( H_1(\RP^2;\Z),\Z/2\Z)\cong\Z/2\Z$. So $\partial$ is an isomorphism. This explains the mystery that we began with.
\end{example}
\begin{remark}
Suppose $R$ is not a PID. For example, consider what we worked with before, e.g., $R=k[e]/(e^2)$, and let $M=k$ (so $e$ acts as $0$). Consider the chain complex $C_\bullet:\cdots\to R\xrightarrow{e}R\xrightarrow{e} R\xrightarrow{e}R\to 0$. This is actually the free resolution of $k$ that we found before. In particular, $ H_n(C_\bullet)=\begin{cases}k & n=0 \\ 0 & n\neq 0\end{cases}$. What is $C_\bullet\otimes_R k$? It's exactly $\cdots\to k\xrightarrow{0}k\xrightarrow{0} k\xrightarrow{0}k\to 0$. So $ H_n(C_\bullet\otimes_R k)=\begin{cases}k & n>0 \\ 0 & n<0\end{cases}=\Tor^R_n(k,k)$. The two homologies are super different. The excess $\Tor$'s are accounted for via spectral sequences, which you'll see when you take 18.906.
\end{remark}
The next step is to consider the homology of products.
%\newpage
\section{K\"{u}nneth and Eilenberg-Zilber}
We want to compute the homology of a product. Long ago, we constructed a bilinear map $S_p(X)\times S_q(Y)\to S_{p+q}(X\times Y)$, called the cross product. So we get a linear map $S_p(X)\otimes S_q(Y)\to S_{p+q}(X\times Y)$, and it satisfies the Leibniz formula, i.e., $d(x\times y)=dx\times y+(-1)^px\times dy$. The method we used was really another example of the fundamental theorem of homological algebra.
\begin{definition}
Let $C_\bullet,D_\bullet$ be chain complexes that are bounded below (i.e., $C_i=0$ and $D_i=0$ for $i\ll 0$; we'll be looking at the case where they're zero if $i<0$). Define $(C_\bullet\otimes D_\bullet)_n=\bigoplus_{p+q=n}C_p\otimes D_q$. The boundedness says that it's a finite sum. The differential $(C_\bullet\otimes D_\bullet)_n\to (C_\bullet\otimes D_\bullet)_{n-1}$ sends $C_p\otimes D_q\to C_{p-1}\otimes D_q\bigoplus C_p\otimes D_{q-1}$ given by $x\otimes y\mapsto dx\otimes y+(-1)^p x\otimes dy$.
\end{definition}
So the cross product is a map of chain complexes $S_\ast(X)\otimes S_\ast(Y)\to S_\ast(X\times Y)$. The K\"{u}nneth theorem in dimension zero is really easy, because $\pi_0(X)\times \pi_0(Y)=\pi_0(X\times Y)$.
\subsection{Acyclic models}
Let $\cc$ be a category, and let $F:\cc\to\mathbf{Ab}$ be a functor. Fix a set of object in $\cc$, and let $\MM$ be the ``models''. If $\cc=\mathbf{Top}\times\mathbf{Top}$, then $\MM$ is the set of pairs of simplices.
\begin{definition}
We say that $F$ is $\MM$-free if it is a direct sum of the free abelian group of the corepresentable functors, i.e., $F$ is a direct sum of $\Z\Hom_\cc(M,-)$ where $M\in\MM$.
\end{definition}
\begin{example}
For example, $S_n(X\times Y)=\Z\Hom_\mathbf{Top}(\Delta^n\times Y)=\Z\Hom_{\mathbf{Top}\times\mathbf{Top}}((\Delta^n,\Delta^n),(X,Y))$. Another example is that $\bigoplus_{p+q=n}S_p(X)\otimes S_q(Y)=\bigoplus\Z\Hom_{\mathbf{Top}}(\Delta^p,X)\otimes\Z\Hom_{\mathbf{Top}}(\Delta^q,Y)=\bigoplus_{p+q=n}\Z\langle\Hom_{\mathbf{Top}}(\Delta^p,X)\times\Hom_{\mathbf{Top}}(\Delta^q,Y)\rangle=\bigoplus_{p+q=n}\Z\Hom_{\mathbf{Top}\times\mathbf{Top}}((\Delta^p,\Delta^q),(X,Y))$.
\end{example}
\begin{definition}
A natural transformation of functors $\theta:F\to G$ is a $\MM$-epimorphism if $\theta_M:F(M)\to G(M)$ is a surjection of abelian groups for every $M\in\MM$. Consider a composition of natural transformations of functors $G^\prime\to G\to G^{\prime\prime}$ that is zero. Let $K$ be the objectwise kernel of $G\to G^{\prime\prime}$. So there's a factorization $G^\prime\to K$. Say that the sequence is $\MM$-exact if $G^\prime\to K$ is a $\MM$-epi.

This means that $G^\prime(M)\to G(M)\to G^{\prime\prime}(M)$ is exact for all $M\in\MM$.
\end{definition}
\begin{example}
We claim that $S_n(X\times Y)\to S_{n-1}(X\times Y)\to\cdots\to S_0(X\times Y)\to H_0(X\times Y)\to 0$ is $\MM$-exact, because when I plug in $(\Delta^p,\Delta^q)$, I get an exact sequence (it's contractible so all homology groups vanish).
\end{example}
\begin{example}
Consider the sequence $\cdots\to(S_\ast(X)\otimes S_\ast(Y))_1\to S_0(X)\otimes S_0(Y)\to H_0(X)\otimes H_0(Y)\to 0$. Is this $\MM$-exact? We don't know that yet, although it's true in each factor if you plug in a simplex. It turns out that it actually \emph{is} $\MM$-exact, but I'll come back to this in a few minutes.
\end{example}
I've been checking things for our chain complexes that'll come up in the K\"{u}nneth theorem. Here's the key lemma that makes it all work.
\begin{lemma}
Let $\cc$ be a category with a set of models $\MM$ and let $F,G,G^\prime:\cc\to\mathbf{Ab}$ be functors. Let $F$ be $\MM$-free, and let $G^\prime\to G$ be a $\MM$-epimorphism. Then there's a lifting:
\begin{equation*}
\xymatrix{ & G^\prime\ar[d]\\
F\ar@{-->}[ur]\ar[r]^f & G}
\end{equation*}
\end{lemma}
\begin{proof}
Clearly we may assume that $F(X)=\Z\Hom_\cc(M,X)$. Suppose $X=M$. We get:
\begin{equation*}
\xymatrix{ & G^\prime(M)\ar@{->>}[d]\\
\Z\Hom_\cc(M,M)\ar@{-->}[ur]^{\overline{f}_M}\ar[r]|{f_M} & G(M)}
\end{equation*}
Consider $1_M\in\Z\Hom_\cc(M,M)$. This maps to $f_M(1_M)$. But because $G^\prime\to G$ is a $\MM$-epi, there is some $c_M$ that maps to $f_M(1_M)$. This is going to be $\overline{f}_M(1_M)$, i.e., $\overline{f}_M(1_M):=c_M$.

Now we're done by naturality! Because given any $\varphi:M\to X$, we get a commutative diagram:
\begin{equation*}
\xymatrix{\cc(M,X)\ar[r]^{\overline{f}_X}\ar[d] & G^\prime(X)\ar[d]\\
\cc(M,M)\ar[r]_{\overline{f}_M} & G^\prime(M)}
\end{equation*}
Now, $1_M\mapsto\varphi$, and so $\overline{f}_X(\varphi)=\varphi_\ast(c_M)$ by commutativity. Now extend linearly.
\end{proof}
We already knew the following result, but now we can make this formal:
\begin{theorem}[Eilenberg-Zilber theorem]
There exists a natural chain map:
\begin{equation*}
\xymatrix{S_\ast(X)\otimes S_\ast(Y)\ar[r]^{\times}\ar[d] & S_\ast(X\times Y)\ar[d]\\
 H_0(X)\otimes H_0(Y)\ar[r]^{\cong} & H_0(X\times Y)}
\end{equation*}
That is unique up to natural chain homotopy (this is part we didn't show before). There's also a map $\alpha:S_\ast(X\times Y)\to S_\ast(X)\otimes S_\ast(Y)$ because $ H_0(X)\otimes H_0(Y)\to H_0(X\times Y)$ is an isomorphism. These two maps $\alpha$ and $\times$ are naturally chain homotopy inverses.
\end{theorem}
\begin{corollary}
There is an isomorphism $ H(S_\ast(X)\otimes S_\ast(Y))\cong H_\ast(X\times Y)$.
\end{corollary}
We will show the following:
\begin{theorem}
Let $C_\bullet,D_\bullet$ be chain complexes, bounded below, where $C_n$ is a free $R$-module for all $n$. Then we have a generalization of the universal coefficient theorem. There is a sexseq:
\begin{equation*}
\xymatrix{0\ar[r] & \bigoplus_{p+q=n} H_p(C)\otimes H_q(D)\ar@{=}[r] & ( H_\ast(C)\otimes H_\ast(D))_n\ar[dll]\\
 H_n(C_\bullet\otimes D_\bullet)\ar[r] & \bigoplus_{p+q=n-1}\Tor^R_1( H_p(C), H_q(D))\ar[r] & 0}
\end{equation*}
This is true over any PID, too.
\end{theorem}
\begin{proof}
This is exactly the same as the proof for the UCT. It's a good idea to work through this on your own.
\end{proof}
So, by combining this theorem and previous corollary, we get:
\begin{theorem}[K\"{u}nneth theorem]
If $R$ is a PID, there is a natural sexseq (that splits, but not naturally):
\begin{equation*}
\xymatrix{0\ar[r] & \bigoplus_{p+q=n} H_p(X)\otimes H_q(Y)\ar@{=}[r] & ( H_\ast(X)\otimes H_\ast(X))_n\ar[dll]\\
 H_n(X\times Y)\ar[r] & \bigoplus_{p+q=n-1}\Tor^R_1( H_p(X), H_q(Y))\ar[r] & 0}
\end{equation*}
\end{theorem}
\begin{example}
If $R=k$ is a field, every module is already free, so the $\Tor$ term vanishes, and you get a K\"{u}nneth isomorphism:
\begin{equation*}
 H_\ast(X;k)\otimes_k H_\ast(Y;k)\cong H_\ast(X\times Y;k)
\end{equation*}
\end{example}
This is rather spectacular. For example, what is $ H_\ast(\RP^2\times\RP^3;\Z/2\Z)$? Well, directly, we see that there is $1$ cell in dimensions $0$ and $5$, $2$ cells in dimensions $1$ and $4$, $3$ cells in dimensions $2$ and $3$. Note the symmetry. This isn't an accident, it's Poincar\'{e} duality, which we'll get to soon. By K\"{u}nneth, it's $ H_\ast(\RP^2;\Z/2\Z)\otimes_{\Z/2\Z} H_\ast(\RP^3)$, i.e.:
\begin{equation*}
 H_n(\RP^2\times\RP^3;\Z/2\Z)=\bigoplus_{p+q=n} H_p(\RP^2;\Z/2\Z)\otimes H_q(\RP^3;\Z/2\Z)=\begin{cases}
\text{work it out yourself}
\end{cases}
\end{equation*}
%\newpage
\section{A few more things about coefficients, cohomology}
Problem Set 5 now due Friday! Recall our example where we let $\cI=(\Z_{>0},|)$. You can consider $\cI\to\mathbf{Ab}$, say assigning to each $i$ the integers $\Z$, and $f_{ij}:\Z\xrightarrow{j/i}\Z$. The colimit is $\QQ$, where you send $X_n\to\QQ$ via $1\mapsto \frac{1}{n}$. It's rather natural. But it's not the simplest way to define $\QQ$. You just could have defined $\QQ=\varinjlim(\Z\xrightarrow{2}\Z\xrightarrow{3}\Z\xrightarrow{4}\Z\to\cdots)$.

We saw that $\varinjlim$ is exact, that it commutes with tensor products, and that homology commutes with direct limits. So if I had a chain complex $C_\bullet$ of abelian groups, then the process of computing homology involves exact sequences. If I want to compute:
\begin{equation*}
 H(C_\bullet\otimes\QQ)= H(C_\bullet\otimes\varinjlim \Z)= H(\varinjlim(C_\bullet\otimes\Z))= H(\varinjlim C_\bullet)=\varinjlim H(C_\bullet)= H(C_\bullet)\otimes\varinjlim \Z= H(C_\bullet)\otimes\QQ
\end{equation*}
Thus $-\otimes\QQ$ is exact, i.e., $\QQ$ is \emph{flat} over $\Z$, so $\Tor^\ZZ_1(M,\QQ)=0$. By UCT, this means that $ H_\ast(X)\otimes \QQ\simeq H_\ast(X;\QQ)$.
\begin{definition}
The $n$th Betti number of $X$ is defined to be $\beta_n:=\dim_\QQ H_n(X;\QQ)$.
\end{definition}
The Euler characteristic can just as well have been defined as $\chi(X)=\sum^\infty_{n=0}(-1)^n\beta_n$.

Oh, let me ask if 11 am works for those of you who are going to take 18.906. OK? It seems like it's too early.

Anyway, every space has a diagonal map $X\xrightarrow{\Delta}X\times X$. This induces a map $ H_\ast(X;R)\to H_\ast(X\times X;R)$, where $R$ is a PID. But now, we have a K\"{u}nneth map $\alpha: H_\ast(X;R)\otimes_R H_\ast(X;R)\to H_\ast(X\times X;R)$. We can get some kind of comultiplication if $\alpha$ is an isomorphism. And, well, the K\"{u}nneth theorem says that $\Tor^R_1( H_\ast(X;R), H_\ast(X;R))=0$ if and only if $\alpha$ is an isomorphism. This condition is satisfied, for example, if each $ H_n(X;R)$ is flat over $R$ for all $n$ (for example, free over $R$). A special case is when $R$ is a field. So you get a comultiplication $\Delta: H_\ast(X;R)\to H_\ast(X;R)\otimes_R H_\ast(X;R)$ if this condition is satisfied.

This diagonal map has many properties.
\begin{definition}
Let $R$ be a ring. A (graded, bounded below) coalgebra over $R$ is a (graded) $R$-module $M$ with a multiplication $\Delta:M\to M\otimes_R M$ and an augmentation map $\varepsilon:M\to R$ such that all of the following diagrams commute:
\begin{equation*}
\xymatrix{ & M\ar[d]\ar[dr]\ar[dl] & \\
R\otimes_R M & M\otimes_R M\ar[l]^{\varepsilon\otimes 1}\ar[r]^{1\otimes\varepsilon} & M\otimes_R R}
\end{equation*}
Where the diagonal maps are the canonical isomorphisms. And you have coassociativity:
\begin{equation*}
\xymatrix{
	M\ar[r]^{\Delta}\ar[d]^{\Delta} & M\otimes_R M\ar[d]^{\Delta\otimes 1}\\
	M\otimes_R M\ar[r]_{1\otimes\Delta} & M\otimes_R M\otimes_R M
}
\end{equation*}
And it's cocommutative (he'll just say commutative because there's no need to say ``co'' if we know we're working with coalgebras, but I want to write it anyway -- I'll probably abuse it though) if:
\begin{equation*}
\xymatrix{
	 & M\ar[dl]^\Delta\ar[dr]^\Delta &\\
	M\otimes_R M\ar[rr]^{\tau} & & M\otimes_R M
}
\end{equation*}
Where $\tau(x\otimes y)=(-1)^{|x|\cdot|y|}y\otimes x$ is the twisting map.
\end{definition}
\begin{example}
The K\"{u}nneth map is coassociative and cocommutative.
\end{example}
Consider:
\begin{equation*}
\xymatrix{S_\ast(X)\otimes S_\ast(Y)\ar[r]^{\tau}\ar[d]^{\times} & S_\ast(Y)\otimes S_\ast(X)\ar[d]^{\times}\\
S_\ast(X\times Y)\ar[r]^{\tau_\ast} & S_\ast(Y\times X)}
\end{equation*}
Where $\tau$ is as defined above on the tensor product and $\tau$ is also used to denote the twisting map $X\times Y\to Y\times X$. And this diagram commutes up to chain homotopy.
\begin{corollary}
Let $k$ be a field. Then $ H_\ast(X;k)$ has the natural structure of a cocommutative graded coalgebraic structure. 
\end{corollary}
I could just talk about coalgebras. But one of my friends told me that nobody in France knew what coalgebras were. So we're going to talk about cohomology, and get an algebra structure. Some say that cohomology is better because you have algebras, but that's more of a sociological statement than a mathematical one.
\begin{slogan}
Cohomology gives algebras. It's a contravariant functor on spaces.
\end{slogan}
A better reason for looking a cohomology is that there are many geometric constructions that pull back. For example, if I have some covering space $\widetilde{X}\to X$, and I have a map $f:Y\to X$, I get a pullback covering space $f^{\ast}\widetilde{X}$. A better example is vector bundles (that we'll talk about in 18.906) -- they don't push out, they pullback. This'll give the theory of \emph{characteristic classes}. Another even better reason is that cohomology is the target of the Poincar\'{e} duality map.
\begin{definition}
Let $N$ be an abelian group. A singular $n$-cochain on $X$ with coefficients in $N$ is a function $\Sin_n(X)\to N$. 
\end{definition}
If $N$ is an $R$-module, then I can extend linearly to get a map $S_n(X;R)\to N$.
\begin{notation}
Write $S^n(X;N):=\Map(\Sin_n(X);N)=\Hom_R(S_n(X;R);N)$.
\end{notation}
This is going to give me something contravariant, that's for sure. But I want to get a cochain complex $(S^\ast(X;N),d)$. Cochain means that the differential increases the degree.

I have a map $(-,-):S^n(X;N)\otimes S_n(X;R)\to N$ given by evaluation. I want $d$ on $S^\ast(X;N)$ that makes the map $S^n(X;N)\otimes S_n(X;R)\to N$ is a chain map where we regard $N$ as a chain complex with zeros everywhere except in dimension $0$. But the way I've said it doesn't quite make sense because $S^\ast(X;N)$ isn't a chain complex! So let $S^\ast(X;N)$ be a chain complex with $S^n(X;N)$ in dimension $(-n)$. But now it's not bounded below. So, to be honest, I should say that we're going to make a decision. If $C_\bullet,D_\bullet$ aren't necessarily bounded below chain complex, then $(C_\bullet\otimes D_\bullet)_n:=\bigoplus_{i+j=n}C_i\otimes D_j$.

Let $f\in S^n(X;R)$ and $\sigma\in S_n(X;R)$. This is a chain map if $d (f,\sigma)=0$. And $d(f,\sigma)=(df,\sigma)+(-1)^{|f|}(f,d\sigma)$. Let me erase this. This doesn't make sense. Scratch that. Let's start over.

Let $f\in S^{n+1}(X;R)$ and $\sigma\in S_n(X;R)$. Then $(df,\sigma)+(-1)^{|f|}(f,d\sigma)=d(f,\sigma)=0$. So $(df)(\sigma)=(-1)^{|f|+1}f(d\sigma)$. That's what the differential is. This makes $S^\ast(X;N)$ a cochain complex. So you can consider its homology.
\begin{definition}
The $n$th cohomology of $X$ with coefficients in $N$ is $ H^n(X;N):= H^n(S^\ast(X;N))$. This is a contravariant functor on $\mathbf{Top}$.
\end{definition}
If you fix $X$, I get a covariant functor $ H^n(X;-)$ on $\mathbf{Mod}_R$.
\begin{construction}
I have a chain map $(,):S^\ast(X;N)\otimes_R S_\ast(X;R)\to N$. I can apply homology to this, to get $\alpha: H^\ast(X;N)\otimes_R H_\ast(X;R)\to H(S^\ast(X;N)\otimes_R S_\ast(X;R))$. In particular, you get a natural pairing $(,): H^\ast(X;N)\otimes_R H_\ast(X;R)\xrightarrow{\alpha} H(S^\ast(X;N)\otimes_R S_\ast(X;R))\xrightarrow{(,)}N$. This ``evaluation map'' is called the Kronecker pairing.
\end{construction}
\begin{warning}
$S^n(X;\Z)=\Map(\Sin_n(X);\Z)=\prod_{\Sin_n(X)}\Z$, which is probably an uncountable product. An awkward fact is that this is never free abelian.
\end{warning}
\begin{construction}
If $A\subseteq X$, there is a restriction map $S^n(X;N)\to S^n(A;N)$. There is an injection $\Sin_n(A)\hookrightarrow \Sin_n(X)$. And as long as $A$ is empty, I can split this. So any function $\Sin_n(A)\to N$ extends to $\Sin_n(X)\to N$. This means that $S^n(X;N)\to S^n(A;N)$ is surjective. You can define the kernel as $S^n(X,A;N)$, which sits in $0\to S^n(X,A;N)\to S^n(X;N)\to S^n(A;N)\to 0$. This gives the \emph{relative cochains}.
\end{construction}
I can take the homology of this sexseq to get a lexseq:
\begin{equation*}
\xymatrix{
	\cdots & & \\
	 H^1(X,A;N)\ar[r] & H^1(X;N)\ar[r] & H^1(A)\ar[ull]^{\delta}\\
	 H^0(X,A;N)\ar[r] & H^0(X;N)\ar[r] & H^0(A)\ar[ull]^{\delta}
}
\end{equation*}
And $ H^0(X;N)$ sits in the cokernel of $\Map(\Sin_0(X),N)\to \Map(\Sin_1(X),N)$, so that $ H^0(X;N)=\Map(\pi_0(X),N)$.
%\newpage
\section{Cohomology, Ext, cup product}
Let $R$ be a ring, probably a PID. It's often a field, but it could be $\Z$. Let $N$ be an $R$-module. Define $S^n(X;N)=\Map(\Sin_n(X),N)$. There's a boundary map $d:S^n(X;N)\to S^{n+1}(X;N)$ that takes a cochain $f$ to the map $df$ defined by $df(\sigma)=(-1)^{n+1}f(d\sigma)$ where $\sigma\in \Sin_{n+1}(X)$. Now, $d^2=0$, so $ H^n(X;N):= H^n(S^\ast(X;N))$. This is a contravariant functor from $\mathbf{Top}$ to $\mathbf{Ab}$ and it's covariant in the coefficients. 

When $n=0$, you have $0\to S^0(X;N)\xrightarrow{d} S^1(X;N)$. Thus $ H^0(X;N)=\ker d$. Well, $S^0(X;N)=\Map(X,N)$, and $d$ sends a $0$-cochain $f$ to $\sigma\mapsto\pm f(d\sigma)=\pm(f(\sigma(0))-f(\sigma(1)))$. So a function is in the kernel of $d$ if its values on the ends of any path is the same. Thus $ H^0(X;N)=\Map(\pi_0(X),N)$.

We also talked about the Kronecker pairing. This gave an evaluation $ H^n(X;N)\otimes_R H_n(X;R)\to N$. Taking the adjoint gives a map $ H^n(X;N)\xrightarrow{\beta}\Hom_R( H_n(X;R),N)$. We can try to understand cohomology in terms of homology. $\beta$'ll often be an isomorphism, but not always.
\begin{theorem}[UCT for cohomology]
There is a natural sexseq:
\begin{equation*}
0\to\Ext^1_R( H_{n-1}(X;R),N)\to H^n(X;N)\xrightarrow{\beta}\Hom_R( H_n(X;R),N)\to 0
\end{equation*}
that splits, but not naturally. This also holds for relative cohomology.
\end{theorem}
I will tell you what $\Ext$ means now. I will prove this on Friday.

The problem that arises is that $\Hom_R(-,N):\mathbf{Mod}_R\to\mathbf{Mod}_R$ is not exact. More precisely, it preserves right exact sequences, but not left exact sequences. Consider $M^\prime\xrightarrow{i} M\xrightarrow{p} M^{\prime\prime}\to 0$ an exact sequence of $R$-modules. This gives a sequence $0\to \Hom_R(M^{\prime\prime},N)\to\Hom_R(M,N)\to \Hom_R(M^{\prime},N)$. If I have $f:M^{\prime\prime}\to N$, and I compose with $p$ to get a zero map, then is $f$ zero? Well, yes, because $p$ is surjective. Now suppose I have $g:M\to N$, such that $i\circ g=0$. So it facts through the cokernel, and you get a unique factorization $M^{\prime\prime}\to N$ (unique because $M\to M^{\prime\prime}$ is surjective).

Suppose I have an injection $0\to M^\prime\to M$. Is $\Hom(M,N)\to\Hom(M^\prime,N)$ surjective? If I have some map $M^\prime\to N$ and $M^\prime\hookrightarrow N$, then does this extend to a map $M\to N$? No! For example, if you have $1:\Z/2\Z\to\Z/2\Z$ and $\Z/2\Z\hookrightarrow\Z/4\Z$, then you can't lift to a map $\Z/4\Z\to\Z/2\Z$. This works, though, if the sexseq splits.

Homological algebra now comes to the rescue! Pick a free resolution of $M$ given by $\cdots\to F_2\to F_1\to M\to F_0\to 0$. If I apply $\Hom$, I get a chain complex $0\to \Hom(F_0,N)\to \Hom(F_1,N)\to \Hom(F_2,N)\to\cdots$.
\begin{definition}
Define $\Ext_R^n(M,N)= H^n(\Hom_R(F_\bullet,N))$ as the $n$-dimensional homology of this chain complex.
\end{definition}
\begin{remark}
If $R$ is a PID, then $\Ext^n=0$ if $n>1$. If $R$ is a field, then $\Ext^n=0$ for $n>0$. Also, $\Ext$ is well-defined and functorial (by the fundamental theorem of homological algebra). Another important point is that $\Hom_R(-,N)$ takes chain homotopies to chain homotopies. This is a pretty important thing, and is something to think about for a minute. This is because if I have $M^\prime\to M$, I get an induced map $\Hom_R(M^\prime,N)\leftarrow\Hom_R(M,N)$, and this is actualy an $R$-module map, and in particular, additive. And this means that the $dh-hd=f_1-f_0$ is preserved. Lastly, if $M$ is free or projective, then $\Ext^n(M,-)=0$ for $n>0$. In addition, $\Ext^0(M,N)=\Hom_R(M,N)$.
\end{remark}
Recall the trick that if I have a sexseq $0\to A\to B\to C\to 0$, and I have free resolutions $F^\prime_\bullet\to A$ and $F^{\prime\prime}_\bullet\to 0$, I can get a free resolution $F_\bullet\to B$ to get a sexseq $0\to F^\prime_\bullet\to F_\bullet\to F^{\prime\prime}_\bullet\to 0$. I can now apply $\Hom_R(-,N)$ to get a sexseq of cochain complexes, because this sequence splits in any given degree. Thus, I get a lexseq:
\begin{equation*}
\xymatrix{ & & 0\ar[dll]\\
\Hom_R(M^{\prime\prime},N)\ar[r] & \Hom_R(M,N)\ar[r] & \Hom_R(M^{\prime},N)\ar[dll]\\
\Ext^1_R(M^{\prime\prime},N)\ar[r] & \Ext^1_R(M,N)\ar[r] & \Ext^1_R(M^{\prime},N)\ar[dll]\\
\cdots & &}
\end{equation*}
In this sense, $\Ext$ is like a cohomology theory for $R$-modules.

Let us use this to make a calculation.
\begin{example}
Let $R=\Z$, and look at the sexseq $0\to \Z\xrightarrow{k}\Z\to\Z/k\Z\to 0$. Here $N$ is some abelian group. So, our lexseq will look like:
\begin{equation*}
\xymatrix{ & & 0\ar[dll]\\
\Hom_R(\Z/k\Z,N)\ar[r] & \Hom_R(\Z,N)=N\ar[r] & \Hom_R(\Z,N)=N\ar[dll]\\
\Ext^1_R(\Z/k\Z,N)\ar[r] & 0\ar[r] & 0\ar[dll]\\
\cdots & &}
\end{equation*}
The map $N\to N$ in this lexseq is multiplication by $k$. Thus $\Hom(\Z/k\Z,N)=\ker(N\xrightarrow{k}N)$. And, well, $\Ext^1_\Z(\Z/k\Z,N)=N/kN$.
\end{example}
Let's get some consequences of cohomology from the UCT. Even independent of that, we get some properties.
\subsection{Properties of cohomology}
\begin{enumerate}
\item It's homotopy invariant. This means that if $f_0\sim f_1:(X,A)\to (Y,B)$, then $ H^\ast(X,A;N)\xleftarrow{f_0^\ast,f_1^\ast} H^\ast(Y,B;N)$ are equal. I can't use the UCT to address this because the UCT only tells you that things are isomorphic (use the 5-lemma). But we did establish a chain homotopy $f_{0,\ast}\sim f_{1,\ast}:S_\ast(X,A)\to S_\ast(Y,B)$, and applying $\Hom$ still retains this chain homotopy, and hence you get the same map on cohomology.
\item Excision. If $U\subseteq A\subseteq X$ such that $\overline{U}\subseteq\mathrm{Int}(A)$, then $ H^\ast(X,A;N)\leftarrow H^\ast(X-U,A-U;N)$ is an isomorphism. This follows from the UCT (in the relative form, which is also true).
\item Mayer-Vietoris sequence. If I have $A,B\subseteq X$ such that their interiors cover $X$, then I have an lexseq:
\begin{equation*}
\xymatrix{ & & \cdots\ar[dll]\\
 H^n(X;N)\ar[r] & H^n(A;N)\oplus H^n(B;N)\ar[r] & H^n(A\cap B;N)\ar[dll]\\
 H^{n+1}(X;N)\ar[r] & \cdots & }
\end{equation*}
\end{enumerate}
%\newpage
\section{Universal coefficient theorem, and products in $ H^\ast$}
We talked about cohomology $ H^\ast(X,A;N)$, which was contravariant in $(X,A)$. We can repeat some of the arguments for homology in the cohomological context. We can also relate cohomology to homology. This is the purpose of the universal coefficient theorem for cohomology. I won't actually prove this here, because I've put up notes on the website that covers this.
\begin{theorem}[Mixed variance UCT]
Let $R$ be a PID, let $N$ be a $R$-module, and let $C_\bullet$ be a chain complex of free $R$-modules. We've decided that $\Hom_R(C_\bullet,N)$ is a cochain complex. I'm always a little confused on how to write the homology of a cochain complex? Should I write $ H^n$ or $ H_n$? Maybe this is a personal problem, and I should keep it personal? We'll just write $ H^n$. (Some ridiculous notation with the $n$ sitting on the line in $H$ was suggested, but this'd be \emph{impossible} to TeX!)

Anyway, we had a map $ H^n\Hom_R(C_\bullet,N)\to\Hom_R( H_n(C_\bullet),N)$. The theorem is that this is surjective, which has kernel $\Ext^1_R( H_{n-1}(C_\bullet),N)$. I.e, there is a natural sexseq:
\begin{equation*}
0\to\Ext^1_R( H_{n-1}(C_\bullet),N)\to H^n\Hom_R(C_\bullet,N)\to\Hom_R( H_n(C_\bullet),N)\to 0
\end{equation*}
that splits, but not naturally.
\end{theorem}
\begin{proof}[Strategy of the proof]
I have a sexseq $0\to Z_n(C_\bullet)\to C_n\to C_n/Z_n(C_\bullet)\to 0$ where $Z_n(C_\bullet)=\ker d_n$ (where $C_\bullet$ is a chain complex). But $C_n/Z_n(C_\bullet)=B_{n-1}\hookrightarrow C_{n-1}$ where $B_n(C_\bullet)=\img d_{n-1}$ (this last thing probably has wrong indexing). We assumed $C_{n-1}$ is a free $R$-module, and that $R$ is a PID, so that $B_{n-1}$ is also free. Thus the sexseq $0\to Z_n(C_\bullet)\to C_n\to B_{n-1}\to 0$ splits.

Another sexseq that's important is $0\to Z_n(C_\bullet)/B_n(C_\bullet)\to C_n/B_n(C_\bullet)\to C_n/Z_n(C_\bullet)\to 0$. If you like, you can think of this as follows:
\begin{equation*}
\xymatrix{
	& 0 & 0 & 0 & \\
	0\ar[r] & Z_n(C_\bullet)/B_n(C_\bullet)\ar[r]\ar[u] & C_n/B_n(C_\bullet)\ar[r]\ar[u] & C_n/Z_n(C_\bullet)\ar[r]\ar[u] & 0\\
	0\ar[r] & Z_n(C_\bullet)\ar[r]\ar[u] & C_n\ar[r]\ar[u] & C_n/Z_n(C_\bullet)\ar[r]\ar[u] & 0\\
	0\ar[r] & B_n(C_\bullet)\ar[r]\ar[u] & B_n(C_\bullet)\ar[r]\ar[u] & 0\ar[r]\ar[u] & 0\\
	& 0\ar[u] & 0\ar[u] & 0\ar[u] &
}
\end{equation*}
Thus $0\to Z_n(C_\bullet)/B_n(C_\bullet)\to C_n/B_n(C_\bullet)\to C_n/Z_n(C_\bullet)\to 0$ splits. But $Z_n(C_\bullet)/B_n(C_\bullet)= H_{n-1}$, so this gives: $0\to H_{n-1}\to C_n/B_n(C_\bullet)\to B_{n-1}\to 0$.

Now, we have a sexseq $0\to B^n\Hom_R(C_\bullet,N)\to Z^n\Hom_R(C_\bullet,N)\to H^n\Hom_R(C_\bullet,N)\to 0$. We want to compare this to $\Hom_R( H_n(C_\bullet),N)$. But, now, $0\to H_{n-1}\to C_n/B_n(C_\bullet)\to B_{n-1}\to 0$ splits, so we get a sexseq $0\to \Hom(B_{n-1},N)\to \Hom(C_n/B_n(C_\bullet),N)\to\Hom( H_{n-1}(C_\bullet),N)\to 0$. Let me write this out:
\begin{equation*}
\xymatrix{
	0\ar[r] & B^n\Hom_R(C_\bullet,N) \ar[r]\ar@{-->}[d] & Z^n\Hom_R(C_\bullet,N) \ar[r]\ar@{-->}[d] & H^n\Hom_R(C_\bullet,N) \ar[r]\ar[d] & 0\\
	0 \ar[r] & \Hom(B_{n-1},N) \ar[r] & \Hom(C_n/B_n(C_\bullet),N)\ar[r] & \Hom( H_{n-1}(C_\bullet),N) \ar[r] & 0
}
\end{equation*}
An element of $Z^n\Hom_R(C_\bullet,N)$ is a map $f:C_n\to N$ such that $f\circ d=0$. So this map $f$ factors as $C_n/B_n(C_\bullet)\to N$. Thus we have the middle dotted map, and it's actually an isomorphism. You can then check compatibility, to get the left dotted map.

Is the map $ H^n\Hom_R(C_\bullet,N)\to\Hom( H_{n-1}(C_\bullet),N)$ surjective? Well, use the snake lemma. I can then use diagram chasing to see that the map is indeed surjective, with kernel given by the kernel of $B^n\Hom_R(C_\bullet,N)\to \Hom(B_{n-1},N)$. And the rest of the proof amounts to showing that this kernel is $\Ext^1_R( H_{n-1}(C_\bullet),N)$. And for splitting we can construct a splitting map, see the notes.
\end{proof}
\begin{remark}
Miguel: Why is $\Ext$ called Ext?

Miller: It deals with extensions. Let $R$ be a commutative ring, and let $M,N$ be two $R$-modules. I can think about extensions $0\to N\to L\to M\to 0$. Well, for example, I have two extensions $0\to\Z/2\Z\to\Z/2\Z\oplus\Z/2\Z\to\Z/2\Z\to 0$, and $0\to \Z/2\Z\to\Z/4\Z\to\Z/2\Z\to 0$. Say that two extensions are equivalent if there's a map of sexseqs between them is the identity on $N$ and $M$. The two extensions above aren't equivalent, for example.

Another definition of $\Ext^1_R(M,N)$ is the set of extensions like this modulo this notion of equivalence. The zero in the group is the split extension.

Also, $\Ext$ is contravariant in the first variable, but not in the second variable. If you want to find the Ext groups, you can use an injective resolution of the second variable, or a projective resolution of the first variable. These are what are known as derived functors. $\Tor$ is a left derived functor because it uses a projective resolution that goes off to the left, but $\Ext$ is a right derived functor because it uses an injective resolution that goes off to the right.
\end{remark}
\subsection{Products}
We'll talk about the cohomology cross product.
\begin{construction}
Define $S^p(X)\otimes S^q(Y)\xrightarrow{\times}S^{p+q}(X\times Y)$ as follows. Let $\sigma$ be a $(p+q)$-simplex in $X\times Y$. Let $f\otimes g\in S^p(X)\otimes S^q(Y)$. We'll define $f\times g\in S^{p+q}(X\times Y)$. Then $f:S_p(X)\to R$ and $g:S_q(Y)\to R$. I can write $\sigma=\begin{pmatrix}\sigma_1 \\ \sigma_2\end{pmatrix}$ where $\sigma_1:\Delta^{p+q}\to X$ and $\sigma_2:\Delta^{p+q}\to Y$. Define:
\begin{equation*}
(f\times g)(\sigma)=f(\sigma_1\circ\alpha_p)g(\sigma_2\circ\omega_q)
\end{equation*}
where $\alpha_p:\Delta^p\to\Delta^{p+q}$ takes $k\mapsto k$ where $k\in[p]$. And $\omega_q:\Delta^q\to\Delta^{p+q}$ sends $\ell\mapsto \ell+p$ where $\ell\in[q]$. It is an extremely (idiotic I think was the word used) construction that I have never gotten used to.
\begin{remark}
It is \emph{incredibly} stupid.
\end{remark}
We get a map on cochains. We need to check that this is a chain map $S^\ast(X)\otimes S^\ast(Y)\to S^\ast(X\times Y)$. This is your homework! What this means is that you get a map $ H^\ast(S^\ast(X)\otimes S^\ast(Y))\to H^\ast(X\times Y)$. I guess I have coefficients in $R$. I'm not quite done, but I have a map $ H^\ast(X)\otimes H^\ast(Y)\to H^\ast(S^\ast(X)\otimes S^\ast(Y))$. The composition $ H^\ast(X)\otimes H^\ast(Y)\to H^\ast(S^\ast(X)\otimes S^\ast(Y))\to H^\ast(X\times Y)$ is the cross product.
\end{construction}
It's not very easy to do computations with this. It's just hard to deal with. Let me make some points about this construction, though.
\begin{definition}
Now take $X=Y$. Then I get $ H^p(X)\otimes H^q(X)\xrightarrow{\times} H^{p+q}(X\times X)\xrightarrow{\Delta^\ast} H^{p+q}(X)$ where $\Delta:X\to X\times X$ is the diagonal. This composition is called the cup product. Some people write $\smile$, and others write $\cup$. (I'll TeX it as $\cup$.)
\end{definition}
Some properties of the cup product are the following. I claim that $ H^0(X)\cong\Map(\pi_0(X),R)$ as rings. This $\alpha$ and $\omega$ stuff collapses if $p=q=0$. There's nothing to do ... they're both the identity maps. So this isomorphism is clear. Also, inside $ H^0(X)$, we pick the element that maps to $(c\mapsto 1)\in\Map(\pi_0(X),R)$. This is the identity for the cup product. This comes out because when $p=0$ in our above story, then $\alpha_0$ is just including the $0$-simplex, and $\omega$ is the identity, so this is completely clear from that description.
\begin{prop}
If $f\in S^p(X)$ and $g\in S^q(Y)$ and $h\in S^r(Z)$, then $((f\times g)\times h)(\sigma)=(f\times(g\times h))(\sigma)$ where $\sigma:\Delta^{p+q+r}\to X\times Y\times Z$.
\end{prop}
\begin{proof}
Well, $((f\times g)\times h)(\sigma)=(f\times g)(\sigma_{12}\circ\alpha_{p+q})h(\sigma_3\circ\omega_r)$ where $\sigma_{12}:\Delta^{p+q+r}\to X\times Y$ and $\sigma_3:\Delta^{p+q+r}\to Z$. But $(f\times g)(\sigma_{12}\circ\alpha_{p+q})=f(\sigma_1\circ\alpha_p)g(\sigma_2\circ\mu_q)$ where $\mu_q$ is the ``middle portion'' that sends $\ell\mapsto \ell+p$ where $\ell\in[q]$. In other words, $((f\times g)\times h)(\sigma)=f(\sigma_1\circ\alpha_p)g(\sigma_2\circ\mu_q)h(\sigma_3\circ\omega_r)$. I've used associativity of the ring. But this thing is exactly the same as $(f\times(g\times h))(\sigma)$, so this is associative.
\end{proof}
Therefore, $(\alpha\cup\beta)\cup\gamma=\alpha\cup(\beta\cup\gamma)$.

But this product is obviously not commutative. It treats the two maps completely differently. But we have ways of dealing with this. This comes from the story of acyclic models, where I'll show that $\alpha\cup\beta=(-1)^{|\alpha|\cdot|\beta|}\beta\cup\alpha$. Thus $ H^\ast(X)$ forms a \emph{graded commutative ring}.
%\newpage
\section{Cup product, continued}
We can construct an explicit map $S^p(X)\otimes S^q(Y)\xrightarrow{\times} S^{p+q}(Y)$ via:
\begin{equation*}
(f\times g)(\sigma)=f(\sigma_1\circ\alpha_p)g(\sigma_2\circ\omega_q)
\end{equation*}
where $\alpha_p:\Delta^p\to\Delta^{p+q}$ takes $k\mapsto k$ where $k\in[p]$, and $\omega_q:\Delta^q\to\Delta^{p+q}$ sends $\ell\mapsto \ell+p$ where $\ell\in[q]$.

I would like to modify this definition a bit, and correct what I said. I think it's more natural to put a sign so that:
\begin{equation*}
(f\times g)(\sigma)=(-1)^{pq}f(\sigma_1\circ\alpha_p)g(\sigma_2\circ\omega_q)
\end{equation*}
You'll see why we're adding the sign soon. The claim is that $\times$ is a chain map, so we get a map $ H(S^p(X)\otimes S^q(Y))\to H_{p+q}(X\times Y)$. There is a map $ H_p(X)\otimes H_q(Y)\xrightarrow{\mu} H(S^p(X)\otimes S^q(Y))$ defined as follows. Given chain complexes $C_\bullet$ and $D_\bullet$, define $\mu: H(C_\bullet)\otimes H(D_\bullet)\to H(C_\bullet\otimes D_\bullet)$. We've done this before, but let me just say: $\mu:[x]\otimes [y]\mapsto [x\otimes y]$. For some reason, he said that we'll not call this $\mu$. But I don't want to delete the $\mu$ so I'll just leave it there.

We get the cup product as follows. Given $\Delta:X\to X\times X$, we get $\cup: H_p(X)\otimes H_q(X)\to H_{p+q}(X\times X)\xrightarrow{\Delta^\ast} H_{p+q}(X)$. We proved that there was a class $1\in H_0(X)=\Map(\pi_0(X),R)\ni (\alpha\mapsto 1)$. This acts as a unit for the cup product. Also, the cup product is strictly associative.
\begin{definition}
Let $R$ be a commutative ring. A \emph{graded $R$-algebra} is a graded $R$-module $\cdots,A_{-1},A_0, A_1,A_2,\cdots$ (integer graded sequence) (some people take a direct sum, but I find no reason for doing that) with maps $A_p\otimes_R A_q\to A_{p+q}$ and a map $R\to A_0$ (that determines the unit), that makes the following diagram commute.
\begin{equation*}
\xymatrix{
	A_p\otimes_R (A_q\otimes_R A_r)\ar[r]\ar[d] & A_p\otimes_R A_{q+r}\ar[d]\\
	(A_{p+q})\otimes_R A_r \ar[r] & A_{p+q+r}
}
\end{equation*}
\end{definition}
\begin{definition}
A graded $R$-algebra $A$ is said to be (graded) commutative id the following diagram commutes:
\begin{equation*}
\xymatrix{
	x\otimes y\ar@{|->}[rr] & & (-1)^{|x|\cdot|y|}y\otimes x\\
	A\otimes A\ar[rr]^{\tau}\ar[dr] & & A\otimes A\ar[dl]\\
	 & A & 
}
\end{equation*}
\end{definition}
We claim that $ H_\ast(X)$ forms a graded commutative ring under the cup product. This is nontrivial. On the cochain level, this is clearly not graded commutative. We're going to have to work hard -- in fact, so hard that you're going to do some of it for homework.

We'll do a chain level construction. I say there's a map $\alpha:S_n(X\times Y)\to \bigoplus_{p+q=n}S_p(X)\otimes S_n(Y)$. First I'll tell you what happens to $n$-simplices $\sigma:\Delta^n\to X\times Y$. Let $\sigma_1:\Delta^n\to X\times Y\to X$, and similarly for $\sigma_2$. Define $S_n(X\times Y)\xrightarrow{\alpha} \bigoplus_{p+q=n}S_p(X)\otimes S_n(Y)$ by sending:
\begin{equation*}
\sigma\mapsto\sum_{p+q=n}(\sigma_1\circ\alpha_p)\otimes(\sigma_2\otimes\omega_q)
\end{equation*}
We claim that this is a chain map, and that this induces the cross product on cochains.
\begin{remark}
This map $\alpha$ is called the Alexander-Whitney map.
\end{remark}
If I have two chain complexes, I want to consider a map $\mu:\Hom(C_\bullet,R)\otimes \Hom(D_\bullet,R)\to \Hom(C_\bullet\otimes D_\bullet,R)$ given by $f\otimes g\mapsto(x\otimes y\mapsto (-1)^{pq}f(x)g(y))$ where $|f|=|x|=p$ and $|g|=|y|=q$. I haven't quite done the right thing here, have I? I have to write:
\begin{equation*}
f\otimes g\mapsto\begin{cases}
(x\otimes y\mapsto (-1)^{pq}f(x)g(y)) & |x|=|f|=p, |y|=|g|=q\\
0 & \text{else}
\end{cases}
\end{equation*}
You should check that this is a chain map.

Recall that we have: $S^p(X)\otimes S^q(Y)=\Hom(S_p(X),R)\otimes_R \Hom(S_q(Y),R)$. The map $\mu$ we constructed just now gives a map $\Hom(S_p(X),R)\otimes_R \Hom(S_q(Y),R)\xrightarrow{\mu}\Hom(S_p(X)\otimes S_q(Y),R)\xrightarrow{\alpha}\Hom(S_{p+q}(X\times Y),R)=S^{p+q}(X\times Y)$. This is exactly the cross product $\times:S^p(X)\otimes S^q(Y)\to S^{p+q}(X\times Y)$.

Now, $\alpha$ is a natural transformation. Acyclic models comes into play. For homework, you're going to check that the following diagram commutes.
\begin{equation*}
\xymatrix{S_\ast(X\times Y)\ar[r]^{T_\ast}\ar[d]_{\alpha_{X,Y}} & S_\ast(Y\times X)\ar[d]^{\alpha_{Y,X}}\\
S_\ast(X)\otimes_R S_\ast(Y)\ar[r]^{\tau} & S_\ast(Y)\otimes_R S_\ast(X)}
\end{equation*}
Acyclic models helps us prove things like this.

All of this implies that $ H_\ast(X;R)$ is graded commutative. It's a theorem that you can't find a commutative multiplication. This is where Steenrod operations come from. They're called cohomology operations, and we'll talk more about this in 18.906.

My goal is to compute the cohomology of some space.
\begin{prop}
$ H^\ast(X)\otimes H^\ast(Y)\xrightarrow{\times} H^\ast(X\times Y)$ is a $R$-algebra homomorphism.
\end{prop}
If $A$ and $B$ are graded $R$-algebras, then $(A\otimes B)_n=\bigoplus_{p+q=n}A_p\otimes_R B_q$, and $(a\otimes b)(a^\prime\otimes b^\prime)=(-1)^{|a^\prime|\cdot|b|}aa^\prime\otimes bb^\prime$. This tensor product is graded commutative if $A$ and $B$ are.
\begin{proof}
I have $\Delta_X:X\to X\times X$ and $\Delta_Y:Y\to Y\times Y$. I also have $\Delta_{X\times Y}:X\times Y\to X\times Y\times X\times Y$, which factors as $(1\times T\times 1)\circ(\Delta_X\times \Delta_Y)$. Let $\alpha_1,\alpha_2\in H^\ast(X)$ and $\beta_1,\beta_2\in H^\ast(Y)$. Then $\alpha_1\times \beta_1,\alpha_2\times\beta_2\in H^\ast(X\times Y)$. I want to calculate what $(\alpha_1\times\beta_1)\cup(\alpha_2\times\beta_2)$ is. Let's see:
\begin{align*}
(\alpha_1\times\beta_1)\cup(\alpha_2\times\beta_2) & = \Delta_{X\times Y}^\ast(\alpha_1\times\beta_1\times\alpha_2\times\beta_2)\\
& = (\Delta_X\times\Delta_Y)^\ast(1\times T\times 1)^\ast(\alpha_1\times\beta_1\times\alpha_2\times\beta_2)\\
& = (\Delta_X\times\Delta_Y)^\ast(\alpha_1\times T^\ast(\beta_1\times\alpha_2)\times\beta_2)\\
& = (-1)^{|\alpha_2|\cdot|\beta_1|}(\Delta_X\times\Delta_Y)^\ast(\alpha_1\times\alpha_2\times\beta_1\times\beta_2)
\end{align*}
Now, I have a diagram:
\begin{equation*}
\xymatrix{
	 H^\ast(X\times Y) & \ar[l]^{\times_{X\times Y}} H^\ast(X)\otimes_R H^\ast(Y)\\
	 H^\ast(X\times X\times Y\times Y)\ar[u]^{(\Delta_X\times\Delta_Y)^\ast} & H^\ast(X\times X)\otimes H^\ast(Y\times Y)\ar[l]_{\times_{X\times X,Y\times Y}}\ar[u]^{\Delta_X^\times\otimes\Delta_Y^\ast}
}
\end{equation*}
This diagram commutes because the cross product is natural. This is exactly what commutativity of the diagram means. This means that:
\begin{align*}
(\alpha_1\times\beta_1)\cup(\alpha_2\times\beta_2) & = (-1)^{|\alpha_2|\cdot|\beta_1|}(\Delta_X\times\Delta_Y)^\ast(\alpha_1\times\alpha_2\times\beta_1\times\beta_2)\\
& = (-1)^{|\alpha_2|\cdot|\beta_1|}(\alpha_1\cup\alpha_2)\times(\beta_1\cup\beta_2)
\end{align*}
That's exactly what we wanted.
\end{proof}
\begin{example}
How about $ H^\ast(S^p)$? Let $p>0$. This is: $ H^k(S_p) = \begin{cases}\Z & k=0,p\\ 0 & \text{else}\end{cases}$. Say that $\sigma_p$ generates $ H^p(S^p)$. We now have $ H^\ast(S^p)\otimes H^\ast(S^q)\to H^\ast(S^p\times S^q)$. From the Kunneth theorem, we know that $ H^k(S^p\times S^q)=\begin{cases}\Z & k=0,p,q,p+q\\ 0 & \text{else}\end{cases}$. This structure $ H^\ast(S^p)\otimes H^\ast(S^q)\cong\Z[\sigma_p,\sigma_q]/(\sigma_p^2,\sigma_q^2)\cong H^\ast(S^p\times S^q)$ where $\sigma_p\sigma_q=(-1)^{|p|\cdot|q|}\sigma_q\sigma_p$ where by $\Z[\sigma_p,\sigma_q]$ I mean the free $\Z$-algebra on $\sigma_p,\sigma_q$. When $p=q=1$, this gives an exterior algebra.
\end{example}
This is to be contrasted with $X=S^p\vee S^q\vee S^{p+q}$. This has the same homology as the product of two spheres. But in cohomology, the product of the generators must be zero. There is a diagram:
\begin{equation*}
\xymatrix{
	X\ar[r] & S^p\vee S^q\\
	S^p\ar@{^(->}[u]
}
\end{equation*}
On cohomology, notice that $\sigma_p\sigma_q=0$ in $ H^\ast(S^p\vee S^q)$ because there's no $(p+q)$-dimensional cohomology. Therefore we find that $S^p\vee S^q\vee S^{p+q}\not\simeq S^p\times S^q$.

It's very interesting to think about what the attaching map is:
\begin{equation*}
\xymatrix{
	S^{p+q-1}\ar[r]\ar[d] & S^p\vee S^q\ar[d]\\
	D^{p+q}\ar[r] & S^p\times S^q
}
\end{equation*}
On wednesday we'll have a relaxed talk about surfaces. BTW I might not TeX that.
%\newpage
\section{Surfaces and symmetric nondegenerate bilinear forms}
Never mind, I decided to TeX this.
\subsection{Case of Poincar\'{e} duality}
Let $M$ be a compact manifold of dimension $n$ (this is the kind of thing most of the world cares about). This whole lecture will be happening with coefficients in $\FF_2$. There is a cup product pairing $ H^p(M)\otimes H^q(M)\to H^{p+q}(M)$.
\begin{theorem}
There exists a unique class $[M]\in H_n(M)$, called the fundamental class, such that there's a pairing $ H^p(M)\otimes H^q(M)\xrightarrow{\cup} H^n(M)\xleftarrow{\langle -,[M]\rangle}\FF_2$ when $p+q=n$. This pairing is a nonsingular (aka perfect) pairing, i.e., the map $ H^p(M)\to\Hom( H^q(M),\FF_2)$ defined by $x\mapsto(y\mapsto\langle x\cup y,[M]\rangle)$ is an isomorphism.
\end{theorem}
One thing I should say is that $ H_\ast(M)$ is zero in dimensions above $n$, and $ H_i(M)$ are finitely generated.
\begin{corollary}
From the UCT, it follows that $ H^p(M)\xrightarrow{\cong}\Hom( H^q(M),\FF_2)= H_q(M)$. The corresponding classes under this association are said to be Poincar\'{e} dual to each other.
\end{corollary}
\begin{remark}
This means I get a pairing $ H_q(M)\otimes H_q(M)\to \FF_2$ in homology when $p+q=n$. This is called the \emph{intersection pairing}. If you have one $p$-cycle and one $q$-cycle, this means that I can make them intersect transversely, i.e., they intersect in points -- or not at all. I count the number of points modulo $2$, and this is the element in $\FF_2$.
\end{remark}
\begin{example}
Let $M=T^2=S^1\times S^1$. We know that $ H^1(M)=\FF_2\times\FF_2=\langle x,y\rangle$ where $x^2=0$ and $y^2=0$, and $xy\neq 0$ (this is the generator of $ H^2(M)$). In terms of homology, this means that I can pick cycles on the torus so that they intersect on one point. This makes sense. Also, $x^2=0=y^2$ because the second copy of $x$ and $y$ can just be moved so that they don't intersect.
\end{example}
\begin{example}[Especially interesting case]
If $n=2k$, I get a symmetric bilinear form on $ H_k(M)$ via $ H_k(M)\otimes H_k(M)\to \FF_2$ that is nondegenerate.
\end{example}
\subsection{Symmetric bilinear forms}
I've really screwed up when TeXing this.

If $W\subseteq V$ is a subspace, then a bilinear form on $V$ gives a bilinear form on $W$, but this need not be nonsingular even if the bilinear form on $V$ is. Observe though that the induced bilinear form on $W$ is nonsingular if and only if $W\cap W^\perp=0$. This result should be obvious, but I don't want to say why.

I have a map $V\xrightarrow{\cong} V^\ast$ by sending $v\mapsto(v^\prime\mapsto v\cdot v^\prime)$. Inside $V$, I have $W^\perp$, and I have a quotient $V^\ast\xrightarrow{\Res} W^\ast$, with kernel $\ker\Res$. I want to claim that $V/W^\perp\cong W^\ast$. We know that $\dim W+\dim W^\perp=\dim V=:n$. If $W$ is nonsingular, then $V=W\oplus W^\perp$. This is true as vector spaces, but also as quadratic forms.

To see this, pick a basis $e_1,\cdots,e_k$ for $W$. The quadratic form is represented by some matrix $\begin{pmatrix} e_i\cdot e_j \end{pmatrix}$. It's nonsingular exactly when its determinant is nonzero, i.e., $1$. Then I can also pick a basis for $W^\perp$. Then I have nondegenerate quadratic form on $V$ given by $\begin{pmatrix}\begin{pmatrix} e_i\cdot e_j \end{pmatrix} & 0 \\ 0 & \begin{pmatrix} ... \end{pmatrix}\end{pmatrix}$ where the bottom left thing is that of $W^\perp$. Since the quadratic form on $V$ has determinant $1$, the matrix for $W^\perp$ also has determinant $1$, and hence $V=W\oplus W^\perp$ as quadratic forms.

Now:
\begin{enumerate}
\item Suppose $v\in V$ has $v\cdot v=1$. Then $V=\langle v\rangle\oplus\langle v\rangle^\perp$. This is an orthogonal splitting into nonsingular forms.
\item Assume $v\cdot v=0$ for all\footnote{Your intuition about dot products isn't very useful here, for example the torus. This is because the matrix for the quadratic form on the torus is $\begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix}$. Also, $(x+y)\cdot(x+y)=0$. This means that every cycle on the torus can be moved to have no self-intersection, at least modulo $2$.} $v\in V$. Anyway, in our general situation, $v$ might be zero -- so pick $v\neq 0$. But the form is nonsingular, so there exists $w$ such that $v\cdot w\neq 0$, i.e., $v\cdot w=1$. Then $\langle v,w\rangle$ is a $2$-dimensional subspace sitting inside $V$, so it splits off. Thus we get a hyperbolic form $\begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix}$ (or something like this). (Example: torus)
\end{enumerate}
Thus we conclude:
\begin{prop}
Any nonsingular symmetric bilinear form on a finite dimensional vector space over $\FF_2$ is isomorphic to: $\begin{pmatrix}\begin{pmatrix}1 & \cdots & 0\\ \vdots & \ddots & \vdots \\ 0 & \cdots & 1 \end{pmatrix} & 0 \\ 0 & \begin{pmatrix}\begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix} & \\ & \begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix}\end{pmatrix}\end{pmatrix}$ where the bottom left thing has some number of the hyperbolic $\begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix}$.
\end{prop}
Let $\mathbf{Bil}$ be the set of nonsingular symmetric bilinear forms that are finite dimensional over $\FF_2$ modulo isomorphisms. I've just given a classification of these things. This is a commutative monoid under $\bigoplus$. This $\mathbf{Bil}$ is $\{\text{nonsingular matrices}\}/\text{similarity}$ where similarity means $M\sim N$ if $N=AMA^T$ for some nonsingular $A$.
\begin{claim}
\begin{equation*}
\begin{pmatrix}
 & 1 & \\
1 & & \\
 & & 1
\end{pmatrix}
\sim
\begin{pmatrix}
1 & & \\
& 1 & \\
& & 1
\end{pmatrix}
\end{equation*}
This is the same thing as saying that $\begin{pmatrix}
 & 1 & \\
1 & & \\
 & & 1
\end{pmatrix}=AA^T$ for some nonsingular $A$.
\end{claim}
\begin{proof}
Let $A=\begin{pmatrix}1 & 1 & 1 \\ 1 & 0 & 1 \\ 0 & 1 & 1 \end{pmatrix}$.
\end{proof}
So, $\mathbf{Bil}$ is the commutative monoid generated by $(1)$, $\begin{pmatrix}0 & 1 \\ 1 & 0\end{pmatrix}$ with relation $\begin{pmatrix}
 & 1 & \\
1 & & \\
 & & 1
\end{pmatrix}
\sim
\begin{pmatrix}
1 & & \\
& 1 & \\
& & 1
\end{pmatrix}$.
\subsection{Connected surfaces}
Let's go back to topology. Let $n=2$, $k=1$ (so that $2k=n$). Then you get an intersection pairing on $ H_1(M)$. Suppose I consider $\RP^2$. We know that $ H_1(\RP^2)=\FF_2$. This must be that ``$(1)$''-form. This says that anytime you have a cycle on a projective plane, there's nothing I can do to remove its self interesections. This is also seen on a Mobius band that I will not draw because I don't know how to draw fundamental polygons in LaTeX. But this can be seen by looking at the projection from the Mobius band to the circle.

We also had the notion of connected sums. Let's compute the homology of $\Sigma_1\#\Sigma_2$ using Mayer-Vietoris, like you did in the exercise. You get $ H_2(\Sigma_1\#\Sigma_2)\to H_1(S^1)\to H_1(\Sigma_1-D^2)\oplus H_1(\Sigma_2-D^2)\to H_1(\Sigma_1\#\Sigma_2)$. When you pierce a surface, it collapses down into its $1$-skeleton, so $ H_2(\Sigma_1-D^2)\oplus H_2(\Sigma_2-D^2)\cong 0$. Let's restrict ourselves to connected surfaces. The map $ H_1(S^1)\to H_1(\Sigma_1-D^2)\oplus H_1(\Sigma_2-D^2)$ is the zero map when you think of it as a boundary. Actually, that argument needs to use something, because we know that with integer coefficients, this isn't right -- you need to find an oriented chain in that case -- but this orientation issue goes away in $\FF_2$ because there's no issues with $\pm$. And actually, the map $ H_1(\Sigma_1\#\Sigma_2)\to H_0(S^1)$ is zero as well, so $ H_1(\Sigma_1-D^2)\oplus H_1(\Sigma_2-D^2)\cong H_1(\Sigma_1)\oplus H_1(\Sigma_2)\cong H_1(\Sigma_1\#\Sigma_2)$ that respect the intersection pairing.

Let $\mathbf{Surf}$ be the commutative monoid of connected compact surfaces modulo homeomorphism. What we've proved is that there's a map $\mathbf{Surf}\to\mathbf{Bil}$ that takes connected sums to direct sums of orthogonal bilinear forms. And this map is an isomorphism. I.e.:
\begin{theorem}
There is an isomorphism of commutative monoids $\mathbf{Surf}\to\mathbf{Bil}$.
\end{theorem}
This is a little strange. What is our claim $\begin{pmatrix}
 & 1 & \\
1 & & \\
 & & 1
\end{pmatrix}
\sim
\begin{pmatrix}
1 & & \\
& 1 & \\
& & 1
\end{pmatrix}$ saying in this context? It's saying that $T^2\#\RP^2\cong(\RP^2)^{\# 3}$.
\begin{claim}
If $\Sigma$ is nonoriented, then $\Sigma\# T^2\cong\Sigma\# K$ (where $K$ is the Klein bottle $\RP^2\#\RP^2$).
\end{claim}
If it's nonoriented, then a Mobius strip $M$ sits into $\Sigma$. Uh I guess you're dragging your attachment of the torus along $M$?

There's more to be said about this. You can think of quadratic forms if you're working over the reals or something. You can't do this modulo $2$. Under the story we talked about, the oriented surfaces are the ones where the dot product is always zero. A better thing to ask over $\FF_2$ are quadratic forms such that $q(x+y)=q(x)+q(y)+x\cdot y$. This leads to the Kervaire invariant, etc.

Happy Thanksgiving! See you on Monday.
%\newpage
\section{A plethora of products}
\begin{remark}
Please note that these notes might be absolute bullshit, because I came back today from my flight at 8 am.
\end{remark}
Recall that we have the Kronecker pairing $\langle ,\rangle: H^p(X)\otimes H_p(X)\to R$, which obviously isn't natural because $ H^p$ is contravariant while homology isn't.

Consider the following. Given $f:X\to Y$, and $b\in H^p(Y)$ and $x\in H_p(X)$, how does $\langle f^\ast b,x\rangle$ relate to $\langle b,f_\ast x\rangle$?
\begin{claim}
$$\langle f^\ast b,x\rangle=\langle b,f_\ast x\rangle$$
\end{claim}
\begin{proof}
Easy! I find it useful to write out diagrams of where things are. We're gonna work on the chain model.
\begin{equation*}
	\xymatrix{
	\Hom(S_p(X),R)\otimes S_p(X)\ar[r]^{\langle,\rangle} & R\\
	\Hom(S_p(Y),R)\otimes S_p(X)\ar[r]^{1\otimes f_\ast}\ar[u]^{f^\ast\otimes 1} & \Hom(S_p(Y),R)\otimes S_p(Y)\ar[u]^{\langle,\rangle}
	}
\end{equation*}
The top line is what gives the Kronecker pairing. Note that $f^\ast$ means contravariant and $f_\ast$ means covariant. This diagram commuting \emph{is} the statement we want to prove. Let's see. Suppose $[\beta]=b$ and $[\xi]=x$. Then from the bottom left, going to the right and then the top is $\beta\otimes\xi\mapsto\beta\otimes f_\ast(\xi)\mapsto\beta(f_\ast\xi)$. The other way is $\beta\otimes\xi\mapsto f^\ast(\beta)\otimes\xi=(\beta\circ f)\otimes\xi\mapsto(\beta\circ f)(\xi)$. This is exactly $\beta(f_\ast\xi)$, because, oh, that's just how composition works.
\end{proof}
There's another product around. We called this $\mu$ I think, where $\mu:H(C_\bullet)\otimes H(D_\bullet)\to H(C_\bullet\otimes D_\bullet)$ given by $[c]\otimes [d]\mapsto[c\otimes d]$. I'm secretly using this in the above proof.

We also have the cross product(s!) $\times: H_p(X)\otimes H_q(Y)\to H_{p+q}(X\times Y)$ and $\times: H^p(X)\otimes H^q(Y)\to H^{p+q}(X\times Y)$. You should think of this as fishy because both maps are in the same direction -- but this is OK because we're using different things to make these constructions. Still, they're related:
\begin{theorem}
Let $a\in H^p(X),b\in H^p(Y),x\in H_p(X), y\in H_q(Y)$. Then:
\begin{equation*}
\langle a\times b,x\times y\rangle=(-1)^{|x|\cdot |b|}\langle a,x\rangle\langle b,y\rangle
\end{equation*}
\end{theorem}
This isn't just idle -- although idle things are a great thing to do!
\begin{proof}
Say $[\alpha]=a,[\beta]=b,[\xi]=x,[\eta]=y$. Then recall that $\langle a\times b,x\times y\rangle$ comes from $(\alpha\times\beta)(\sigma)=(-1)^{pq}\alpha(\sigma_1\circ\alpha_p)\beta(\sigma_2\circ\omega_q)$ where $\sigma:\Delta^{p+q}\to X\times Y$. There's two uses of the symbol $\alpha$, and there'll be a third one in a minute, but they'll all have subscripts, so I hope you'll forgive me.

Recall also the ($(p,q)$th component of the) Alexander-Whitney map $\alpha_{X,Y}:S_{p+q}(X\times Y)\to S_p(X)\otimes S_q(Y)$. We have a big diagram:
\begin{equation*}
\xymatrix{
	S_p(X)\otimes S_q(Y)\ar[r]^{\times}\ar[dr]^{1\sim} & S_{p+q}(X\times Y)\ar[d]^{\alpha_{X,Y}}\ar[dr]^{\alpha\times\beta} & \\
	& S_p(X)\otimes S_p(Y)\ar[r]_{\alpha\cdot\beta} & R
}
\end{equation*}
Where $\alpha\cdot\beta:(\xi\otimes\eta)\mapsto(-1)^{pq}\alpha(\xi)\cdot\beta(\xi)$. Now, the diagonal arrow $S_p(X)\otimes S_q(Y)\to S_p(X)\otimes S_p(Y)$ is unique up to chain homotopy, and is homotopic to the identity -- this is what the method of acyclic models tells me. (See the statement of the Eilenberg-Zilber theorem above.)

Thus we find that $\alpha_{X,Y}(\xi\times\eta)=\xi\otimes\eta+(dh+hd)(\xi\otimes\eta)$ for some chain homotopy $h$. I think we're really down now, because $\xi$ and $\eta$ are both cycles, and hence $d$ will kill them (wait it seems like it only kills $\eta$???). So $\alpha_{X,Y}(\xi\times\eta)=\xi\otimes\eta$. Now, $\alpha\cdot\beta$ is a cocycle (check!). When I apply $\alpha$ it kills the $dh$ factor (what???), therefore $(\alpha\cdot\beta)\alpha_{X,Y}(\xi\times \eta)=(\alpha\cdot\beta)(\xi\otimes\eta)$.
\end{proof}
All because of the magic of acyclic models.

Let's now try to prove a Kunneth theorem for $ H^\ast$. Let $R=k$ be a field (eg $\FF_p,\QQ$) that's our coefficient. Then we have $ H_\ast(X)\otimes_k H_\ast(Y)\cong H_\ast(X\times Y)$. Also, this map $ H^p(X)\otimes H_p(X)\to k$ has an adjoint $ H^p(X)\to \Hom_k( H_p(X),k)=: H_p(X)^\vee$, which is an isomorphism because $\Ext$ vanishes over a field.
\begin{theorem}
Let $k$ be a field. Assume that $ H_p(X)$ is finite-dimensional for all $p$. Then $ H^\ast(X)\otimes H^\ast(Y)\cong H^\ast(X\times Y)$.
\end{theorem}
\begin{proof}
We have:
\begin{equation*}
\xymatrix{
	 H^\ast(X)\otimes H^\ast(Y)\ar[r]^{\times}\ar[d]^\cong & H^\ast(X\times Y)\ar[d]^\cong\\
	 H_\ast(X)\otimes H_\ast(Y)^\vee\ar[d]^{\zeta} & H_\ast(X\times Y)^\vee\ar[dl]^\cong\\
	\left( H_\ast(X)\otimes H_\ast(Y)\right)^\vee
}
\end{equation*}
Where $\zeta:\alpha\otimes\beta\mapsto(x\otimes y\mapsto \pm\alpha(x)\beta(y))$. The theorem we proved above implies that this diagram commutes.

In general, I might have two (graded) vector spaces $U,V$, and consider $U^\vee\otimes V^\vee\to(U\otimes V)^\vee$ by the above formula. Well, $(U\otimes V)^\vee=\Hom_k(U\otimes V,k)=\Hom_k(U,V^\vee)$. Thus I get a map $U^\vee\otimes V^\vee\to\Hom_k(U,V^\vee)$. This map is an isomorphism when $U$ or $V$ is finite dimensional. I also have $\widehat{\alpha}:U^\vee\otimes W\to \Hom(U,W)$ via $\alpha\otimes w\mapsto(w\mapsto\alpha(u)w)$. And that's the map we have in mind. The image of $\widehat{\alpha}$ consists of finite rank homomorphisms because a general tensor is a finite sum. This is therefore an isomorphism if $U$ or $W$ is finite dimensional. 

This shows that the map $\zeta$ above is an isomorphism if $ H_\ast(X)$ or $ H_\ast(Y)$ is finite-dimensional. We're done by commutativity.
\end{proof}
We saw before that $\times$ is an algebra map! So this is an isomorphism of algebras.

There are more products around. There is a map $ H^p(Y)\otimes H^q(X,A)\to H^{p+q}(Y\times X,Y\times A)$. Constructing this is on your homework. You can see how this comes about. This comes from the map on the chain level, and it comes from looking at the cochains, and you're going to get a map (???). Anyway. Suppose $Y=X$. Then I get $\cup: H^\ast(X)\otimes H^\ast(X,A)\to H^\ast(X\times X,X\times A)\xrightarrow{\Delta^\ast} H^\ast(X,A)$ where $\Delta:(X,A)\to (X\times X,X\times A)$. This ``relative cup product'' makes $ H^\ast(X,A)$ into a graded module over $ H^\ast(X)$. This is \emph{not} a ring -- it doesn't have a unit, for example -- but it is a module. Also the lexseq is a sequence of $ H^\ast(X)$-modules. I'm just making statements here.

I want to introduce you to \emph{one more} product, which we'll talk more about, and forms the foundation of Poincar\'{e} duality. This is the cap product. What can I do with $S^p(X)\otimes S^n(X)$? Well, I get big map:
\begin{equation*}
S^p(X)\otimes S_n(X)\xrightarrow{1\times (\alpha_{X,X}\circ \Delta_\ast)} S^p(X)\otimes S_p(X)\otimes S_{n-p}(X)\xrightarrow{\langle -,-\rangle\otimes 1}S_{n-p}(X)
\end{equation*}
This composite participates in a chain map. This induces a map in homology $\cap: H^p(X)\otimes H_n(X)\to H_{n-p}(X)$ that comes from $\mu$. This is a pretty interesting map.
\begin{lemma}
$(\alpha\cup\beta)\cap x=\alpha\cap(\beta\cap x)$ and $1\cap x=x$.
\end{lemma}
\begin{proof}
Easy to check from the definition.
\end{proof}
This makes $ H_\ast(X)$ into a module over $ H^\ast(X)$. These are not hard things to check. There's a lot of structure, and the fact that $ H^\ast(X)$ forms an algebra is a good thing. Notice how the dimensions work. People made a mistake before, and they should have indexed cohomology with negative numbers, so that $\cap: H^p(X)\otimes H_n(X)\to H_{n-p}(X)$ makes sense. A cochain complex with positive grading is the same as a chain complex with negative grading.

There's also slant products (two of them!). Maybe we won't talk about them. We will check a few things about cap products, and then we'll go into Poincar\'{e} duality. We can prove nice theorems then.
%\newpage
\section{Cap product and ``\v{C}ech'' cohomology}
Let $R$ be a commutative ring with coefficients. The cap product is a map $\cap: H^p(X)\otimes H_n(X)\to H_{q}(X)$ where $p+q=n$. This comes from a chain level map $S^p(X)\otimes S_n(X)\xrightarrow{1\otimes\alpha} S^p(X)\otimes S_p(X)\otimes S_q(X)\xrightarrow{\langle-,-\rangle\otimes 1}R\otimes S_q(X)\cong S_q(X)$. Using our explicit formula for $\alpha$, we can write:
\begin{equation*}
\cap:\beta\otimes\sigma\mapsto\beta\otimes(\sigma\circ\alpha_p)\otimes(\sigma\circ\omega_q)\mapsto\left(\beta(\sigma\circ\alpha_p)\right)\cdot (\sigma\circ\omega_q)
\end{equation*}
There's many things to say:
\begin{enumerate}
\item $ H_\ast(X)$ is a module for $ H^\ast(X)$.
\item The only reasonable thing to ask for in terms of naturality is the following. Suppose $f:X\to Y$, and let $b\in H^p(Y)$ and $x\in H_n(X)$. We then have $f_\ast(f^\ast(b)\cap x)=b\cap f_\ast(x)$, where $f^\ast(b)\cap x\in H_q(X)$ and $b\cap f_\ast(x)\in H_n(X)$. This is called a projection formula. To see this, let $[\beta]=b$. Then:
\begin{align*}
f_\ast(f^\ast(\beta)\cap\sigma)& =f_\ast(\left(f^\ast(\beta)(\sigma\circ\alpha_p)\right)\cdot(\sigma\circ\omega_q))\\
& =f_\ast(\beta(f\circ\sigma\circ\alpha_p)\cdot(\sigma\circ\omega))\\
& =\beta(f\circ\sigma\circ\alpha_p)\cdot f_\ast(\sigma\circ\omega_q)\\
& = \beta(f\circ\sigma\circ\alpha_p)\cdot(f\circ\sigma\circ\omega_q)\\
& = \beta\cap f_\ast(\sigma)
\end{align*}
So we're done.
\item There's a relation between the cap and Kronecker product. Any space has an augmentation $\varepsilon:X\to\ast$, so I get $\varepsilon_\ast: H_\ast(X)\to R$. Maybe we should compute $\varepsilon_\ast(\beta\cap \sigma)$. I will get zero unless $p=n$ and $q=0$. What does our formula say? This just says that $\varepsilon_\ast(b\cap x)=\varepsilon_\ast(\beta(\sigma)\cdot c^0_{\sigma(n)})=\beta(\sigma)\varepsilon_\ast(c^0_{\sigma(n)})=\beta(\sigma)=\langle \beta,\sigma\rangle$ because $\varepsilon_\ast$ counts the number of points, i.e., it's $1$. Hence $\varepsilon_\ast(b\cap x)=\langle b,x\rangle$.
\item What is $\langle a\cup b,x\rangle$? This is $\varepsilon_\ast((a\cup b)\cap x)=\varepsilon_\ast(a\cap(b\cap x))$ by an assertion in the previous lecture (namely that $(\alpha\cup\beta)\cap x=\alpha\cap(\beta\cap x)$ and $1\cap x=x$), which becomes $\langle a,b\cap x\rangle$. In other words, $\langle a\cup b,x\rangle=\langle a,b\cap x\rangle$. So the cup product is adjoint to the cap product.
\end{enumerate}
\subsection{Relative $\cap$}
There's a lot of structure, but we want more. We want to now try to understand the relative cap product. Suppose $A\subseteq X$ is a subspace. We have:
\begin{equation*}
\xymatrix{
	0\ar[d] & & 0\ar[d]\\
	S^p(X)\otimes S_n(A)\ar[d]^{1\otimes i_\ast}\ar[r]^{i^\ast\otimes 1} & S^p(A)\otimes S_n(A)\ar[r]^{\cap} & S_q(A)\ar[d]\\
	S^p(X)\otimes S_n(X)\ar[rr]^\cap\ar[d] & & S_q(X)\ar[d]\\
	S^p(X)\otimes S_n(X,A)\ar[d]\ar@{-->}[rr] & & S_q(X,A)\ar[d]\\
	0 & & 0
}
\end{equation*}
The left sequence is exact because $0\to S_n(A)\to S_n(X)\to S_n(X,A)\to 0$ splits and tensoring with $S^p(X)$ still leaves it exact. We have to check that this diagram commutes.

Let $\beta\otimes \sigma\in S^p(X)\otimes S_n(A)$. We then get:
\begin{equation*}
\beta\otimes\sigma\xrightarrow{i^\ast\otimes 1}i^\ast\beta\otimes\sigma\to i^\ast(\beta)\cap\sigma\xrightarrow{i_\ast}i_\ast(i^\ast(\beta)\cap\sigma)
\end{equation*}
And:
\begin{equation*}
\beta\otimes\sigma\xrightarrow{1\otimes i_\ast}\beta\otimes i_\ast\sigma\to \beta\cap i_\ast(\sigma)
\end{equation*}
So they're equal by the projection formula. Hence you get $\cap: H^p(X)\otimes H_n(X,A)\to H_q(X,A)$ that makes $ H_\ast(X,A)$ a $ H^\ast(X)$-module.
\subsection{A different perspective on excision}
Recall what excision is. We know that $ H_\ast(X-U,A-U)\cong H_\ast(X,A)$. There's another perspective on this. Suppose $K\subseteq U\subseteq X$ such that $\overline{K}\subseteq\mathrm{Int}(U)$. To simplify things, suppose $K$ is closed and $U$ is open. Let $A=X-K\supseteq X-U=V$. Then excision says that $ H_\ast(X-V,A-V)= H_\ast(X-(X-U),(X-K)-(X-U))\cong H_\ast(X,A)= H_\ast(X,X-K)$. There's a simpler expression: $ H_\ast(X-(X-U),(X-K)-(X-U))= H_\ast(U,U-K)$, so $ H_\ast(U,U-K)\cong H_\ast(X,X-K)$, i.e., it depends only on an open neighborhood of $K$. A question that we now have is: how does this depend on $ H_\ast(K)$? $ H^\ast(K)$? This is really what Poincar\'{e} duality wants to understand.
\begin{example}
We'll eventually be talking, for example, about $X=S^3$ and $K=\text{knot}$.
\end{example}
We want to understand $ H_\ast(X,X-K)$ better. We have a cap product $ H^p(X)\otimes H_n(X,X-K)\to H_q(X,X-K)$. We just decided that $ H_n(X,X-K)\cong H_n(U,U-K)$, and so I have the cap product $ H^p(U)\otimes H_n(U,U-K)\to H_q(U-U-K)$. Hence I get the cap product map like $ H^p(U)\otimes H_n(X,X-K)\to H_q(X,X-K)$. But this seems to depend upon a choice of $U$. What if I make $U$ smaller?
\begin{lemma}
Let $U\supseteq V\supseteq K$. Then:
\begin{equation*}
\xymatrix{
	 H^p(U)\ar[dd]^{i^\ast\otimes 1}\otimes H_n(X,X-K)\ar[dr]^\cap & \\
	 & H_q(X,X-K)\\
	 H^p(V)\otimes H_n(X,X-K)\ar[ur]^\cap
}
\end{equation*}
\end{lemma}
\begin{proof}
Hint: use projection formula again.
\end{proof}
Let $\mathcal{U}_K$ be the set of open neighborhoods of $K$ in $X$. This is a poset (actually a directed set because you can take intersections), under reverse-inclusion as the ordering. This lemma says that $ H^p:\mathcal{U}_K\to\mathbf{Ab}$.
\begin{definition}
$\cHH^p(K):=\varinjlim_{U\in\mathcal{U}_K} H^p(U)$.
\end{definition}
This is bad notation because it depends on the way $K$ is sitting in $X$.

You therefore get $\cHH^p(K)\otimes H_n(X,X-K)\xrightarrow{\cap} H_q(X,X-K)$. This is the best you can do. It's the natural structure that this relative homology has, i.e., $ H_\ast(X,X-K)$ is a module over $\cHH^\ast(K)$.

Sometimes, $\cHH^\ast(K)$ will just be $ H^\ast(K)$. Suppose $K\subseteq X$ satisfies the condition (called the ``regularity'' condition) that for every open $U\supseteq K$, there exists an open $V$ such that $U\supseteq V\supseteq K$ such that $K\to V$ is a homotopy equivalence (or actually just a homology isomorphism). (for example, a smooth knot in $S^3$) Then:
\begin{lemma}
Suppose $\cI$ is a directed set (nonempty). Let $F:\cI\to\mathbf{Ab}$, and suppose I have a natural transformation $\theta:F\to c_A$ (for example, a map from $F$ to its direct limit). This expresses $A$ as $\varinjlim_\cI F$ provided that for all $i$, there is $j\geq i$ such that $F(i)\to A$ factors through $F(j)\to A$, which should be an isomorphism, i.e.:
\begin{equation*}
\xymatrix{
	F(i)\ar[dr]\ar[rr] & & A\\
	& F(j)\ar[ur]^\cong
}
\end{equation*}
\end{lemma}
\begin{proof}
Given $a\in A$, it has to come from somewhere to be a direct limit. This is obviously true. Also, for any $i$ and $a_i\in F(i)$ such that $a_i\mapsto 0$, then there exists $j\geq i$ such that $a_i\mapsto 0\in F(j)$. This is also obvious.
\end{proof}
\begin{remark}
This is a really strong condition by the way. It is a really stupid way.
\end{remark}
This works in the case that $K$ is regular in $X$. Thus, under this condition, $\cHH^p(K)\cong H^p(K)$. One other comment is that more generally, if $X$ is an Euclidean neighborhood retract (a retract of a neighborhood in some $\RR^n$), and $K$ is locally compact, then $\cHH^p(K)$ depends only on $K$, and it is isomorphic to \v{C}ech cohomology (which is a different type of cohomology theory).
%\newpage
\section{$\cHH^\ast$ as a cohomology theory, and the fully relative $\cap$ product}
pset 6 is now doe December 7. If you read any book about Poincar\'{e} duality, there'll be an incomprehensible smear of stuff about cap products. I want to give you a cleaner explanation. The motivation is that it's the main step in the proof of Poincar\'{e} duality.

Let $X$ be any space, and let $K\subseteq X$ be a closed subspace. We'll write $\cHH^p(K)=\varinjlim_{U\in\mathcal{U}_K} H^p(U)$ (and call it the \v{C}ech cohomology -- but there's a different definition, although in certain cases they are isomorphic). We should write down a relative version of this as well. Suppose $L\subseteq K$ be closed. Define $\cHH^p(K,L)=\varinjlim_{(U,V)\in\mathcal{U}_{K,L}} H^p(U,V)$ where $K\supseteq L$ and $K\subseteq U$, and $L\subseteq V$ such that $V\subseteq U$. Here $\mathcal{U}_{K,L}$ is the directed set:
\begin{equation*}
\mathcal{U}_{K,L}\text{ is the set of }\xymatrix{K\ar@{^(->}[d] & L\ar@{^(->}[d]\ar@{^(->}[l] \\ U & V\ar@{^(->}[l]}
\end{equation*}
such that $U$ and $V$ are open.
\begin{theorem}
There is a lexseq:
\begin{equation*}
\cdots\to\cHH^p(K,L)\to\cHH^p(K)\to\cHH^p(L)\xrightarrow{\delta}\cHH^{p+1}(K,L)\to\cdots
\end{equation*}
\end{theorem}
All the maps in the lexseq are mysterious.

Also, excision holds:
\begin{theorem}[Excision]
Suppose $A,B\subseteq X$ are closed. Then $\cHH^p(A\cup B,A)\cong\cHH^p(B,A\cap B)$. This is a form of excision that doesn't hold for ordinary cohomology.
\end{theorem}
So \v{C}ech cohomology is better suited for talking about closed sets. 

We defined $\cap:\cHH^p(K)\otimes H_n(X,X-K)\to H_q(X,X-K)$, such that $p+q=n$. Fix $x_K\in H_n(X,X-K)$. Then capping with $x_K$ gives a map $\cap x_k:\cHH^p(K)\to H_q(X,X-K)$.

Now, if $K\supseteq L$, then $X-K\subseteq X-L$, so I get $H_n(X,X-K)\xrightarrow{i_\ast} H_n(X,X-L)$. Then $x_K\mapsto x_L$. We can now extend our lexseq:
\begin{equation*}
\xymatrix{
	\cdots\ar[r] & \cHH^p(K,L)\ar[r] & \cHH^p(K)\ar[r]\ar[d]_{-\cap x_k} & \cHH^p(L)\ar[r]^\delta\ar[d]_{-\cap x_L} & \cHH^{p+1}(K,L)\ar[r] & \cdots\\
	& H_q(X-L,X-K)\ar[r]& H_q(X,X-K)\ar[r] & H_q(X,X-L)\ar[r]^\partial & H_{q-1}(X-L,X-K)\ar[r] & \cdots
}
\end{equation*}
Where the bottom thing comes from the lexseq of the triple (see exercise 9 on your pset) $X-K\subseteq X-L\subseteq X$ (I think). Then we can extend our theorem on the lexseq:
\begin{theorem}
There is a lexseq and a ladder:
\begin{equation*}
\xymatrix{
	\cdots\ar[r] & \cHH^p(K,L)\ar[r]\ar@{-->}[d]_{-\cap x_{K}} & \cHH^p(K)\ar[r]\ar[d]_{-\cap x_k} & \cHH^p(L)\ar[r]^\delta\ar[d]_{-\cap x_L} & \cHH^{p+1}(K,L)\ar[r]\ar[d]_{-\cap x_{K}} & \cdots\\
	\cdots\ar[r] & H_q(X-L,X-K)\ar[r]& H_q(X,X-K)\ar[r] & H_q(X,X-L)\ar[r]^\partial & H_{q-1}(X-L,X-K)\ar[r] & \cdots
}
\end{equation*}
\end{theorem}
What I have to do is define a cap product of the following form (bottom row):
\begin{equation*}
\xymatrix{
	\cHH^p(K)\otimes H_n(X,X-K)\ar[r]^{\cap} & H_q(X,X-K)\\
	\cHH^p(K,L)\otimes H_n(X,X-K)\ar[u]\ar[r]^{\cap} & H_q(X-L,X-K)
}
\end{equation*}
(where $p+q=n$)

I want to define this fully relative cap product $\cHH^p(K,L)\otimes H_n(X,X-K)\to H_q(X-L,X-K)$. We'll use this in the inductive proof of (some) important theorem.

Our map $\cHH^p(K)\otimes H_n(X,X-K)\to H_q(X,X-K)$ came from $S^p(U)\otimes S_n(U,U-K)\to S_q(U,U-K)$ where $U\supseteq K$, defined via $\beta\otimes\sigma\mapsto\beta(\sigma\circ\alpha_p)\cdot(\sigma\circ\omega_q)$. I'm hoping to get:
\begin{equation*}
\xymatrix{
	S^p(U)\otimes S_n(U,U-K)\ar[r] & S_q(U,U-K)\\
	S^p(U,V)\otimes S_n(U-L)/S_n(U-K)\ar[r]\ar[u] & S_q(U-L)/S_q(U-K)\ar[u]
}
\end{equation*}
where again we have inclusions ($U,V$ open and $K,L$ closed):
\begin{equation*}
\xymatrix{K\ar@{^(->}[d] & L\ar@{^(->}[d]\ar@{^(->}[l] \\ U & V\ar@{^(->}[l]}
\end{equation*}
The bottom map $S^p(U,V)\otimes S_n(U-L)/S_n(U-K)\to S_q(U-L)/S_q(U-K)$ makes sense. We can evaluate a cochain that kills everything on $V$. This means that we can add in $S_n(V)$ to get $S^p(U,V)\otimes (S_n(U-L)+S_n(V))/S_n(U-K)\to S_q(U-L)/S_q(U-K)$ by sending $\beta\otimes\tau\mapsto 0$ where $\tau:\Delta^n\to V$. This means that the diagram:
\begin{equation*}
\xymatrix{
	S^p(U)\otimes S_n(U,U-K)\ar[r] & S_q(U,U-K)\\
	S^p(U,V)\otimes (S_n(U-L)+S_n(V))/S_n(U-K)\ar[r]\ar[u] & S_q(U-L)/S_q(U-K)\ar[u]
}
\end{equation*}
commutes. It's not that far off from where we want to go.

Now, $(U-L)\cup V=U$. I have this covering of $U$ by two open sets. In $S_n(U-L)+S_n(V)$ we're taking the sum of $n$-chains. We have a map $S_\ast(U-L)+S_\ast(V)\to S_\ast(U)$. We have already worked through this -- the locality principle! This tells us that $S_\ast(U-L)+S_\ast(V)\to S_\ast(U)$ is a homotopy equivalence. Hence we can extend our diagram:
\begin{equation*}
\xymatrix{
	S^p(U)\otimes S_n(U,U-K)\ar[r] & S_q(U,U-K)\\
	S^p(U,V)\otimes (S_n(U-L)+S_n(V))/S_n(U-K)\ar[r]\ar[d]^{\simeq}\ar[u] & S_q(U-L)/S_q(U-K)\ar[u]\\
	S^p(U,V)\otimes S_n(U)/S_n(U-K) & 
}
\end{equation*}
We want the homology of $S_n(U)/S_n(U-K)$ to approximate $H_n(X,X-K)$.
\begin{claim}
There is an isomorphism $H_n(S_\ast(U)/S_\ast(U-K))=H_n(U,U-K)\to H_n(X,X-K)$.
\end{claim}
\begin{proof}
This is exactly excision! Remember our recasting of excision in the previous lecture.
\end{proof}
This means that what we've constructed really \emph{is} what we want! We now have our large lexseq:
\begin{equation*}
\xymatrix{
	\cdots\ar[r] & \cHH^p(K,L)\ar[r]\ar@{-->}[d]_{-\cap x_{K}} & \cHH^p(K)\ar[r]\ar[d]_{-\cap x_k} & \cHH^p(L)\ar[r]^\delta\ar[d]_{-\cap x_L} & \cHH^{p+1}(K,L)\ar[r]\ar[d]_{-\cap x_{K}} & \cdots\\
	\cdots\ar[r] & H_q(X-L,X-K)\ar[r]& H_q(X,X-K)\ar[r] & H_q(X,X-L)\ar[r]^\partial & H_{q-1}(X-L,X-K)\ar[r] & \cdots\\
	\cdots\ar[r] & H_q(U-L,U-K)\ar[r]\ar[u]^{\cong,\text{ five-lemma}} & H_q(U,U-K)\ar[r]\ar[u]^{\cong,\text{ locality}} & H_q(U,U-L)\ar[r]\ar[u]^{\cong,\text{ locality}} & \cdots
}
\end{equation*}
As desired.

The diagram:
\begin{equation*}
\xymatrix{
	\cHH^p(L)\ar[r]^\delta\ar[d]^{-\cap x_L} & \cHH^{p+q}(K,L)\ar[d]^{-\cap x_K}\\
	H_q(X,X-L)\ar[r]^{\partial} & H_{q-1}(X-L,X-K)
}
\end{equation*}
says that:
\begin{equation*}
(\delta b)\cap x_k=\partial(b\cap x_L)
\end{equation*}
It's rather wonderful! You have a decreasing sequence below and an increasing one above.

I want to reformulate all of this in a more useful fashion, from Mayer-Vietoris. We had two different proofs, one from locality, and another one that we'll remind you of:
\begin{equation*}
\xymatrix{
	\cdots\ar[r] & A_n\ar[r]\ar[d] & B_n\ar[r]\ar[d]^\cong & C_n\ar[r]\ar[d] & A_{n-1}\ar[r]\ar[d] & \cdots\\
	\cdots\ar[r] & A_n^\prime\ar[r] & B_n^\prime\ar[r] & C^\prime_n\ar[r] & A^\prime_{n-1}\ar[r] & \cdots
}
\end{equation*}
then you get a lexseq:
\begin{equation*}
\cdots\to C_{n+1}\to C^\prime_{n+1}\oplus A_n\to A^\prime_n\xrightarrow{\partial} C_n\to\cdots
\end{equation*}
You can use this to prove Mayer-Vietoris -- I will do this in a special case. (This is exactly what I did in a homework assignment\footnote{Suppose $A\subseteq X$ is a subspace of $X$. Then there is a lexseq in reduced homology $\cdots\to \widetilde{ H}_n(A)\to \widetilde{ H}_n(X)\to H_n(X,A)\to\widetilde{ H}_{n-1}(A)\to\cdots$ that can be obtained by using the lexseq in homology of the sexseq $0\to\widetilde{S}_\ast(A)\to\widetilde{S}_\ast(X)\to S_\ast(X,A)\to 0$.

Now suppose $X=A\cup B$. Consider the ladder:
\begin{equation*}
\xymatrix@C=10pt{\cdots\ar[r] & H_{n+1}(A,A\cap B)\ar[r]\ar[d] & \widetilde{ H}_n(A\cap B)\ar[r]\ar[d] & \widetilde{ H}_n(A)\ar[r]\ar[d] & H_n(A,A\cap B)\ar[r]\ar[d] & \cdots\\
\cdots\ar[r] & H_{n+1}(X,B)\ar[r] & \widetilde{ H}_n(B)\ar[r] & \widetilde{ H}_n(X)\ar[r] & H_n(X,B)\ar[r] & \cdots}
\end{equation*}
The first and fourth maps as shown are isomorphisms because of excision. The lexseq from the ladder (see above) therefore yields the Mayer-Vietoris sequence $\cdots\to \widetilde{ H}_n(A\cap B)\to \widetilde{ H}_n(B)\oplus \widetilde{ H}_n(A)\to \widetilde{ H}_n(X)\to \widetilde{ H}_{n-1}(A\cap B)\to\cdots$.}!) We have a ladder of lexseqs:
\begin{equation*}
\xymatrix{
	\cdots\ar[r] & H_q(X,X-A\cup B)\ar[r]\ar[d] & H_q(X,X-A)\ar[r]\ar[d] & H_{q-1}(X-A,X-A\cup B)\ar[r]\ar[d]^{\cong,\text{ excision}} & \cdots\\
	\cdots\ar[r] & H_q(X,X-B)\ar[r] & H_q(X,X-A\cap B)\ar[r] & H_{q-1}(X-A\cap B,X-B)\ar[r] & \cdots
}
\end{equation*}
This means that (using the lexseq of the ladder) you have a lexseq:
\begin{equation*}
\cdots\to H_q(X,X-A\cup B)\to H_q(X,X-A)\oplus H_q(X,X-B)\to H_q(X,X-A\cap B)\to H_{q-1}(X,X-A\cup B)\to\cdots
\end{equation*}
This can be used to give a lexseq for \v{C}ech cohomology:
\begin{equation*}
\cdots\to \cHH^p(A\cup B)\to \cHH^p(A)\oplus \cHH^p(B)\to \cHH^p(A\cap B)\to \cHH^{p+q}(A\cup B)\to\cdots
\end{equation*}
so that we're going to get a commutative Mayer-Vietoris ladder:
\begin{theorem}
There's a ``Mayer-Vietoris'' ladder:
\begin{equation*}
\xymatrix{
	\to\cHH^p(A\cup B)\ar[r]\ar[d]^{-\cap x_{A\cup B}} & \cHH^p(A)\oplus \cHH^p(B)\ar[r]\ar[d]^{(-\cap x_A)\oplus -\cap x_B} & \cHH^p(A\cap B)\ar[r]\ar[d] & \cHH^{p+q}(A\cup B)\ar[r]\ar[d] & \cdots\\
	\to H_q(X,X-A\cup B)\ar[r]& H_q(X,X-A)\oplus H_q(X,X-B)\ar[r]& H_q(X,X-A\cap B)\ar[r]& H_{q-1}(X,X-A\cup B)\ar[r]&\cdots
}
\end{equation*}
where I have four cohomology classes $x_{A \cup B},x_A,x_B,x_{A\cap B}$ that commute in:
\begin{equation*}
\xymatrix{
	 & H_n(X,X-A)\ar[dr] & \\
	H_n(X,X-A\cap B)\ar[ur]\ar[dr] & & H_n(X,X-A\cap B)\\
	 & H_n(X,X-B)\ar[ur]
}
\end{equation*}
\end{theorem}
This is the most complicated blackboard for the rest of the course. Also xymatrix is not compiling properly because the diagram is too big!
%\newpage
\section{$\cHH^\ast$ as a cohomology theory}
Office hours: today, Hood in 4-390 from 1:30 to 3:30 and Miller in 4-478 from 1-3 on Tuesday. Note that pset 6 is due Wednesday. Also, Wednesday we'll have a lightning review of $\pi_1$ and covering spaces.

We're coming to the end of the course, and there are going to be oral exams. I have some questions that I'd like to ask you. They won't be super advanced, detailed questions -- they'll be basic things. I'll post a list of examples of questions. I won't select questions from that list, that's cruel and isn't the point. The oral will be 40 minutes. It'll be fun -- better than a written exam. It's much better than grading a written exam!

PLEASE DRAW A PICTURE WHEN READING THIS IF YOU DIDN'T COME TO CLASS!
\subsection{$\cHH^\ast$ versus $H^\ast$}
Let's come up with an example that distinguishes $\cHH^\ast$ and $H^\ast$. This is a famous example -- the topologist's sine curve. The topologist's sine curve is defined as follows. Consider the graph of $\sin(\pi/x)$ where $0<x\leq 1$, where we draw a continuous curve from $(0,-1)$ to $(1,0)$. This is a counterexample for a lot of things, you've probably seen it in 18.901.

What is $H_\ast$ of the topologist sine curve? Use Mayer-Vietoris! I can choose the bottom half to be some connected portion of the continuous curve from $(0,-1)$ to $(1,0)$, and the top half to be the rest of the space that intersects the bottom half (in two spots). The top is the union of two path components, each contractible.

To see this, suppose I have $\sigma:I\to\mathrm{top}$ such that $\sigma(0)=(0,b)$ for some $-3/2 < b\leq 1$ (the $-3/2$ is arbitrary, just choose something $\leq 0$). If $b<1$, pick $\epsilon>0$ such that if we write $\sigma=(\sigma_1,\sigma_2)$, then $\sigma_2(t)<1$ for all $t\in[0,\epsilon)$, where we use continuity. Then $\sigma|_{[0,\epsilon)}$ can't be on the sine curve. If $b=1$, pick $\epsilon>0$ such that $\sigma_2(t)>-1$ for all $t\in[0,\epsilon)$. Similarly, it can't be on the sine curve.

Thus, $H_1$ is simple: it fits into $0\to H_1(X)\to H_0(\mathrm{top}\cap\mathrm{bottom})\to H_0(\mathrm{top})\oplus H_0(\mathrm{top})\to H_0(X)\to 0$. This is basically $0\to H_1(X)\xrightarrow{\partial}\to\Z\oplus\Z\hookrightarrow\Z\oplus\Z\oplus\Z\to\Z\to 0$, so $\partial=0$. This means that $H_\ast(X)\cong H_\ast(\ast)$ and this implies that $H^\ast(X)\cong H^\ast(\ast)$.

How about $\cHH^\ast$? Let $X\subset U$ be an open neighborhood. The interval is contained in some $\epsilon$-neighborhood that's contained in $U$. This implies that there exists a neighborhood $X\subseteq V\subseteq U$ such that $V\sim S^1$. Therefore, $\varinjlim_{U\in\mathcal{U}_X}H^\ast(U)\cong H^\ast(S^1)$ by ``cofinality''. So $\cHH^\ast$ and $H^\ast$ differ.
\subsection{Cofinality}
Let $\cI$ be a directed set. Let $A:\cI\to \mathbf{Ab}$ be a functor. If I have a functor $f:\cK\to\cI$, then I get $Af:\cK\to\mathbf{Ab}$, i.e., $(Af)_j=A_{f(j)}$.

I can form $\varinjlim_{\cK}Af$ and $\varinjlim_{I}A$. I claim you have a map $\varinjlim_{\cK}Af\to\varinjlim_{\cI}A$. All I have to do is the following:
\begin{equation*}
\xymatrix{
	\varinjlim_{J}Af\ar[r] & \varinjlim_{I}A\\
	A_{f(j)}\ar[u]^{\mathrm{in}_j}
}
\end{equation*}
So I have to give you maps $A_{f(j)}\to\varinjlim_{I}A$ for various $j$. I know what to do, because I have $\mathrm{in}_{f(j)}:A_{f(j)}\to\varinjlim_{I}A$. Are they compatible when I change $j$? Suppose I have $j^\prime\leq j$. Then I get a map $f(j^\prime)\to f(j)$, so I have a map $A_{f(j^\prime)}\to A_{f(j)}$, and thus the maps are compatible. Hence I get:
\begin{equation*}
\xymatrix{
	\varinjlim_{J}Af\ar[r] & \varinjlim_{I}A\\
	(Af)_j=A_{f(j)}\ar@{-->}[ur]^{\mathrm{in}_{f(j)}}\ar[u]^{\mathrm{in}_j}
}
\end{equation*}
\begin{example}
Suppose $K\supseteq L$ be closed, then I get a map $\cHH^\ast(K)\to\cHH^\ast(L)$. Is this a homomorphism? Well, $\cHH^\ast(K)=\varinjlim_{U\in\mathcal{U}_K}H^\ast(U)$ and $\cHH^\ast(L)=\varinjlim_{V\in\mathcal{U}_L}H^\ast(V)$. This is an example of a $\cI$ and $\cK$ that I care about. Well, $\mathcal{U}_K\subseteq\mathcal{U}_L$, and thus I get a map $\cHH^\ast(K)\to\cHH^\ast(L)$, which is what I wanted.

I can do something for relative cohomology. Suppose:
\begin{equation*}
\xymatrix{K\ar@{^(->}[d] & L\ar@{^(->}[d]\ar@{_(->}[l] \\ K^\prime & L^\prime\ar@{_(->}[l]}
\end{equation*}
I get a homomorphism $\cHH^\ast(K,L)\to \cHH^\ast(K^\prime,L^\prime)$ because I have $\mathcal{U}_{K,L}\to\mathcal{U}_{K^\prime,L^\prime}$.
\end{example}
This isn't exactly what we need:
\begin{question}
When does $f:\cK\to\cI$ induce an isomorphism $\varinjlim_{J}Af\to\varinjlim_{I}A$?
\end{question}
This is a lot like taking a sequence and a subsequence and asking when they have the same limit. There's a cofinality condition in analysis, that has a similar expression here.
\begin{definition}
$f:\cK\to\cI$ is cofinal if for all $i\in\cI$, there exists $j\in\cK$ such that $i\leq f(j)$.
\end{definition}
\begin{example}
If $f$ is surjective.
\end{example}
\begin{lemma}
If $f$ is cofinal, then $\varinjlim_{J}Af\to\varinjlim_{I}A$ is an isomorphism.
\end{lemma}
\begin{proof}
Check that $\{A_{f(j)}\to\varinjlim_{I}A\}$ satisfies the necessary and sufficient conditions:
\begin{enumerate}
\item For all $a\in\varinjlim_{I}A$, there exists $j$ and $a_j\in A_{f(j)}$ such that $a_j\mapsto a$. We know that there exists some $i$ and $a_i\in A$ such that $a_i\mapsto a$. Pick $j$ such that $f(j)\geq i$, so we get a map $a_i\to a_{f(j)}$, and by compatibility, we get $a_{f(j)}\mapsto a$.
\item The other condition is also just as easy.
\end{enumerate}
\end{proof}
This is a very convenient condition.
\begin{example}
I had a perverse way of constructing $\QQ$ by using the divisibility directed system. A much simpler (linear!) directed system is $\Z\xrightarrow{2}\Z\xrightarrow{3}\Z\xrightarrow{4}\Z\to\cdots$. This has the same colimit as the divisibility directed system because $n|n!$, so we have a cofinal map between directed systems.
\end{example}
How about the direct limits in the \v{C}ech cohomology case?
\begin{example}
Do I have a map $\cHH^\ast(K,L)\to\cHH^\ast(K)$? Suppose:
\begin{equation*}
\xymatrix{K\ar@{^(->}[d] & L\ar@{^(->}[d]\ar@{_(->}[l] \\ U & V\ar@{_(->}[l]}
\end{equation*}
Then $\cHH^p(K,L)=\varinjlim_{(U,V)\in\mathcal{U}_{K,L}}H^p(U,V)$ and $\cHH^p(K)=\varinjlim_{U\in\mathcal{U}_K}H^p(U)$. I have a map of directed sets $\mathcal{U}_{K,L}\to\mathcal{U}_K$ by sending $(U,V)\mapsto U$. I didn't have to use cofinality. I want a long exact sequence, though, and I'm going to do this by saying that it's a directed limit of a long exact sequence. I'm going to have to have all of these various \v{C}ech cohomologies as being the directed limit over the \emph{same} indexing set.

I'd really like to say that $\cHH^p(K)=\varinjlim_{U\in\mathcal{U}_K}H^p(U)\cong \varinjlim_{(U,V)\in\mathcal{U}_{K,L}}H^p(U)$. Thus I need to show that $\mathcal{U}_{K,L}\to\mathcal{U}_K$ where $(U,V)\mapsto U$ is cofinal. This is easy, because if $U\in\mathcal{U}_K$, just pick $(U,U)$, i.e., $\mathcal{U}_{K,L}\to\mathcal{U}_K$ is cofinal. How about $\mathcal{U}_{K,L}\to\mathcal{U}_L$ by $(U,V)\mapsto V$; is it cofinal? Yes! For $V\in\mathcal{U}_L$, pick $(X,V)$! This means that $\cdots\cHH^{p-1}(L)\to\cHH^p(K,L)\to\cHH^p(K)\to\cHH^p(L)\to\cHH^{p+1}(K,L)$ is $\varinjlim_{\mathcal{U}_{K,L}}\left(\cdots\to H^{p}(U,V)\to\cdots\right)$, and hence exact.
\end{example}
How about excision? I need this to get to Mayer-Veitoris!
\begin{lemma}
Assume $X$ is normal and $A,B$ are closed subsets. Then $\cHH^p(A\cup B,B)\to\cHH^p(A,A\cap B)$ is an isomorphism. 
\end{lemma}
\begin{proof}
Well, $\cHH^p(A\cup B,B)$ is $\varinjlim$ over $\mathcal{U}_{A\cup B,B}$ and $\cHH^p(A,A\cap B)$ is $\varinjlim$ over $\mathcal{U}_{A,A\cap B}$. Let $W\supseteq A$ and $Y\supseteq B$ are neighborhoods. I claim that $\mathcal{U}_A\times\mathcal{U}_B\to\mathcal{U}_{A\cup B,B}$ sending $(W,Y)\mapsto (W\cup Y,Y)$ and $\mathcal{U}_A\times\mathcal{U}_B\to\mathcal{U}_{A,A\cap B}$ sending $(W,Y)\mapsto (W,W\cap Y)$ are cofinal.

If I give you $(U,V)\in \mathcal{U}_{A\cup B,B}$, define $(W,V)\in\mathcal{U}_A\times\mathcal{U}_B$ where $W=U$ and $Y=V$, so $\mathcal{U}_A\times\mathcal{U}_B\to\mathcal{U}_{A\cup B,B}$ is surjective, hence cofinal. The latter is trickier. Let $U\supseteq A$ and $V\supseteq A\cap B$. Here's where normality comes into play. Separate $B-V$ from $A$. Let $T\supseteq B-V$. Shit. \emph{Shit!}

Maybe I'll leave this to you. I'll put this on the board on Wednesday. Anyway, I'll use normality to show that $\mathcal{U}_A\times\mathcal{U}_B\to\mathcal{U}_{A,A\cap B}$ is cofinal, and thus this verifies excision -- so you actually have excision.
\end{proof}
\section{Finish off the proof of $\cHH^p$ excision, topological manifolds, fundamental classes}
\subsection{The end of the proof}
Let's finish off the proof from last time. Suppose $A,B$ are closed in normal $X$. \underline{Excision for $\cHH^p$}:
\begin{equation*}
\xymatrix{
	\varinjlim_{(W,Y)\in\mathcal{U}_A\times\mathcal{U}_B}H^p(W\cup Y,Y)\ar[rrr]^{\cong,\text{ ordinary excision}}\ar[d]^{\cong,\text{ cofinality/surjectivity}} & & & \varinjlim_{\mathcal{U}_A\times\mathcal{U}_B}H^p(W,W\cap Y)\ar[d]^{\cong,\text{ cofinality, see below}}\\
	\varinjlim_{(U,V)\in\mathcal{U}_{A\cup B,B}}H^p(U,V)\ar[rrr]\ar@{=}[d] & & & \varinjlim_{(U,V)\in\mathcal{U}_{A,A\cap B}}H^p(U,V)\ar@{=}[d]\\
	\cHH^p(A\cup B,B)\ar[rrr] & & & \cHH^p(A,A\cap B)
}
\end{equation*}

$\mathcal{U}_A\times\mathcal{U}_B\to\mathcal{U}_{A,A\cap B}$ is cofinal since: start with $(U,V)\supseteq(A,A\cap B)$. Using normality, separate $B\cap(X-V)\subseteq T$ and $A\subseteq S$. Take $W=U\cap S$ and $Y=V\cup T$. Then $A\subseteq W\subseteq U$ and $A\cap B\subseteq W\cap Y=S\cap V\subseteq V$.

This means that $\cHH^p$ satisfies excision, hence Mayer-Vietoris. Let's put this in the drawer for now.
\subsection{Topological manifolds + Poincar\'{e} duality}
yayyyyyyyyyyyyy finally
\subsubsection{Fundamental class and orientation local system}
\begin{definition}
A \emph{topological manifold} is a Hausdorff space $M$ such that for every $x\in M$, there exists a neighborhood $U\ni x$ that is homeomorphic to some Euclidean space $\RR^n$. It's called an $n$-manifold if all $U$ are homeomorphic to $\RR^n$ for the \emph{same} $n$.
\end{definition}
\begin{example}
$\RR^n$, duh. $\emptyset$ is an $n$-manifold for every $n$. The sphere $S^n$. The Grassmannian $\mathrm{Gr}_k(\RR^n)$, introduced in the beginning of the course. I don't know exactly what the dimension of this is, but you can figure it out. Also, $V_k(\RR^n)$, and surfaces.
\end{example}
These things are the most interesting things to look at.
\begin{warning}
We assume the following.
\begin{enumerate}
\item There exists a countable basis.
\item There exists a good cover, i.e., all nonempty intersections are Euclidean as well (always true for differentiable manifolds because you can take geodesic neighborhoods, and in particular for the manifolds we listed above).
\end{enumerate}
\end{warning}
This is the context in which duality works.
\begin{definition}
Let $X$ be any space, and let $a\in X$. The local homology of $X$ at $a$ is the homology $H_\ast(X,X-a)$. We're always working over a commutative ring.
\end{definition}
For example, $H_q(\RR^n,\RR^n-0)=\begin{cases}\text{free of rank }1 & q=n \\ 0 & q\neq n\end{cases}$. This means that local homology is picking out the characteristic feature of Euclidean space. Therefore we also have $H_q(M,M-a)=\begin{cases}\text{free of rank }1 & q=n \\ 0 & q\neq n\end{cases}$ for $n$-manifolds.
\begin{notation}
Let $j_a:(M,\emptyset)\to (M,M-a)$ be the inclusion.
\end{notation}
\begin{definition}
A fundamental class for $M$ (an $n$-manifold) is $[M]\in H_n(M)$ such that for every $a\in M$, the image of $[M]$ under $j_{a,\ast}:H_n(M)\to H_n(M,M-a)$ is a generator of $H_n(M,M-a)$.
\end{definition}
This is somehow trying to say that this class $[M]$ covers the whole manifold.
\begin{example}
When does a space have a fundamental class?
\begin{center}
\begin{tabular}{c|c c c } 
 \hline
  & $\RR^2$ & $\RP^2$ & $T^2$ \\ 
  \hline
 $R=\Z$ & no! & no! & yes! you did this for homework \\
 $R=\Z/2\Z$ & no! & yes! & yes!
\end{tabular}
\end{center}
Something about orientability and compactness seem to be involved.
\end{example}
What do we have? 
\begin{definition}
$o_M=\coprod_{a\in M}H_n(M,M-a)$ as a set. This has a map $p:o_M\to M$.
\end{definition}
\begin{construction}
This can be topologized in Euclidean neighborhoods. Let $U\cong\RR^n$ be an Euclidean neighborhood of $a$. I can always arrange so that $a$ corresponds to $0$. We have the open disk sitting inside the closed disk: $\widetilde{D^n}\subseteq D^n\subseteq \RR^n$ that corresponds to some open $V\subseteq \overline{V}\subseteq U$. Let $x\in V$. I have a diagram:
\begin{equation*}
\xymatrix{
	H_n(M,M-\overline{V})\ar[d] & & H_n(U,U-\overline{V})\ar[ll]^{\text{ excision of }M-U}_{\cong}\ar[d]^\cong & H_n(\RR^n,\RR^n-D^n)\ar@{=}[l]\ar[d]^{\cong,\text{ homotopy equivalence}}\\
	H_n(M,M-x) & & H_n(U,U-x)\ar[ll] & H_n(\RR^n,\RR^n-0)\ar@{=}[l]
}
\end{equation*}
Hence $H_n(M,M-\overline{V})\cong H_n(M,M-x)$. Thus I can collect points in $o_M$ together when they come from the same class in $H_n(M,M-\overline{V})$, so they form ``sheets''.

I have a map $V\times H_n(M,M-\overline{V})\to o_M|_{V}=p^{-1}(V)$ by sending $(x,c)\mapsto (j_x)_\ast(c)\in H_n(M,M-x)$, and this map is bijective (that's what comes from excision). This LHS has a nice topology by letting $H_n(M,M-\overline{V})$ be discrete. I'm topologizing $o_M$ as the weakest topology these generate.
\end{construction}
``Have I been sufficiently obscure enough? This is not supposed to be a complicated point''. This $o_M\to M$ is called the \emph{orientation local system}, and is a covering space.
\begin{definition}
A continuous map $p:E\to B$ is a covering space if:
\begin{enumerate}
\item $p^{-1}(b)$ is discrete for all $b\in B$.
\item For every $b$ there's a neighborhood $V$ and a map $p^{-1}(V)\to p^{-1}(b)$ such that $p^{-1}(V)\xrightarrow{\cong}V\times p^{-1}(b)$ is a homeomorphism.
\end{enumerate}
\end{definition}
That's exactly the way we topologized $o_M$. There's more structure though because $H_n(M,M-\overline{V})$ is an $R$-module!
\begin{definition}
A local system (of $R$-modules) $p:E\to B$ is a covering space together with structure maps $E\times_B E:=\{(e,e^\prime)|pe=pe^\prime\}\xrightarrow{+} E$ and $z:B\to E$ such that:
\begin{equation*}
\xymatrix{
	E\times_B E\ar[rr]^+\ar[dr] & & E\ar[dl] & R\times E\ar[l]\\
	 & B\ar@{=}[r]\ar[ur] & B\ar[u]^{z} & 
}
\end{equation*}
making $p^{-1}(b)$ a $R$-module.
\end{definition}
We have $H_n(M)\xrightarrow{j_x}H_n(M,M-x)$, which gives a \emph{section} of $o_M$. If I have a covering space $p:E\to B$, a section is a continuous map $s:B\to E$ such that $ps=1_B$. Write $\Gamma(E)$ to be the set of sections. If $E$ is a local system, this is an $R$-module. Hence $H_n(M)\xrightarrow{j_x}H_n(M,M-x)$ gives a map $j:H_n(M)\to \Gamma(o_M)$. This is pretty cool because it's telling you about this high-dimensional homology of $M$ into something ``discrete''.
\begin{theorem}
If $M$ is compact then $j:H_n(M)\to\Gamma(o_M)$ is an isomorphism, and $H_q(M)=0$ for $q>n$.
\end{theorem}
This is case of Poincar\'{e} duality actually because $\Gamma(o_M)$ is somewhat like zero-dimensional cohomology. If this is trivial, like it is for a torus, so if the manifold is connected, then $\Gamma(o_M)$ is just $R$.
%\newpage
\section{Fundamental class}
Note that if $M$ is a compact manifold, then $H_q(M;R)=0$ for $q\gg 0$, and if $R$ is a PID, then for all $q$, $H_q(M;R)$ is finitely-generated. This follows from:
\begin{claim}
Suppose $X$ admits an open cover $\{U_i\}_{i=1}^n$ such that all intersections are either empty or contractible (this is what you get for a good cover on a manifold). Then $H_q(X;R)=0$ for $q\geq n$, and if $R$ is a PID, then for all $q$, $H_q(X;R)$ is finitely-generated.
\end{claim}
\begin{proof}
Induct. Certainly true for $n=1$. Let $Y=\bigcup^{n-1}_{i=1}U_i$, then this statement is true by induction -- and similarly for $Y\cap U_n$. Now use Mayer-Vietoris. You have $\cdots\to H_q(Y\cap U_n)\to H_q(Y)\oplus H_q(U_n)\to H_q(X)\to H_{q-1}(Y\cap U_n)\to\cdots$. When $q=n-1$, $H_q(Y\cap U_n)$ could be nonzero, and so you might get something nontrival(???). Also, you'll get a sexseq by unsplicing the lexseq: $0\to H_q(Y)\oplus H_q(U_n)/\text{something}\to H_q(X)\to \text{submodule of }H_{q-1}(Y\cap U_n)\to 0$, where you use $R$ being a PID to conclude that $\text{submodule of }H_{q-1}(Y\cap U_n)$ is finitely generated.
\end{proof}
Let $M$ be an $n$-manifold. We had a map $j:H_n(M)\to \Gamma(M;o_M)$. Here $\Gamma(M;o_M)$ is the collection of compatible elements of $H_n(M,M-x)$ for $x\in M$. This map $j:H_n(M)\to \Gamma(M;o_M)$ sends $c\mapsto(x\mapsto j_x c)$ where $j_x:H_n(M,\emptyset)\to H_n(M,M-x)$. I want to make two refinements.

You can't expect $j$ to be surjective, except maybe when $M$ is compact. Here's why. Let $c\in Z_n(M)$. It's a sum of simplices, and each simplex is compact, and so the union of the images is compact, and hence there's a compact subset $K\subseteq M$ such that $c\in Z_n(K)$. Now if I take $x\not\in K$, then the map $H_n(K)\to H_n(M)$ splits as $H_n(K)\to H_n(M-x)\to H_n(M)$. In the relative homology, $H_n(M,M-x)$, the map $H_n(K)\to H_n(M)\to H_n(M,M-x)$ sends $c$ to zero.
\begin{definition}
Let $\sigma$ be a section of $p:E\to B$ (local system). Then the support of $\sigma$ is defined as $\mathrm{supp}(\sigma)=\overline{\{x\in B|\sigma(x)\neq 0\}}$. The collection of all sections with compact support is $\Gamma_c(B;E)$, and it's a submodule of $\Gamma(B;E)$.
\end{definition}
The first refinement is that $j:H_n(M)\to \Gamma(M;o_M)$ lands in $\Gamma_c(M;o_M)$, because homology is compactly supported.

The second refinement seems a little artificial but is part of the inductive process. Let $A\subseteq M$ be closed. Then you have a restriction map $H_n(M,M-A)\xrightarrow{j_x}H_n(M,M-x)$ for $x\in A$. Thus you get a map $j:H_n(M,M-A)\to \Gamma_c(A;o_M|_{A})$, the latter of which we'll just denote $\Gamma_c(A;o_M)$.
\begin{theorem}
The map $j:H_n(M,M-A)\to \Gamma_c(A;o_M|_{A})$ is an isomorphism and $H_q(M,M-A)=0$ for $q>n$. (If $A=M$ then $j:H_n(M)\to \Gamma_c(M;o_M)$ is an isomorphism.)
\end{theorem}
\begin{proof}
For $X=\RR^n$ and $A=D^n$. Well, $o_{\RR^n}=\RR^n\times H_n(\RR^n,\RR^n-0)$ is trivial (i.e., a product projection), so $\Gamma(D^n;o_{\RR^n})=\Hom_{\mathbf{Top}}(D^n,H_n(\RR^n,\RR^n-0))$ where $H_n(\RR^n,\RR^n-0)$ is discrete, and this is therefore just a map from $\pi_0$ into this, and thus $\Gamma(D^n;o_{\RR^n})=R$ (your coefficient). But also, $H_n(\RR^n,\RR^n-D^n)\cong R$, so you have that $j$ gives $H_n(\RR^n,\RR^n-D^n)\to \Gamma_c(D^n;o_{\RR^n}|_{D^n})$.

Say that this is true for $A,B,A\cap B$ -- we'll prove this for $A\cup B$. Obviously, use Mayer-Vietoris. I have a restriction $\Gamma_c(A\cup B;o_M)\to \Gamma_c(A;o_M)\oplus \Gamma_c(B;o_M)$ that sits in an exact sequence $0\to \Gamma_c(A\cup B;o_M)\xrightarrow{\text{inclusion, determined by }A,B} \Gamma_c(A;o_M)\oplus \Gamma_c(B;o_M)\to \Gamma_c(A\cap B;o_M)$. This is a gluing lemma. We also have a relative Mayer-Vietoris $H_n(M,M-A\cup B)\to H_n(M,M-A)\oplus H_n(M,M-B)\to H_n(M,M-A\cap B)$, so we have:
\begin{align*}
\xymatrix@C=10pt{
	0\ar[r] & \Gamma_c(A\cup B;o_M)\ar[r]^{\text{inclusion }A,B\to A\cup B} & \Gamma_c(A;o_M)\oplus \Gamma_c(B;o_M)\ar[r] & \Gamma_c(A\cap B;o_M)\\
	H_{n+1}(M,M-A\cap B)=0\ar[r]^0 & H_n(M,M-A\cup B)\ar[r]\ar[u] & H_n(M,M-A)\oplus H_n(M,M-B)\ar[r]\ar[u]^{j_\ast}_{\cong} & H_n(M,M-A\cap B)\ar[u]^{j_\ast}_{\cong}
}
\end{align*}
This is a ``local-to-global'' argument. ``I don't feel like going through the point-set topology -- the rest of the proof is just annoyance.'' See Bredon's book for the conclusion of the proof.
\end{proof}
\begin{corollary}
$j:H_n(M)\to \Gamma_c(M;o_M)$ is an isomorphism.
\end{corollary}
\begin{definition}
An $R$-orientation for $M$ is a section $\sigma$ of $\Gamma(M;o_M^\times)$ where $o_M^\times$ is the covering space of $M$ given by the generators (as $R$-modules) of the fibers of $o_M$.
\end{definition}
If $M$ is compact, then $j:H_n(M)\to \Gamma(M;o_M)$, and you get $[M]\leftrightarrow \sigma$. When does that exist?

\underline{Over $\Z$:} $o_M^\times\to M$ is a double cover of $M$ (over every element you have two possible elements given by the two possible orientations ($\pm 1$)). If $M$ is an $n$-manifold and $f:N\to M$ is a covering space, then $N$ is also locally Euclidean. I have the orientation local system to get a pullback local system:
\begin{equation*}
\xymatrix{
	f^\ast o_M=N\times_M o_M\ar[r]\ar[d] & o_M\ar[d]\\
	N\ar[r] & M
}
\end{equation*}
Because $N\to M$ is a covering space, the fibers of $f^\ast o_M$ are the same as the fibers of $o_N$, so actually, $f^\ast o_M\cong o_N$. For example, suppose $N=o_M^\times$. What happens if I consider:
\begin{equation*}
\xymatrix{
	o_N=N\times_M N\ar[r]\ar[d] & N\ar[d]\\
	N\ar[r] & M
}
\end{equation*}
But now, I have the identity $N\to N$ that sits compatibly as:
\begin{equation*}
\xymatrix{
	N\ar[r]^{\mathrm{id}}\ar[d] ^{\mathrm{id}} & N\ar[d]\\
	N\ar[r] & M
}
\end{equation*}
And hence you get $N\to o_N^\times$, which is a section of $o_N^\times\to N$. The conclusion is that $N=o_M^\times$ is canonically oriented (even if $M$ is not oriented!). If $M$ is oriented, then the local system is trivial and you have the trivial double cover.

The overarching conclusion is: if $M$ is an $n$-manifold, then:
\begin{enumerate}
\item $H_q(M)=0$ for $q>n$.
\item If $M$ is compact, then $H_n(M)\xrightarrow{\cong}\Gamma(M,o_M)$.
\item If $M$ is connected and compact, then:
	\begin{enumerate}
	\item if $M$ is oriented with respect to $R$, then $H_n(M)\cong \Gamma(M,o_M)\cong R$.
	\item (I have no idea what was happening here, we didn't reach to a conclusion for a while.) if $M$ is not orientable, then $o_M^\times$ is nontrivial. If $o_M^\times$ has a section, then it's trivial (and so is $o_M$) because if it has a section $\sigma:M\to o^\times_M$, define $M\times R^\times\xrightarrow{\cong} o_M^\times$ by sending $(x,r)\mapsto r\sigma(x)\in o_M^\times$ (and the same thing $M\times R\xrightarrow{\cong} o_M$ for the orientation local system itself). I don't see an argument to conclude that if $M$ is nonorientable, then there aren't any section of $o_M$. In particular, if $R=\Z$, then $H_n(M;\Z)=0$. I'm going to leave this as a statement without proof, unless any of you can help me.
	\end{enumerate}
\end{enumerate}
If a section $\sigma(x)=0$ for some $x$, then $\sigma=0$.
\begin{remark}
Prof. Miller talked with me about this after class. If I recall correctly, one way to think about this is as follows. If you have a local system $p:E\to B$, this can be viewed as a representation of $\pi_1(B)\to R^\times$, and the $\Gamma(B;E)=(E_x)^{\pi_1(B)}$ where $\pi_1(B)$ acts on the fibers by multiplication. Thus $(E_x)^{\pi_1(B)}=R^{\pi_1(B)}$. If $R=\Z$, then $R^\times=\{\pm 1\}$, so $R^{\pi_1(B)}=\{r|ar=r,a\in\pi_1(B)\}$, so that $\Z^{\pi_1(B)}=0$. Hence there are no sections of $o_M$, as desired. For a ring $R$, $o_{M,R}=o_{M,\Z}\otimes R$. Something else for $\Z/2\Z$. A higher homotopy theoretic perspective is that if you have a fibration $E\to B$, then $E=PB\times_{\Omega B}F$ where $F$ is the fiber of the fibration, so that $\Gamma(B;E)=\Map_{\Omega B}(PB,F)=F^{h\Omega B}$. In the case of a covering space you recover what you have above since $\pi_0(\Omega B)=\pi_1(B)$.
\end{remark}
%\newpage
\section{Covering spaces and Poincar\'{e} duality}
Miller's office hours are tomorrow, from 1-3 in 2-478. The first half of this lecture was just explaining the remark above by using less technology.

On the website, there are notes on $\pi_1(X,\ast)$. I'm assuming people have seen this thing. Assume $X$ is path-connected, and let $\ast\in X$. There's another technical assumption: semi-locally simply connected (SLSC), which means that for every $b\in X$ and neighborhood $b\in U$, there exists a smaller neighborhood $b\in V\subseteq U$ such that $\pi_1(V,b)\to\pi_1(X,b)$ is trivial. This is a very very weak condition.
\begin{theorem}
Let $X$ be a path-connected, SLSC space with $\ast\in X$. Then there is an equivalence of categories between covering spaces over $X$ and sets with an action of $\pi_1(X,\ast)$. The way this functor goes is by sending $p:E\to X$ to $p^{-1}(\ast)$, which has an action of $\pi_1(X,\ast)$ in the obvious way by path-lifting.
\end{theorem}
\begin{example}[Stupidest possible case]
Suppose $\mathrm{id}:X\to X$ is sent to $\ast$ with the trivial action. This is the terminal covering space over $X$.
\end{example}
We've been interested in $\Gamma(E;X)$, which is the same thing as $\Map_X(X\to X,E\to X)\cong\Map_{\pi_1(X)}(\ast,E_\ast)=(E_\ast)^{\pi_1(B)}$, the fixed points of the action. We also thought about the case of $E$ being a local system of $R$-modules, and the same functor gives an equivalence between local systems of $R$-modules and $R[\pi_1(X)]$-modules, i.e., representations of $\pi_1(X)$.

Recall that $o_M$ is the orientation local system, but now \emph{over $\Z$}. Thus, over a general ring, $o_{M,R}=o_M\otimes R$. We were thinking about what happens with a closed path-connected SLSC subset $\ast\in A\subseteq M$ of an $n$-manifold $M$, and then considering $\Gamma(A,o_M\otimes R)$, which we now see to be $(o_M\otimes R)_{\ast}^{\pi_1(A,\ast)}$. How many options do we have here?

That is to say, this local system $o_M$ is the same thing as the free abelian group $H_n(M,M-\ast)$ with an action of $\pi_1(X,\ast)$. There aren't many options for this action. In other words, this is a homomorphism $\pi_1(M,\ast)\to \Aut(H_n(M,M-\ast))$. I haven't chosen a generator for $H_n(M,M-\ast)$, and there's only two automorphisms, i.e., we get a homomorphism $w_1:\pi_1(M,\ast)\to\Z/2\Z$. This homomorphism is called the ``first Stiefel-Whitney class''. 18.906 will describe all the Stiefel-Whitney classes. With $R$-coefficients, I get a map $\pi_1(M,\ast)\to \Aut(H_n(M,M-\ast;R))\cong R^\times$. This is a natural construction, so this homomorphism $\pi_1(M,\ast)\to R^\times$ factors through $\pi_1(M,\ast)\to\Z/2\Z$. This lets us get a good handle on what the sections are: $\Gamma(A;o_M\otimes R)=H_n(M,M-\ast;R)^{\pi_1(X,\ast)}$, but our analysis shows that:
\begin{align*}
\Gamma(A;o_M\otimes R) & =H_n(M,M-\ast;R)^{\pi_1(X,\ast)}\\
& =\begin{cases}
H_n(M,M-\ast;R)\cong R & \text{if }w_1=1\text{, well-defined up to sign; the orientable case}\\
\ker(R\xrightarrow{2}R) & \text{if }w_1\neq 1\text{, and this is a canonical identification}
\end{cases}
\end{align*}
where we get the latter thing because then $a=-a$, i.e., $2a=0$. In particular, if $R=\Z/2\Z$, since $\Aut_{\Z/2\Z}(\Z/2\Z)=1$, you always have a unique orientation. If $R=\Z/p\Z,\Z,\QQ$, then $\ker(R\xrightarrow{2}R)=0$.

We had a general theorem:
\begin{theorem}
$H_n(M,M-A;R)\xrightarrow{j,\cong}\Gamma_c(A;o_M\otimes R)$ and $H_q(M,M-A;R)=0$ for $q>n$.
\end{theorem}
\begin{corollary}
If $M$ is connected and $A=M$, and if $M$ is not compact, then $H_n(M;R)=0$. If $M$ is compact, then the work we just did shows that $H_n(M;R)=\begin{cases}R & \text{oriented} \\ \ker(R\xrightarrow{2}R) & \text{nonorientable}\end{cases}$.
\end{corollary}
\subsection{Poincare duality, finally}
Assume $M$ is $R$-oriented. Let $K\subseteq M$ be compact. Then $H_n(M,M-K)\xrightarrow{\cong}\Gamma(K;o_M\otimes R)$. Picking an orientation picks an isomorphism $\Gamma(K;o_M\otimes R)\cong R$. This gives some $[M]_K$, which is called the fundamental class along $K$. If $K=M$, then $[M]_M=:[M]\in H_n(M;R)$.

Suppose $K\subseteq L$ are compact subsets. We now combine all of our results above:
\begin{theorem}[Fully relative Poincare duality]
If $p+q=n$, then $\cHH^p(K,L;R)\xrightarrow{\cap[M]_K}H_q(M-L,M-K;R)$ is an isomorphism.
\end{theorem}
\begin{proof}
``It's, like, not hard at this point.'' One thing we did was set up an LES for $\cHH$ of a pair, which implies that we may assume that $L=\emptyset$. We want to prove that $\cHH^p(K;R)\xrightarrow{\cap[M]_K}H_q(M,M-K;R)$ is an isomorphism. Now there's a standard local-to-global process.

In the local case, if $M=\RR^n$ and $K=D^n$, then this is saying that $\cHH^p(D^n;R)\cong H^p(D^n;R)\xrightarrow{\cap[\RR^n]_{D^n}}H_q(\RR^n,\RR^n-D^n;R)$ where the first isomorphism comes from analysis we did earlier about \v{C}ech and ordinary cohomology coinciding. If $p\neq 0$, then both sides are zero. When $p=0$, we are asking that $H^0(D^n;R)\xrightarrow{\cap[\RR^n]_{D^n}}H_n(\RR^n,\RR^n-D^n;R)$. They're both equal to $R$, and we are just capping along $[\RR^n]_{D^n}$, because we found that $1\cap[\RR^n]_{D^n}=[\RR^n]_{D^n}$, as desired.

We carefully set up the Mayer-Vietoris sequence ladder (Theorem 33.5) that allows us to put this all together. ``We're not going to go through the details because there's point set topology that I don't like there.'' Note that normality is not needed for $K,L$ compact because compact sets in hausdorff spaces can always be separated, normal or not. I just reversed the order in which things are usually taught in books.
\end{proof}
We have time for one beginning application.
\begin{corollary}[Relative Poincare duality]
Suppose $K=M$ and $M$ is compact and $R$-oriented. Then $\cHH^p(M,L;R)\xrightarrow{\cap[M]}H_{n-p}(M-L,R)$ is an isomorphism.
\end{corollary}
\begin{corollary}[Poincare duality, corollary of corollary]
Let $M$ be compact and $R$-oriented, then $H^p(M;R)\xrightarrow{\cap [M]}H_{n-p}(M;R)$ is an isomorphism.
\end{corollary}
\begin{proof}
Follows from the above corollary since $\cHH^p(M;R)$ is literally equal to $H^p(M;R)$
\end{proof}
That's the most beautiful form of all. If you do have an $L$, you have this ladder, where all vertical maps are isomorphisms:
\begin{equation*}
\xymatrix{
	\cdots\ar[r] & \cHH^p(M,L)\ar[r]\ar@{-->}[d]_{-\cap [M]} & \cHH^p(M)\ar[r]\ar[d]_{-\cap [M]} & \cHH^p(L)\ar[r]^\delta\ar[d]_{-\cap [M]_L} & \cHH^{p+1}(M,L)\ar[r]\ar[d]_{-\cap [M]} & \cdots\\
	\cdots\ar[r] & H_q(L)\ar[r]& H_q(M)\ar[r] & H_q(M,M-L)\ar[r]^\partial & H_{q-1}(L)\ar[r] & \cdots
}
\end{equation*}
This is a consistency statement for Poincare duality. On Wednesday, we'll specialize even further, and prove the Jordan curve theorem as well as study the cohomology rings of things we haven't worked through before.
\section{Applications}
Please check exam schedule! Also, a sample exam is posted. This is the payoff day. All this stuff about Poincare duality has got to be good for something. Recall:
\begin{theorem}[Fully relative duality]
Let $M$ be a $R$-oriented $n$-manifold. Let $L\subseteq K\subseteq M$ be compact ($M$ need not be compact). Then $[M]_K\in H_n(M,M-K)$, and capping gives an isomorphism:
$$\cHH^p(K,L;R)\xrightarrow{\cap[M]_k,\cong}H_{n-p}(M-L,M-K;R)$$
\end{theorem}
Today we'll think about the case $L=\emptyset$, so this is saying:
$$\cHH^p(K;R)\xrightarrow{\cap[M]_k,\cong}H_{n-p}(M,M-K;R)$$
\begin{corollary}
$\cHH^q(K;R)=0$ for $q>n$.
\end{corollary}
We can contrast this with singular (co)homology. Here's an example:
\begin{example}[Barratt-Milnor]
A two-dimensional version $K$ of the Hawaiian earring, i.e., nested spheres all tangent to a point whose radii are going to zero. What they proved is that $H_q(K;\QQ)$ is uncountable for every $q>1$. But if you look at the \v{C}ech cohomology, stuff vanishes.
\end{example}
That's nice.

How about an even more special subcase? Suppose $M=\RR^n$. The result is called Alexander duality. This says:
\begin{theorem}[Alexander duality]
If $\emptyset\neq K\subseteq \RR^n$ be compact. Then $\cHH^{n-q}(K;R)\xrightarrow{\cong}\widetilde{H}_{q-1}(\RR^n-K;R)$
\end{theorem}
\begin{proof}
We have the LES of a pair, which gives an isomorphism $\partial:H_q(\RR^n,\RR^n-K;R)\xrightarrow{\cong}\widetilde{H}_{q-1}(\RR^n-K;R)$, so the composition $\partial\circ(-\cap[M]_K)$ is an isomorphism by Poincare duality.
\end{proof}
For most purposes, this is the most useful duality theorem.
\begin{example}[Jordan curve theorem]
$q=1$ and $R=\Z$. Then this is saying that $\cHH^{n-1}(K)\xrightarrow{\cong}\widetilde{H}_0(\RR^n-K)$. But $\widetilde{H}_0(\RR^n-K)$ is free on $\#\pi_0(\RR^n-K)-1$ generators. If $n=2$, for example, and $K\cong S^1$, then $\cHH^{n-1}(K)=H^{n-1}(K)\cong H^{n-1}(S^1)$, so $H^1(S^1)\cong \widetilde{H}_0(\RR^2-K)$. Hence there are \emph{two} components in the complement of $K$. This could also be the topologist's sine curve as well. This is the Jordan curve theorem.
\end{example}
Consider the UCT, which states that there's a sexseq $0\to\Ext^1_\Z(H_{q-1}(X),\Z)\to H^q(X)\to\Hom(H_q(X),\Z)\to 0$ that splits, but not naturally. First, note that $\Hom(H_q(X),\Z)$ is always torsion-free. If I assume that $H_{q-1}(X)$ is finitely generated, then $\Ext^1_\Z(H_{q-1}(X),\Z)$ is a finite abelian group, but in particular it's torsion.

The UCT is making the decomposition of $H^q(X)$ into its torsion-free and torsion parts. I can divide by torsion, so that $H^q(X)/\mathrm{tors}\cong \Hom(H_q(X),\Z)$. But there's also an isomorphism $\Hom(H_q(X)/\mathrm{tors},\Z)\to \Hom(H_q(X),\Z)$ because $\Z$ is torsion-free. Therefore I get an isomorphism $\alpha:H^q(X)/\mathrm{tors}\to \Hom(H_q(X)/\mathrm{tors},\Z)$. I.e.:
\begin{equation*}
\xymatrix{
	0\ar[r] & \Ext^1_\Z(H_{q-1}(X),\Z)\ar[r] & H^{q}(X)\ar[r]\ar[d] & \Hom(H_q(X),\Z)\ar[r] & 0\\
 & & H^q(X)/\mathrm{tors}\ar[ur]^{\cong}\ar[r]^{\alpha} & \Hom(H_q(X)/\mathrm{tors}/\Z)\ar[u]^{\cong}
}
\end{equation*}
Or I could say it like this: the Kronecker pairing can be quotiented by torsion, and you get an induced map $H^q(X)/\mathrm{tors}\otimes H_q(X)/\mathrm{tors}\to\Z$ is a perfect pairing, which means that the adjoint map $H^q(X)/\mathrm{tors}\xrightarrow{\cong}\Hom(H_q(X)/\mathrm{tors},\Z)$. Let's combine this with Poincare duality.

Let $X=M$ be a compact oriented $n$-manifold. Then $H^{n-q}(X)\xrightarrow{-\cap[M],\cong}H_q(M)$, and so we get a perfect pairing $H^q(X)/\mathrm{tors}\otimes H^{n-q}(X)/\mathrm{tors}\to\Z$. And what is that pairing? It's the cup product! We have:
\begin{equation*}
\xymatrix{
	H^q(M)\otimes H^{n-q}(M)\ar[r]\ar[d]_{1\otimes(-\cap [M])} & \Z\\
	H^q(M)\otimes H_q(M)\ar[ur]_{\langle,\rangle}
}
\end{equation*}
And, well:
\begin{equation*}
\langle a,b\cap [M]\rangle = \langle a\cup b,[M]\rangle
\end{equation*}
Thus the map $H^q(M)\otimes H^{n-q}(M)\to \Z$ is $a\otimes b\mapsto\langle a\cup b,[M]\rangle$, and it's a perfect pairing. This is a purely cohomological version, and is the most useful statement.
\begin{example}
Suppose $M=\CP^2=D^0\cup D^2\cup D^4$, and its homology is $\Z \, 0 \, \Z \, 0\, \Z$, and so its cohomology is the same. Let $a\in H^2(\CP^2)$. Then we have $H^2(\CP^2)\otimes H^2(\CP^2)\to \Z$, and so $a\cup a$ is a generator of $H^4(\CP^2)$, and hence specifies an orientation for $\CP^2$. The conclusion is that $H^\ast(\CP^2)=\Z[a]/(a^3)$ where $|a|=2$.

How about $\CP^3$? It just adds a $6$-cell, so its homology is $\Z \, 0 \, \Z \, 0\, \Z \, 0 \, \Z$, and so its cohomology is the same. But then $a^3=a\cup a\cup a$ is a generator of $H^6(\CP^2)$, and etc. Thus in general, we have:
$$H^\ast(\CP^n)=\Z[a]/(a^{n+1})$$
These things are finite CW-complexes, so you find:
\begin{equation}
H^\ast(\CP^\infty)=\Z[a]
\end{equation}
\end{example}
\begin{example}
Suppose I look at maps $f:S^m\to S^n$. One of the most interesting things is that there are lots of non null-homotopic maps $S^m\to S^n$ if $m>2$. For example, $\eta:S^3\to S^2$ that's the attaching map for the $4$-cell in $\CP^2$. This is called the Hopf fibration. It's essential. Why is it nullhomotopic? If $\eta$ was null homotopic, then $\CP^2\simeq S^2\wedge S^4$. That's compatible with the cohomology in each dimension, but not into the cohomology ring! There's a map $S^2\wedge S^4\to S^2$ that collapses $S^4$, and the generator in $H^\ast(S^2)$ has $a^2=0$, so $a^2=0$ in $H^\ast(S^2\wedge S^4)$. But this is not compatible with our computation that $H^\ast(\CP^2)=\Z[a]/(a^3)$ where $|a|=2$.
\end{example}

With coefficients in a field $k$, then the torsion is zero, so you find that if $M$ is compact $k$-oriented, then if the characteristic of $k=2$, there's no condition for $M$ to be oriented, and if the characteristic of $k$ is not $2$, then $M$ is $\Z$-oriented. Thus we get that $H^q(M;k)\otimes_k H^{n-q}(M;k)\to k$ is a perfect pairing.
\begin{example}
Exactly the same argument as for complex projective space shows that:
\begin{equation*}
H^\ast(\RP^n;\FF_2)=\FF_2[a]/(a^{n+1})
\end{equation*}
where $|a|=1$. So:
\begin{equation}
H^\ast(\RP^\infty;\FF_2)=\FF_2[a]
\end{equation}
where $|a|=1$.
\end{example}
I'll end with the following application.
\begin{theorem}
Suppose $f:\RR^{m+1}\supseteq S^m\to S^n\subseteq \RR^{n+1}$ that is equivariant with respect to the antipodal action, i.e., $f(-x)=-f(x)$. Then $m\leq n$.
\end{theorem}
So there are \emph{no} equivariant maps from $S^m\to S^n$ if $m>n$!
\begin{proof}
Suppose I have a map like that: the map on spheres induces a map $\overline{f}:\RP^m\to\RP^n$. We claim that $H_1(\overline{f})$ is an isomorphism. Let $\pi:S^n\to\RP^n$ denote the map. Let $\sigma:I\to S^m$ be defined via $\sigma(0)=v$ and $\sigma(1)=-v$. So this gives a $1$-cycle $\sigma:I\to S^m\to\RP^m$, and $H_1(\RP^n)=[\pi\sigma]$ is generated by this thing. When I map this thing to $\RP^n$, we send $\pi\sigma$ to a generator. What we've actually proved, therefore, is that $H_1(\RP^m)\cong H_1(\RP^n)$. This is also true with mod $2$ coefficients, i.e., $H_1(\overline{f},\FF_2)\neq 0$.

That means that $H^1(\overline{f};\FF_2)\neq 0$ by UCT. But what is this? This is a map $H^1(f;\FF_2):H^\ast(\RP^n;\FF_2)\to H^\ast(\RP^n;\FF_2)$, i.e., a map $\FF_2[a]/(a^{n+1})\to \FF_2[a]\to(a^{m+1})$. Thus $a\mapsto a$. There's not a lot of ways to do this if $m>n$. Thus what we've shown that $m\leq n$.
\end{proof}
This is the Borsuk-Ulam theorem from the '20s, I think. This is an example of how you can use the cohomology ring structure for projective space.

Please check the website for details about your finals. I will ask you to sign a form, to make sure that you don't share the questions or that you haven't heard the questions beforehand. I have a fixed set of questions that'll guide the conversation.
